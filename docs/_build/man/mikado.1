.\" Man page generated from reStructuredText.
.
.TH "MIKADO" "1" "Aug 04, 2016" "1.0" "Mikado"
.SH NAME
mikado \- Mikado Documentation
.
.nr rst2man-indent-level 0
.
.de1 rstReportMargin
\\$1 \\n[an-margin]
level \\n[rst2man-indent-level]
level margin: \\n[rst2man-indent\\n[rst2man-indent-level]]
-
\\n[rst2man-indent0]
\\n[rst2man-indent1]
\\n[rst2man-indent2]
..
.de1 INDENT
.\" .rstReportMargin pre:
. RS \\$1
. nr rst2man-indent\\n[rst2man-indent-level] \\n[an-margin]
. nr rst2man-indent-level +1
.\" .rstReportMargin post:
..
.de UNINDENT
. RE
.\" indent \\n[an-margin]
.\" old: \\n[rst2man-indent\\n[rst2man-indent-level]]
.nr rst2man-indent-level -1
.\" new: \\n[rst2man-indent\\n[rst2man-indent-level]]
.in \\n[rst2man-indent\\n[rst2man-indent-level]]u
..
.sp
\fI\%python_badge\fP \fI\%snake_badge\fP
.INDENT 0.0
.TP
.B Authors
Venturini Luca,
Caim Shabhonam,
Mapleson Daniel,
Kaithakottil Gemy George,
Swarbreck David
.TP
.B Version
1.0 (July 2016)
.UNINDENT
.sp
Mikado is a lightweight Python3 pipeline to extract the best transcript models from multiple transcript assemblies.
.sp
Contents:
.SH INTRODUCTION
.sp
\fI\%python_badge\fP \fI\%snake_badge\fP
.sp
Introduction test
.SS Metrics
.sp
These are all the metrics available to quantify transcripts. The documentation for this section has been generated using the metrics utility\&.
.sp
Metrics belong to one of the following categories:
.INDENT 0.0
.IP \(bu 2
\fBDescriptive\fP: these metrics merely provide a description of the transcript (eg its ID) and are not used for scoring.
.IP \(bu 2
\fBcDNA\fP: these metrics refer to basic features of any transcript such as its number of exons, its cDNA length, etc.
.IP \(bu 2
\fBIntron\fP: these metrics refer to features related to the number of introns and their lengths.
.IP \(bu 2
\fBCDS\fP: these metrics refer to features related to the CDS assigned to the transcript.
.IP \(bu 2
\fBUTR\fP: these metrics refer to features related to the UTR of the transcript. In the case in which a transcript has been assigned multiple ORFs, unless otherwise stated the UTR metrics will be derived only considering the \fIselected\fP ORF, not the combination of all of them.
.IP \(bu 2
\fBLocus\fP: these metrics refer to features of the transcript in relationship to all other transcripts in its locus, eg how many of the introns present in the locus are present in the transcript. These metrics are calculated by Mikado during the picking phase, and as such their value can vary during the different stages as the transcripts are shifted to different groups.
.IP \(bu 2
\fBExternal\fP: these metrics are derived from accessory data that is recovered for the transcript during the run time. Examples include data regarding the number of introns confirmed by external programs such as PortCullis, or the BLAST score of the best hits.
.UNINDENT
.TS
center;
|l|l|l|l|.
_
T{
Metric name
T}	T{
Description
T}	T{
Data type
T}	T{
Category
T}
_
T{
\fItid\fP
T}	T{
Name of the transcript. Not used for scoring.
T}	T{
String
T}	T{
\fBDescriptive\fP
T}
_
T{
\fIparent\fP
T}	T{
Name of the transcript parent. Not used for scoring.
T}	T{
String
T}	T{
\fBDescriptive\fP
T}
_
T{
\fIscore\fP
T}	T{
Final score of the transcript.
T}	T{
Float
T}	T{
\fBDescriptive\fP
T}
_
T{
\fIbest_bits\fP
T}	T{
Best Bit Score associated with the transcript.
T}	T{
Float
T}	T{
\fBExternal\fP
T}
_
T{
\fIblast_score\fP
T}	T{
Alias for either \fIbest_bits\fP or \fIsnowy_blast_score\fP\&. Set
currently to \fIbest_bits\fP
T}	T{
Float
T}	T{
\fBExternal\fP
T}
_
T{
\fIcanonical_intron_proportion\fP
T}	T{
This metric returns the proportion of canonical introns of
the transcript on its total number of introns.
T}	T{
Float
Float
T}	T{
\fBIntron\fP
T}
_
T{
\fIcdna_length\fP
T}	T{
This property returns the length of the transcript.
T}	T{
Int
T}	T{
\fBcDNA\fP
T}
_
T{
\fIcds_not_maximal\fP
T}	T{
This property returns the length of the CDS excluding
that contained in the selected ORF. If the transcript only
has one ORF, this metric returns a value of 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIcds_not_maximal_fraction\fP
T}	T{
This property returns the fraction of bases not in the
selected ORF compared to the total number of CDS bases
in the cDNA.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIcombined_cds_fraction\fP
T}	T{
This property return the percentage of the CDS part of the
transcript vs. the cDNA length.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIcombined_cds_intron_fraction\fP
T}	T{
This property returns the fraction of CDS introns of the
transcript vs. the total number of CDS introns in the
Locus. If the transcript is by itself, it returns 1.
T}	T{
Float
T}	T{
\fBLocus\fP
T}
_
T{
\fIcombined_cds_length\fP
T}	T{
This property returns the fraction of CDS introns of the
transcript, across all its ORFs.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIcombined_cds_num\fP
T}	T{
This property returns the number of non\-overlapping CDS
segments in the transcript.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIcombined_cds_num_fraction\fP
T}	T{
This property returns the fraction of non\-overlapping CDS
segments in the transcript vs. the total number of exons.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIcombined_utr_fraction\fP
T}	T{
This property returns the fraction of the cDNA which is
not coding according to any ORF. Complement of
\fIcombined_cds_fraction\fP
T}	T{
Float
T}	T{
\fBUTR\fP
T}
_
T{
\fIcombined_utr_length\fP
T}	T{
This property return the length of the UTR part of the
transcript.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIend_distance_from_junction\fP
T}	T{
This metric returns the cDNA distance between the stop
and the last junction of the transcript. In many
eukaryotes, this distance cannot exceed 50\-55 bps,
otherwise the transcript becomes a target for NMD. If the
transcript is not coding or there is no junction
downstream of the stop codon, the metric returns 0.
This metric considers the combined CDS end.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIend_distance_from_tes\fP
T}	T{
This property returns the distance of the end of the
combined CDS from the transcript end site. If no CDS is
defined, it defaults to 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIexon_fraction\fP
T}	T{
This property returns the fraction of exons of the
transcript which are contained in the sublocus. If the
transcript is by itself, it returns 1.
T}	T{
Float
T}	T{
\fBLocus\fP
T}
_
T{
\fIexon_num\fP
T}	T{
This property returns the number of exons of the
transcript.
T}	T{
Int
T}	T{
\fBcDNA\fP
T}
_
T{
\fIfive_utr_length\fP
T}	T{
Returns the length of the 5\(aq UTR of the \fIselected\fP ORF.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIfive_utr_num\fP
T}	T{
This property returns the number of 5\(aq UTR segments for
the selected ORF.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIfive_utr_num_complete\fP
T}	T{
This property returns the number of 5\(aq UTR segments for
the selected ORF, considering only those which are
complete exons.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIhas_start_codon\fP
T}	T{
True if the selected ORF has a start codon, False
otherwise
T}	T{
Bool
T}	T{
\fBCDS\fP
T}
_
T{
\fIhas_stop_codon\fP
T}	T{
True if the selected ORF has a stop codon, False otherwise
T}	T{
Bool
T}	T{
\fBCDS\fP
T}
_
T{
\fIhighest_cds_exon_number\fP
T}	T{
This property returns the maximum number of CDS segments
among the ORFs; this number can refer to an ORF
\fIDIFFERENT\fP from the maximal ORF.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIhighest_cds_exons_num\fP
T}	T{
Returns the number of CDS segments in the selected ORF
(irrespective of the number of exons involved)
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIintron_fraction\fP
T}	T{
This property returns the fraction of introns of the
transcript vs. the total number of introns in the Locus.
If the transcript is by itself, it returns 1.
T}	T{
Float
T}	T{
\fBLocus\fP
T}
_
T{
\fIis_complete\fP
T}	T{
Boolean. True if the selected ORF has both start and end.
T}	T{
Bool
T}	T{
\fBCDS\fP
T}
_
T{
\fImax_intron_length\fP
T}	T{
This property returns the greatest intron length for the
transcript.
T}	T{
Int
T}	T{
\fBIntron\fP
T}
_
T{
\fImin_intron_length\fP
T}	T{
This property returns the smallest intron length for the
transcript.
T}	T{
Int
T}	T{
\fBIntron\fP
T}
_
T{
\fInon_verified_introns_num\fP
T}	T{
This metric returns the number of introns of the
transcript which are not validated by external data.
T}	T{
Int
T}	T{
\fBExternal\fP
T}
_
T{
\fInum_introns_greater_than_max\fP
T}	T{
This metric returns the number of introns greater than the
maximum acceptable intron size indicated in the
constructor.
T}	T{
Int
T}	T{
\fBIntron\fP
T}
_
T{
\fInum_introns_smaller_than_min\fP
T}	T{
This metric returns the number of introns smaller than the
mininum acceptable intron size indicated in the
constructor.
T}	T{
Int
T}	T{
\fBIntron\fP
T}
_
T{
\fInumber_internal_orfs\fP
T}	T{
This property returns the number of ORFs inside a
transcript.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIproportion_verified_introns\fP
T}	T{
This metric returns, as a fraction, how many of the
transcript introns are validated by external data.
T}	T{
Float
T}	T{
\fBExternal\fP
T}
_
T{
\fIproportion_verified_introns_inlocus\fP
T}	T{
This metric returns, as a fraction, how many of the
verified introns inside the Locus are contained inside the
transcript.
T}	T{
Float
T}	T{
\fBLocus\fP
T}
_
T{
\fIretained_fraction\fP
T}	T{
This property returns the fraction of the cDNA which is
contained in retained introns.
T}	T{
Float
T}	T{
\fBLocus\fP
T}
_
T{
\fIretained_intron_num\fP
T}	T{
This property records the number of introns in the
transcripts which are marked as being retained.
T}	T{
Int
T}	T{
\fBLocus\fP
T}
_
T{
\fIselected_cds_exons_fraction\fP
T}	T{
Returns the fraction of CDS segments in the selected ORF
(irrespective of the number of exons involved)
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_cds_fraction\fP
T}	T{
This property calculates the fraction of the selected CDS
vs. the cDNA length.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_cds_intron_fraction\fP
T}	T{
This property returns the fraction of CDS introns of the
selected ORF of the transcript vs. the total number of
CDS introns in the Locus (considering only the selected
ORF). If the transcript is by itself, it should return 1.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_cds_length\fP
T}	T{
This property calculates the length of the CDS selected
as best inside the cDNA.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_cds_num\fP
T}	T{
This property calculates the number of CDS exons for the
selected ORF.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_cds_number_fraction\fP
T}	T{
This property returns the proportion of best possible CDS
segments vs. the number of exons. See selected_cds_number.
T}	T{
Float
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_end_distance_from_junction\fP
T}	T{
This metric returns the distance between the stop codon
and the last junction of the transcript. In many
eukaryotes, this distance cannot exceed 50\-55 bps,
otherwise the transcript becomes a target for NMD. If the
transcript is not coding or there is no junction
downstream of the stop codon, the metric returns 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_end_distance_from_tes\fP
T}	T{
This property returns the distance of the end of the best
CDS from the transcript end site. If no CDS is defined,
it defaults to 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIselected_start_distance_from_tss\fP
T}	T{
This property returns the distance of the start of the
best CDS from the transcript start site. If no CDS is
defined, it defaults to 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIsnowy_blast_score\fP
T}	T{
Metric that indicates how good a hit is compared to the
competition, in terms of BLAST similarities. As in
SnowyOwl [SnowyOwl], the score for each hit is calculated
by taking the percentage of positive matches and dividing
it by (2 * len(self.blast_hits)). IMPORTANT: when
splitting transcripts by ORF, a blast hit is added to the
new transcript only if it is contained within it. This
will influnce directly this metric.
T}	T{
Float
T}	T{
\fBExternal\fP
T}
_
T{
\fIsource_score\fP
T}	T{
This metric returns a score that is assigned to the
transcript solely in virtue of its origin.
T}	T{
Float
T}	T{
\fBExternal\fP
T}
_
T{
\fIstart_distance_from_tss\fP
T}	T{
This property returns the distance of the start of the
combined CDS from the transcript start site.
If no CDS is defined, it defaults to 0.
T}	T{
Int
T}	T{
\fBCDS\fP
T}
_
T{
\fIthree_utr_length\fP
T}	T{
Returns the length of the 5\(aq UTR of the selected ORF.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIthree_utr_num\fP
T}	T{
This property returns the number of 3\(aq UTR segments
(referred to the selected ORF).
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIthree_utr_num_complete\fP
T}	T{
This property returns the number of 3\(aq UTR segments for
the selected ORF, considering only those which are
complete exons.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIutr_fraction\fP
T}	T{
This property calculates the length of the UTR of the
selected ORF vs. the cDNA length.
T}	T{
Float
T}	T{
\fBUTR\fP
T}
_
T{
\fIutr_length\fP
T}	T{
Returns the sum of the 5\(aq+3\(aq UTR lengths.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIutr_num\fP
T}	T{
Returns the number of UTR segments.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIutr_num_complete\fP
T}	T{
Returns the number of UTR segments which are complete
exons.
T}	T{
Int
T}	T{
\fBUTR\fP
T}
_
T{
\fIverified_introns_num\fP
T}	T{
This metric returns the number of introns of the
transcript which are validated by external data.
T}	T{
Int
T}	T{
\fBExternal\fP
T}
_
.TE
:: \fI\%Installation\fP
.SH INSTALLATION
.SS Python version
.sp
Mikado
.SS Download
.sp
Mikado is available on PyPI, so it is possible to install it with
.sp
\fBpip3 install mikado\fP
.sp
The source for the latest release can be obtained with
.sp
\fBpip3 download mikado\fP
.sp
As the package contains some core Cython components, it might be necessary to download and compile the source code instead of relying on the wheel.
.sp
Alternatively, Mikado can be installed from source by obtaining it from our \fI\%GitHub\fP repository. Either download the \fI\%latest release\fP  or download the latest stable development snapshot with
.sp
\fBgit clone https://github.com/lucventurini/mikado.git; cd mikado\fP
.sp
If you desire, the unstable development version can be obtained with the command
.sp
\fBgit checkout development\fP
.sp
in the Git directory. Please note that development can proceed quite rapidly.
.SS Building and installing from source
.sp
If you desire to install Mikado from source, this can be achieved with
.sp
\fBpython3 setup.py bdist_wheel\fP
.sp
Followed by
.sp
\fBpip3 install dist/*whl\fP
.sp
We advise to test whether the distribution has been built successfully by executing the unit test suite with
.sp
\fBpython3 setup.py test\fP
.sp
Although code coverage is not perfect yet, it is over 50% for the whole package and considerably higher for the core components.
.SS Python Dependencies
.sp
Mikado has been written for Python 3.4 and 3.5. It is dependent on the following Python3 modules:
.INDENT 0.0
.IP \(bu 2
wheel>=0.28.0
.IP \(bu 2
pyyaml [PyYaml]
.IP \(bu 2
jsonschema
.IP \(bu 2
Cython [Cython]
.IP \(bu 2
cython [Cython]
.IP \(bu 2
numpy [Numpy]
.IP \(bu 2
networkx>=1.10 [NetworkX]
.IP \(bu 2
sqlalchemy>=1
.IP \(bu 2
sqlalchemy_utils
.IP \(bu 2
biopython>=1.66 [BioPython]
.IP \(bu 2
intervaltree
.IP \(bu 2
nose
.IP \(bu 2
pyfaidx
.IP \(bu 2
scikit\-learn>=0.17.0 [SciKit]
.IP \(bu 2
scipy>=0.15.0 [Scipy]
.IP \(bu 2
frozendict
.IP \(bu 2
python\-magic
.IP \(bu 2
drmaa [DRMAA]
.IP \(bu 2
snakemake [Snake]
.IP \(bu 2
docutils
.UNINDENT
.sp
These dependencies will be installed automatically by PIP.
.SS Additional dependencies
.sp
Mikado relies on relational databases for its functioning, so one of SQLite, PosGRESql or MySQL has to present for if to function properly. Additionally, the 
.nf
Daijin_
.fi
 pipeline requires BLAST+ and TransDecoder for the Mikado stage, and at least one RNA\-Seq aligner and one assembler, to be installed. If you are planning to execute it on a cluster, we do support job submission on SLURM, LSF and PBS clusters, either in the presence or absence of DRMAA.
.SH TUTORIAL
.SH USAGE
.sp
Mikado is composed of four different programs (\fIconfigure, prepare, serialise, pick\fP) which have to be executed serially to go from an ensemble of different assemblies to the final dataset. In addition to these core programs, Mikado provides a utility to compare annotations, similarly to CuffCompare and ParsEval (\fIcompare\fP), and various other minor utilities to perform operations such as extracting regions from a GFF, convert between different gene annotation formats, etc.
.SH MIKADO PIPELINE STAGES
.SS Mikado configure
.sp
This utility prepares the configuration file that will be used throughout the pipeline stages. While the most important options can be set at runtime through the command line, many algorithmic details can be accessed and intervened upon only through the file produced through this command.
.SS Usage
.sp
This command will generate a configuration file (in either JSON or YAML format), with the correct configuration for the parameters set on the command line. See \fI\%the in\-depth section on the structure of the configuration file\fP for details.
.sp
Command line parameters:
.INDENT 0.0
.IP \(bu 2
\fIfull\fP: By default, Mikado configure will output a stripped\-down configuration file, with only some of the fields explicitly present. Use this flag to show all the available fields.
.UNINDENT
.sp
\fBHINT:\fP
.INDENT 0.0
.INDENT 3.5
If a parameter is not explicitly present, its value will be set to the available default.
.UNINDENT
.UNINDENT
.INDENT 0.0
.IP \(bu 2
\fIexternal\fP: an external JSON/YAML file from which Mikado should recover parameters. If something is specified both on the command line and in the external configuration file, \fBcommand line options take precedence\fP\&.
.IP \(bu 2
\fIreference\fP: Reference genome FASTA file. Required for the correct functioning of Mikado.
.IP \(bu 2
\fIgff\fP: list of GFFs/GTFs of the assemblies to use for Mikado, comma separated.
.IP \(bu 2
\fIlabels\fP: optional list of labels to be assigned to each assembly. The label will be also the "source" field in the output of Mikado prepare\&.
.IP \(bu 2
\fIstrand\-specific\-assemblies\fP: list of strand specific assemblies among those specified with the \fIgff\fP flag.
.IP \(bu 2
\fIstrand\-specific\fP: flag. If set, all assemblies will be treated as strand\-specific.
.IP \(bu 2
.INDENT 2.0
.TP
.B \fIlist\fP: in alternative to specifying all the information on the command line, it is possible to give to Mikado a \fItab\-separated\fP file with the following contents:
.INDENT 7.0
.IP 1. 3
Location of the file
.IP 2. 3
label for the file
.IP 3. 3
whether that assembly is strand\-specific or not (write True/False)
.IP 4. 3
Optionally, a bonus/malus to be associated to transcripts coming from that assembly.
.UNINDENT
.UNINDENT
.IP \(bu 2
\fI\-j\fP, \fIjson\fP: flag. If present, the output file will be in JSON rather that YAML format.
.IP \(bu 2
\fImode\fP: in which mode Mikado pick will run. See the \fI\%relative section\fP for further details.
.IP \(bu 2
.INDENT 2.0
.TP
.B \fIscoring\fP: scoring file to be used for selection. At the moment, four configuration files are present:
.INDENT 7.0
.IP \(bu 2
plants
.IP \(bu 2
human
.IP \(bu 2
worm
.IP \(bu 2
insects
.UNINDENT
.UNINDENT
.IP \(bu 2
\fIcopy\-scoring\fP: this flag specifies a file the scoring file will be copied to. Useful for customisation on new species. The configuration file will account for this and list the location of the \fIcopied\fP file as the scoring file to be used for the run.
.IP \(bu 2
\fIjunctions\fP: Reliable junctions derived from the RNA\-Seq alignments. Usually obtained through \fI\%Portcullis\fP, but we also support eg junctions from Tophat2. This file must be in \fI\%BED12\fP format.
.IP \(bu 2
\fIblast_targets\fP: FASTA database of blast targets, for the serialisation stage.
.UNINDENT
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado configure \-\-help
usage: Mikado configure [\-h] [\-\-full]
                        [\-\-scoring {insects.yaml,human.yaml,plants.yaml,worm.yaml}]
                        [\-\-copy\-scoring COPY_SCORING] [\-\-strand\-specific]
                        [\-\-no\-files | \-\-gff GFF | \-\-list LIST]
                        [\-\-reference REFERENCE] [\-\-junctions JUNCTIONS]
                        [\-bt BLAST_TARGETS]
                        [\-\-strand\-specific\-assemblies STRAND_SPECIFIC_ASSEMBLIES]
                        [\-\-labels LABELS] [\-\-external EXTERNAL]
                        [\-\-mode {nosplit,stringent,lenient,permissive,split}]
                        [\-j]
                        [out]

This utility guides the user through the process of creating a configuration file for Mikado.

positional arguments:
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-full
  \-\-strand\-specific     Boolean flag indicating whether all the assemblies are strand\-specific.
  \-\-no\-files            Remove all files\-specific options from the printed configuration file.
                                               Invoking the "\-\-gff" option will disable this flag.
  \-\-gff GFF             Input GFF/GTF file(s), separated by comma
  \-\-list LIST           List of the inputs, one by line, in the form:
                        <file1>  <label>  <strandedness (true/false)>
  \-\-reference REFERENCE
                        Fasta genomic reference.
  \-\-strand\-specific\-assemblies STRAND_SPECIFIC_ASSEMBLIES
                        List of strand\-specific assemblies among the inputs.
  \-\-labels LABELS       Labels to attach to the IDs of the transcripts of the input files,
                                separated by comma.
  \-\-external EXTERNAL   External configuration file to overwrite/add values from.
                            Parameters specified on the command line will take precedence over those present in the configuration file.
  \-\-mode {nosplit,stringent,lenient,permissive,split}
                        Mode in which Mikado will treat transcripts with multiple ORFs.
                        \- nosplit: keep the transcripts whole.
                        \- stringent: split multi\-orf transcripts if two consecutive ORFs have both BLAST hits
                                     and none of those hits is against the same target.
                        \- lenient: split multi\-orf transcripts as in stringent, and additionally, also when
                                   either of the ORFs lacks a BLAST hit (but not both).
                        \- permissive: like lenient, but also split when both ORFs lack BLAST hits
                        \- split: split multi\-orf transcripts regardless of what BLAST data is available.
  \-j, \-\-json            Output will be in JSON instead of YAML format.

Options related to the scoring system:
  \-\-scoring {insects.yaml,human.yaml,plants.yaml,worm.yaml}
                        Available scoring files.
  \-\-copy\-scoring COPY_SCORING
                        File into which to copy the selected scoring file, for modification.

Options related to the serialisation step:
  \-\-junctions JUNCTIONS
  \-bt BLAST_TARGETS, \-\-blast_targets BLAST_TARGETS
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Anatomy of the configuration file
.sp
The guide here describes all voices of the configuration file. However, the configuration created by default by \fBmikado configure\fP is much simpler
.SS Database settings
.sp
This section deals with the database settings that will be necessary for the serialisation and picking phases of the pipeline. By default, Mikado will use a \fI\%SQLite database\fP, but it currently also supports \fI\%MySQL\fP and \fI\%PostgreSQL\fP through \fI\%SQLAlchemy\fP\&. Fields:
.INDENT 0.0
.IP \(bu 2
db: name of the database to use. In case the database is SQLite, this will be the database file, otherwise it will be the database \fIname\fP\&.
.IP \(bu 2
dbtype: one of:
* sqlite
* mysql
* postgresql
.IP \(bu 2
dbhost: host where the database is located. \fBRequired with MySQL and PostgreSQL\fP\&.
.IP \(bu 2
dbuser: User of the database. \fBRequired with MySQL and PostgreSQL\fP\&.
.IP \(bu 2
dbpasswd: Database password. \fBRequired with MySQL and PostgreSQL\fP\&.
.IP \(bu 2
dbport: Port to access to the database. It defaults to the normal ports for the selected database.
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
db_settings:
  #  Settings related to DB connection. Parameters:
  #  db: the DB to connect to. Required. Default: mikado.db
  #  dbtype: Type of DB to use. Choices: sqlite, postgresql, mysql. Default: sqlite.
  #  dbhost: Host of the database. Unused if dbtype is sqlite. Default: localhost
  #  dbuser: DB user. Default:
  #  dbpasswd: DB password for the user. Default:
  #  dbport: Integer. It indicates the default port for the DB.
  db: /usr/users/ga002/venturil/workspace/mikado/docs/mikado.db
  dbhost: localhost
  dbpasswd: \(aq\(aq
  dbport: 0
  dbtype: sqlite
  dbuser: \(aq\(aq
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Reference settings
.sp
This section of the configuration file deals with the reference genome. It specifies two fields:
.INDENT 0.0
.IP \(bu 2
genome: the genome FASTA file. \fBRequired\fP\&.
.IP \(bu 2
genome_fai: FAI index of the genome. Used by Mikado serialise, it can be inferred if left null.
.IP \(bu 2
transcriptome: optional annotation file for the genome. Mikado currently ignores this field, but it is used by Daijin to guide some of the RNA\-Seq assemblies.
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
reference:
  #  Options related to the reference genome.
  genome: \(aq\(aq
  genome_fai: \(aq\(aq
  transcriptome: \(aq\(aq
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Settings for the prepare stage
.sp
This section of the configuration file deals with the prepare stage of Mikado\&. It specifies the input files, their labels, and which of them are strand specific. The available fields are the following:
.INDENT 0.0
.IP \(bu 2
canonical: this voice specifies the splice site donors and acceptors that are considered canonical for the species. By default, Mikado uses the canonical splice site (GT/AG) and the two semi\-canonical pairs (GC/AG and AT/AC). Type: Array of two\-element arrays, composed by two\-letter strings.
.IP \(bu 2
lenient: boolean value. If set to \fIfalse\fP, transcripts that only have non\-canonical splice sites will be \fBremoved\fP from the output.
.IP \(bu 2
minimum_length: minimum length of the transcripts to be kept.
.IP \(bu 2
procs: number of processors to be used.
.IP \(bu 2
strand_specific: boolean. If set to \fItrue\fP, \fBall\fP input assemblies will be treated as strand\-specific, therefore keeping the strand of monoexonic fragments as it was.
.IP \(bu 2
strip_cds: boolean. If set to \fItrue\fP, the CDS features will be stripped off the input transcripts. This might be necessary for eg transcripts obtained through alignment with \fI\%GMAP\fP [GMAP]\&.
.IP \(bu 2
.INDENT 2.0
.TP
.B files: this sub\-section is the most important, as it contains among other things the locations and labels for the input files. Voices:
.INDENT 7.0
.IP \(bu 2
gff: array of the input files, in GFF or GTF format. Please note that only CDS/exon/UTR features will be considered from these files.
.IP \(bu 2
labels: optional array of the labels to be assigned to the input files. If non\-empty, \fIit must be of the same order and length of the gff array\fP, and be composed of unique elements. The labels will be used in two ways:
* as a prefix of the transcripts coming from the corresponding GFF
* as the \fIsource field\fP assigned to the transcript. This might be of relevance \fI\%during the picking stage\fP\&.
.IP \(bu 2
log: name of the log file.
.IP \(bu 2
out: name of the GTF output file.
.IP \(bu 2
out_fasta: name of the corresponding output FASTA file.
.IP \(bu 2
output_dir: output directory. It will be created if it does not exist already.
.IP \(bu 2
strand_specific_assemblies: array of the names of the GFF/GTF files that are strand specific. \fBAll the file names in this array must also appear in the gff array as well.\fP\&.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
prepare:
  #  Options related to the input data preparation.
  #  \- files: options relative to the input/output files.
  #  \- procs: Number of processes to use.
  #  \- strip_cds: whether to remove the CDS from the predictions during preparation.
  #  \- lenient: if set to True, invalid transcripts will be only flagged and not removed.
  #  EXPERIMENTAL.
  #  \- strand_specific: if set to True, transcripts will be assumed to be in the correct
  #  orientation, no strand flipping or removal
  #  \- strand_specific_assemblies: array of input predictions which are to be considered
  #  as strand\-specific.
  #    Predictions not in this list will be considered as non\-strand\-specific.
  #  \- canonical: canonical splice sites, to infer the correct orientation.
  canonical:
  \- \- GT
    \- AG
  \- \- GC
    \- AG
  \- \- AT
    \- AC
  files:
    #  Options related to the input and output files.
    #  \- out: output GTF file
    #  \- out_fasta: output transcript FASTA file
    #  \- gff: array of input predictions for this step.
    #  \- log: output log. Default: prepare.log
    #  \- labels: labels to be associated with the input GFFs. Default: None.
    gff: []
    labels: []
    log: prepare.log
    out: mikado_prepared.gtf
    out_fasta: mikado_prepared.fasta
    output_dir: .
    strand_specific_assemblies: []
  lenient: false
  minimum_length: 200
  procs: 1
  single: false
  strand_specific: false
  strip_cds: false
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Settings for the serialisation stage
.sp
This section of the configuration file deals with the serialisation stage of Mikado\&. It specifies the location of the ORF BED12 files from TransDecoder, the location of the XML files from BLAST, the location of portcullis junctions, and other details important at run time. It has the following voices:
.INDENT 0.0
.IP \(bu 2
discard_definition: boolean. This is used to specify whether we will use the ID or the definition of the sequences when parsing BLAST results. This is important when BLAST data might have a mock, local identifier for the sequence ("lcl|1") rather than its original ID.
.IP \(bu 2
force: whether the database should be truncated and rebuilt, or just updated.
.UNINDENT
.INDENT 0.0
.IP \(bu 2
max_objects: this parameter is quite important when running with a SQLite database. SQLite does not support caching on the disk before committing the changes, so that every change has to be kept in memory. This can become a problem for RAM quite quickly. On the other hand, committing is an expensive operation, and it makes sense to minimise calls as much as possible. This parameter specifies the maximum number of objects Mikado will keep in memory before committing them to the database. The default number, 100,000, should ensure that Mikado runs with less than 1GB memory. Increase it to potentially increase speed at the price of greater memory usage; for example, increasing it to 1,000,000 will cause Mikado to use ~6GB of RAM at its peak usage.
.UNINDENT
.INDENT 0.0
.IP \(bu 2
max_regression: this parameter is a float comprised between 0 and 1. TransDecoder will sometimes output open ORFs even in the presence of an in\-frame start codon. Mikado can try to "regress" along the ORF until it finds one such start codon. This parameter imposes how much Mikado will regress, in percentage of the cDNA length.
.IP \(bu 2
max_target_seqs: equivalent to the BLAST+ parameter of the same name \- it indicates the maximum number of discrete hits that can be assigned to one sequence in the database.
.IP \(bu 2
procs: number of processors to use. Most important for serialising BLAST+ files.
.IP \(bu 2
single_thread: boolean, if set to \fItrue\fP it will forcibly disable multi\-threading. Useful mostly for debugging purposes.
.IP \(bu 2
.INDENT 2.0
.TP
.B files: this sub\-section codifies the location of the input files for serialise. It contains the following voices:
.INDENT 7.0
.IP \(bu 2
junctions: array of locations of reliable junction files. These must be in BED12 format.
.IP \(bu 2
log: log file.
.IP \(bu 2
orfs: array of locations of ORFs location on the cDNA, as created by eg TransDecoder [Trinity]\&.
.IP \(bu 2
output_dir: output directory where the log file and the SQLite database will be written to (if SQLite has been chosen as the database type)
.IP \(bu 2
transcripts: input transcripts. This should be set to be equal to the output of Mikado prepare, ie the "out_fasta" field of the \fI\%prepare section of the configuration file\fP\&.
.IP \(bu 2
.INDENT 2.0
.TP
.B xml: this array indicates the location of the BLAST output file. Elements of the array can be:
.INDENT 7.0
.IP \(bu 2
BLAST+ XML files (optionally compressed with gzip)
.IP \(bu 2
BLAST+ ASN files (optionally compressed with gzip), which will be converted in\-memory using \fBblast_formatter\fP
.IP \(bu 2
a folder containing files of the above types.
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
serialise:
  #  Options related to serialisation
  #  \- force: whether to drop and reload everything into the DB
  #  \- files: options related to input files
  #  \- max_objects: Maximum number of objects to keep in memory while loading data
  #  into the database
  #  \- max_regression: if the ORF lacks a valid start site, this percentage indicates
  #  how far
  #    along the sequence Mikado should look for a good start site. Eg. with a value
  #  of 0.1,
  #    on a 300bp sequence with an open ORF Mikado would look for an alternative in\-frame
  #  start codon
  #    in the first 30 bps (10% of the cDNA).
  #  \- max_target_seqs: equivalently to BLAST, it indicates the maximum number of
  #  targets to keep
  #    per blasted sequence.
  #  \- discard_definition: Boolean. Used to indicate whether Mikado should use the
  #  definition
  #    rather than the ID for BLAST sequences. Necessary as in some instances BLAST
  #  XMLs will have
  #    a mock identifier rather than the original sequence ID (eg lcl|1). Default:
  #  false.
  #  \- procs: Number of processors to use. Default: 1.
  #  \- single_thread: if true, Mikado prepare will force the usage of a single thread
  #  in this step.
  discard_definition: false
  files:
    blast_targets:
    \- \(aq\(aq
    junctions: []
    log: serialise.log
    orfs:
    \- \(aq\(aq
    output_dir: .
    transcripts: mikado_prepared.fasta
    xml:
    \- \(aq\(aq
  force: false
  max_objects: 100000
  max_regression: 0
  max_target_seqs: 100000
  procs: 1
  single_thread: false
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
\fBHINT:\fP
.INDENT 0.0
.INDENT 3.5
The most expensive operation in a "Mikado serialise" run is by far the serialisation of the BLAST files. Splitting the input files in multiple chunks, and analysing them separately, allows Mikado to parallelise the analysis of the BLAST results. If a single monolythic XML/ASN file is produced, by contrast, Mikado will be quite slow as it will have to parse it all.
.UNINDENT
.UNINDENT
.SS Settings for the pick stage
.sp
This section of the configuration file deals with the picking stage of Mikado\&. It specifies details on how to handle BLAST and ORF data, which alternative splicing events are considered as valid during the final stages of the picking, and other important algorithmic details. The section comprises the following subsections:
.INDENT 0.0
.IP \(bu 2
alternative_splicing: Options related to which AS events are considered as valid for the primary transcript in a locus.
.IP \(bu 2
chimera_split: Options related to how to handle transcripts with multiple valid ORFs.
.IP \(bu 2
files: Input and output files.
.IP \(bu 2
orf_loading: Options related to how to decide which ORFs to load onto each transcript.
.IP \(bu 2
output_format: options related to how to format the names of the transcripts, the source field of the GFFs, etc.
.IP \(bu 2
run_options: Generic options related either to the general algorithm or to the number of resources requested.
.UNINDENT
.INDENT 0.0
.IP \(bu 2
scoring_file: This value specifies the scoring file to be used for Mikado. These can be found in Mikado.configuration.scoring_files.
.UNINDENT
.sp
\fBHINT:\fP
.INDENT 0.0
.INDENT 3.5
It is possible to ask for the configuration file to be copied in\-place for customisation when calling \fBmikado configure\fP\&.
.UNINDENT
.UNINDENT
.INDENT 0.0
.IP \(bu 2
source_score: in this section, it is possible to specify boni/mali to be assigned to specific labels. Eg, it might be possible to assign a bonus of 1 to any transcript coming from PacBio reads, or a malus to any transcript coming from a given assembler. Example of such a configuration:
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
    source_score:
        \- Cufflinks: 0
        \- Trinity: 0
        \- PacBio: 2
        \- Stringtie: 1
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
In this example, we asked Mikado to consider Stringtie transcripts as more trustworthy than the rest (1 additional point), and PacBio transcripts even more so (2 additional points).
.sp
Each subsection of the pick configuration will be explained in its own right.
.SS Parameters regarding the alternative splicing
.sp
After selecting the best model for each locus, Mikado will backtrack and try to select valid alternative splicing events. This section deals with how Mikado will operate the selection. There are the following available parameters:
.INDENT 0.0
.IP \(bu 2
report: boolean. Whether to calculate and report possible alternative splicing events at all. By default this is set to true; \fIsetting this parameter to false will inactivate all the options in this section\fP\&.
.IP \(bu 2
keep_retained_introns: boolean. It specifies whether transcripts with retained introns will be retained. A retained intron is defined as an exon at least partly non\-coding, whose non\-coding part falls within the intron of another transcript (so, retained intron events which yield a valid ORF will not be excluded). By default, such transcripts will be excluded.
.IP \(bu 2
max_fiveutr_length: maximum 5\(aq UTR length of any alternative splicing transcript. By default, this is set to 1Mbps, \fIde facto\fP inactivating this filter.
.IP \(bu 2
max_threeutr_length: maximum 3\(aq UTR length of any alternative splicing transcript. By default, this is set to 1Mbps, \fIde facto\fP inactivating this filter.
.IP \(bu 2
max_utr_length: maximum total UTR length of any alternative splicing transcript. By default, this is set to 1Mbps, \fIde facto\fP inactivating this filter.
.IP \(bu 2
min_cdna_overlap: minimum cDNA overlap between the primary transcript and the AS candidate. By default, this is set to 0 and we rely only on the class code and the CDS overlap. It must be a number between 0 and 1.
.IP \(bu 2
min_cds_overlap: minimum CDS overlap between the primary transcript and the AS candidate. By default this is set to 0.6, ie 60%. It must be a number between 0 and 1.
.IP \(bu 2
min_score_perc: Minimum percentage of the score of the primary transcript that any candidate AS must have to be considered. By default, this is set to 0.6 (60%). It must be a number between 0 and 1.
.IP \(bu 2
only_confirmed_introns: boolean. This parameter determines whether to consider only transcripts whose introns are confirmed \fI\%in the dataset of reliable junctions\fP, or whether to consider all possible candidate transcripts.
.IP \(bu 2
redundant_ccodes: any candidate AS will be compared against all the transcripts already retained in the locus. If any of these comparisons returns one of the class codes specified in this array, \fBthe transcript will be ignored\fP\&. Default class codes: =, _, m, c, n, C
.IP \(bu 2
valid_ccodes: any candidate AS will be compared against \fIthe primary transcript\fP to determine the type of AS event. If the class code is one of those specified in this array, the transcript will be considered further. Default class codes: j, J, g, G, h.
.UNINDENT
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
the AS transcript event does not need to be a valid AS event for \fIall\fP transcripts in the locus, only against the \fIprimary\fP transcript.
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
  #  \- scoring_file: a scoring file for the analysis. Default: plants.yaml.
  #  \- source_score: a dictionary with pre\-defined scores to assign to the transcripts
  #  according to their source. Eg all Cufflinks transcripts from the seed (label:
  #  "cuff_seed") could be assigned a default additional score of 1.
  alternative_splicing:
    #  Parameters related to alternative splicing reporting.
    #  \- report: whether to report at all or not the AS events.
    #  \- min_cds_overlap: minimum overlap between the CDS of the primary transcript
    #  and any AS event. Default: 60%.
    #  \- min_cdna_overlap: minimum overlap between the CDNA of the primary transcript
    #  and any AS event.
    #  Default: 0% i.e. disabled, we check for the CDS overlap.
    #  \- keep_retained_introns: Whether to consider as valid AS events where one intron
    #  is retained compared to the primary or any other valid AS. Default: false.
    #  \- max_isoforms: Maximum number of isoforms per locus. 1 implies no AS reported.
    #  Default: 3
    #  \- valid_ccodes: Valid class codes for AS events. See documentation for details.
    #  Choices:
    #  j, n, O, e, o, h, J, C, mo. Default: j, J, O, mo
    #  \- max_utr_length: Maximum length of the UTR for AS events. Default: 10e6 (i.e.
    #  no limit)
    #  \- max_fiveutr_length: Maximum length of the 5UTR for AS events. Default:
    #  10e6 (i.e. no limit)
    #  \- max_threeutr_length: Maximum length of the 5UTR for AS events. Default:
    #  10e6 (i.e. no limit)
    #  \- min_score_perc: Minimum score threshold for subsequent AS events.
    #   Only transcripts with a score at least (best) * value are retained.
    #  \- only_confirmed_introns: bring back AS events only when their introns are
    #  either
    #   present in the primary transcript or in the set of confirmed introns.
    keep_retained_introns: false
    max_fiveutr_length: 1000000
    max_isoforms: 3
    max_threeutr_length: 1000000
    max_utr_length: 1000000
    min_cdna_overlap: 0
    min_cds_overlap: 0.6
    min_score_perc: 0.6
    only_confirmed_introns: false
    redundant_ccodes:
    \- c
    \- m
    \- _
    \- \(aq=\(aq
    \- n
    \- C
    report: true
    valid_ccodes:
    \- j
    \- J
    \- G
    \- g
    \- h
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Parameters regarding assignment of ORFs to transcripts
.sp
This section of the configuration file deals with how to determine valid ORFs for a transcript from those present in the database. The parameters to control the behaviour of Mikado are the following:
.INDENT 0.0
.IP \(bu 2
\fIminimal_orf_length\fP: minimal length of the \fIprimary\fP ORF to be loaded onto the transcript. By default, this is set at 50 \fBbps\fP (not aminoacids)
.IP \(bu 2
\fIminimal_secondary_orf_length\fP: minimal length of any ORF that can be assigned to the transcript after the first. This value should be set at a \fBhigher setting\fP than minimal_orf_length, in order to avoid loading uORFs [uORFs] into the transcript, leading to \fI\%spurious break downs of the UTRs\fP\&. Default: 200 bps.
.IP \(bu 2
\fIstrand_specific\fP: boolean. If set to \fItrue\fP, only ORFs on the plus strand (ie the same of the cDNA) will be considered. If set to \fIfalse\fP, monoexonic transcripts mihgt have their strand flipped.
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
    orf_loading:
      #  Parameters related to ORF loading.
      #  \- minimal_secondary_orf_length: Minimum length of a *secondary* ORF
      #    to be loaded after the first, in bp. Default: 200 bps
      #  \- minimal_orf_length: Minimum length in bps of an ORF to be loaded,
      #    as the primary ORF, onto a transcript. Default: 50 bps
      #  \- strand_specific: Boolean flag. If set to true, monoexonic transcripts
      #    will not have their ORF reversed even if they would have an ORF on the opposite
      #  strand.
      minimal_orf_length: 50
      minimal_secondary_orf_length: 200
      strand_specific: true
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Parameters regarding splitting of chimeras
.sp
This section of the configuration file specifies how to deal with transcripts presenting multiple ORFs, ie \fBputative chimeras\fP (see the section above for parameters related to \fI\%which ORFs can be loaded\fP). Those are identified as transcripts with more than one ORF, where:
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
all the ORFs share the same strand
.IP \(bu 2
all the ORFs are non\-overlapping, ie they do not share any bp
.UNINDENT
.UNINDENT
.UNINDENT
.sp
In these situations, Mikado can try to deal with the chimeras in five different ways, in decreasingly conservative fashion:
.INDENT 0.0
.IP \(bu 2
\fInosplit\fP: leave the transcript unchanged. The presence of multiple ORFs will affect the scoring.
.IP \(bu 2
\fIstringent\fP: leave the transcript unchanged, unless the two ORFs both have hits in the protein database and none of the hits is in common.
.IP \(bu 2
\fIlenient\fP: leave the transcript unchanged, unless \fIeither\fP the two ORFs both have hits in the protein database, none of which is in common, \fIor\fP both have no hits in the protein database.
.IP \(bu 2
\fIpermissive\fP: presume the transcript is a chimera, and split it, \fIunless\fP two ORFs share a hit in the protein database.
.IP \(bu 2
\fIsplit\fP: presume that every transcript with more than one ORF is incorrect, and split them.
.UNINDENT
.sp
If any BLAST hit \fIspans\fP the two ORFs, then the model will be considered as a non\-chimera because there is evidence that the transcript constitutes a single unit. The only case when this information will be disregarded is during the execution of the \fIsplit\fP mode.
.sp
These modes can be controlled directly from the pick command line\&.
.sp
The behaviour, and when to trigger the check, is controlled by the following parameters:
.INDENT 0.0
.IP \(bu 2
\fIexecute\fP: boolean. If set to \fIfalse\fP, Mikado will operate in the \fInosplit\fP mode. If set to \fItrue\fP, the choice of the mode will be determined by the other parameters.
.IP \(bu 2
\fIblast_check\fP: boolean. Whether to execute the check on the BLAST hits. If set to \fIfalse\fP, Mikado will operate in the \fIsplit\fP mode, unless \fIexecute\fP is set to \fIfalse\fP (execute takes precedence over the other parameters).
.IP \(bu 2
.INDENT 2.0
.TP
.B \fIblast_params\fP: this section contains the settings relative to the \fIpermissive\fP, \fIlenient\fP and \fIstringent\fP mode.
.INDENT 7.0
.IP \(bu 2
\fIevalue\fP: maximum evalue of a hit to be assigned to the transcript and therefore be considered.
.IP \(bu 2
\fIhsp_evalue\fP: maximum evalue of a hsp inside a hit to be considered for the analysis.
.IP \(bu 2
\fIleniency\fP: one of \fBLENIENT, PERMISSIVE, STRINGENT\fP\&. See above for definitions.
.IP \(bu 2
\fImax_target_seqs\fP: integer. when loading BLAST hits from the database, only the first N will be considered for analysis.
.IP \(bu 2
\fIminimal_hsp_overlap\fP: number between 0 and 1. This indicates the overlap that must exist between the HSP and the ORF for the former to be considered for the split.
.UNINDENT
.INDENT 7.0
.IP \(bu 2
\fImin_overlap_duplication\fP: in the case of tandem duplicated genes, a chimera will have two ORFs that share the same hits, but possibly in a peculiar way \- the HSPs will insist on the same region of the \fItarget\fP sequence. This parameter controls how much overlap counts as a duplication. The default value is of 0.9 (90%).
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
    chimera_split:
      #  Parameters related to the splitting of transcripts in the presence of
      #  two or more ORFs. Parameters:
      #  \- execute: whether to split multi\-ORF transcripts at all. Boolean.
      #  \- blast_check: whether to use BLAST information to take a decision. See blast_params
      #  for details.
      #  \- blast_params: Parameters related to which BLAST data we want to analyse.
      blast_check: true
      blast_params:
        #  Parameters for the BLAST check prior to splitting.
        #  \- evalue: Minimum evalue for the whole hit. Default: 1e\-6
        #  \- hsp_evalue: Minimum evalue for any HSP hit (some might be discarded even
        #  if the whole hit is valid). Default: 1e\-6
        #  \- leniency: One of STRINGENT, LENIENT, PERMISSIVE. Default: LENIENT
        #  \- max_target_seqs: maximum number of hits to consider. Default: 3
        #  \- minimal_hsp_overlap: minimum overlap of the ORF with the HSP (*not* reciprocal).
        #  Default: 0.8, i.e. 80%
        #  \- min_overlap_duplication: minimum overlap (in %) for two ORFs to consider
        #  them as target duplications.
        #    This means that if two ORFs have no HSPs in common, but the coverage of
        #  their disjoint HSPs covers more
        #    Than this % of the length of the *target*, they represent most probably
        #  a duplicated gene.
        evalue: 1.0e\-06
        hsp_evalue: 1.0e\-06
        leniency: LENIENT
        max_target_seqs: 3
        min_overlap_duplication: 0.8
        minimal_hsp_overlap: 0.9
      execute: true
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Parameters regarding input and output files
.sp
The "files" and "output_format" sections deal respectively with input files for the pick stage and with some basic settings for the GFF output. Options:
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
\fIinput\fP:
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
   files:
     #  Input and output files for Mikado pick.
     #  \- gff: input GTF/GFF3 file. Default: mikado_prepared.gtf
     #  \- loci_out: output GFF3 file from Mikado pick. Default: mikado.loci.gff3
     #  \- subloci_out: optional GFF file with the intermediate subloci. Default: no
     #  output
     #  \- monoloci_out: optional GFF file with the intermediate monoloci. Default:
     #  no output
     #  \- log: log file for this step.
     input: mikado_prepared.gtf
     loci_out: mikado.loci.gff3
     log: mikado_pick.log
     monoloci_out: \(aq\(aq
     output_dir: .
     subloci_out: \(aq\(aq
   output_format:
     #  Parameters related to the output format.
     #    \- source: prefix for the source field in the mikado output.
     #    \- id_prefix: prefix for the ID of the genes/transcripts in the output
     id_prefix: mikado
     report_all_orfs: false
     source: Mikado
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Generic parameters on the pick run
.sp
This section deals with other parameters necessary for the run, such as the number of processors to use, but also more important algorithmic parameters such as how to recognise fragments.
Parameters:
.INDENT 0.0
.IP \(bu 2
\fIexclude_cds\fP: whether to remove CDS/UTR information from the Mikado output. Default: \fIfalse\fP\&.
.IP \(bu 2
\fIflank\fP: when creating superloci, Mikado will gather together all groups of overlapping transcripts that are within this distance. By default, this is set at 1 kbp. This parameter is important to recognize fragments derived from UTRs or misfired transcription in the neighborhood of real transcripts.
.IP \(bu 2
\fIfragments_maximal_cds\fP: during the last control on fragments, Mikado will consider as non\-fragmentary any transcript with an ORF of at least this value in bps. By default, this is set to 100, ie any transcript with an ORF of 33 AA or more will be considered by default as valid.
.IP \(bu 2
\fIfragments_maximal_exons\fP: in addition, any transcript with more than this number of exons will be considered as non\-fragmentary by definition. By default, this parameter is set at 2, ie any transcript with 3 or more exons will be considered non\-fragmentary by definition.
.IP \(bu 2
\fIintron_range\fP: tuple that indicates the range of lengths in which most introns should fall. Transcripts with introns either shorter or longer than this interval will be potentially penalised, depending on the scoring scheme. For the paper, this parameter was set to a tuple of integers in which \fI98%\fP of the introns of the reference annotation were falling (ie cutting out the 1st and 99th percentiles).
.IP \(bu 2
\fIpreload\fP: boolean. In certain cases, ie when the database is quite small, it might make sense to preload it in memory rather than relying on SQL queries. Set to \fIfalse\fP by default.
.IP \(bu 2
\fIshm\fP: boolean. In certain cases, especially when disk access is a severely limiting factor, it might make sense to copy a SQLite database into RAM before querying. If this parameter is set to \fItrue\fP, Mikado will copy the SQLite database into a temporary file in RAM, and query it from there.
.IP \(bu 2
\fIshm_db\fP: string. If \fIshm\fP is set to true and this string is non\-empty, Mikado will copy the database in memory to a file with this name \fIand leave it there for other Mikado runs\fP\&. The file will have to be removed manually.
.IP \(bu 2
\fIprocs\fP: number of processors to use. Default: 1.
.IP \(bu 2
\fIsingle_thread\fP: boolean. If set to true, Mikado will completely disable multiprocessing. Useful mostly for debugging reasons.
.IP \(bu 2
\fIsubloci_from_cds_only\fP: boolean. If set to true, subloci will be built only using CDS information \- therefore, transcripts with overlapping cDNA but discrete CDSs will be analysed separately. Most useful in cases of \fBcompact\fP genomes, where genes lie near and it might be possible to analyse them together as the UTRs are overlapping.
.UNINDENT
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
the shared\-memory options are available only on Linux platforms.
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
pick:
   run_options:
     #  Generic run options.
     #  \- shm: boolean flag. If set and the DB is sqlite, it will be copied onto the
     #  /dev/shm faux partition
     #  \- shm_db: String. It indicates a DB that has to be copied onto SHM and left
     #  there for
     #    concurrent Mikado runs.
     #  \- shm_shared: boolean flag. If set, the database loaded onto SHM will be shared
     #  and should not be
     #    deleted at the end of the run (see shm_db).
     #    for faster access. Default: false
     #  \- exclude_cds: boolean flag. If set, the CDS information will not be printed
     #  in Mikado output. Default: false
     #  \- purge: boolean flag. If set, all loci where all transcripts have a score
     #  of 0 will be excluded
     #    from the output. Default: false
     #  \- remove_overlapping_fragments: boolean flag. If set, fragments (defined as
     #  monoexonic loci
     #    classified as P,x,i or p compared to another locus, will be removed from
     #  the output.
     #  \- fragments_maximal_cds: a locus will never be considered a fragment if its
     #  longest CDS is over
     #    this length. Default: 100 bps.
     #  \- fragments_maximal_exons: a locus will never be considered a fragment if its
     #  representative transcript
     #    has more than this number of exons. Default: 2
     #  \- procs: number of processes to use. Default: 1
     #  \- preload: boolean flag. If set, the whole database will be preloaded into
     #  memory for faster access. Useful when
     #    using SQLite databases.
     #  \- single_thread: boolean flag. If set, multithreading will be disabled \- useful
     #  for profiling and debugging.
     exclude_cds: false
     flank: 1000
     fragments_maximal_cds: 100
     fragments_maximal_exons: 2
     intron_range:
     \- 60
     \- 900
     preload: false
     procs: 1
     purge: false
     remove_overlapping_fragments: true
     shm: false
     shm_db: \(aq\(aq
     single_thread: false
     subloci_from_cds_only: false
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Miscellanea
.SS "Python, multiprocessing, and cluster schedulers"
.sp
Some schedulers, in particular SLURM, are not capable to understand that the processes \fIforked\fP by Python are still sharing the same memory with the main process, and think instead that each process is using that memory in isolation. As a result, they might think that the Mikado process is using its memory multiplied by the number of processes \- depending on when the forking happens \- and therefore shut down the program as it \fIappears\fP to be using much more memory than needed. For this reason, Daijin forces Mikado to run in \fBspawn\fP mode. Although spawning is slower than forking, it happens only once per run, and it has therefore a limited cost in terms of runtime \- while greatly reducing the chances of the program being shut down because of "Out of memory" reasons.
.sp
It is possible to set high\-level settings for the logs in the \fBlog_settings\fP section:
.INDENT 0.0
.IP \(bu 2
log_level: level of the logging for Mikado. Options: \fIDEBUG, INFO, WARNING, ERROR, CRITICAL\fP\&. By default, Mikado will be quiet and output log messages of severity \fIWARNING\fP or greater.
.IP \(bu 2
sql_level: level of the logging for messages regarding the database connection (through \fI\%SQLAlchemy\fP). By default, SQLAlchemy will be set in quiet mode and asked to output only messages of severity \fIWARNING\fP or greater.
.UNINDENT
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
Mikado and SQLAlchemy can be greatly verbose if asked to output \fIDEBUG\fP or \fIINFO\fP messages, to the point of slowing down the program significantly due to the amount of writing to disk. Please consider setting the level to \fIDEBUG\fP only when there is a real problem to debug, not otherwise!
.UNINDENT
.UNINDENT
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
log_settings:
  #  Settings related to the logs. Keys:
  #  \- sql_level: verbosity for SQL calls. Default: WARNING.
  #    In decreasing order: DEBUG, INFO, WARNING, ERROR, CRITICAL
  #  \- log_level: verbosity. Default: WARNING.
  #    In decreasing order: DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_level: WARNING
  sql_level: WARNING
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
It is also possible to set the type of multiprocessing method that should be used by Python3. The possible choices are "fork", "spawn", and "fork\-server".
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
multiprocessing_method: spawn
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Technical details
.sp
The configuration file obeys a specific JSON schema which can be found at \fBMikado/configuration/configuration_blueprint.json\fP\&. Every time a Mikado utility is launched, it checks the configuration file against the schema to validate it. The schema contains non\-standard "Comment" and "SimpleComment" string arrays which are used at runtime to generate the comment strings in the YAML output.
.SS Mikado prepare
.sp
This is the first executive step of the Mikado pipeline. It will accomplish the following goals:
.INDENT 0.0
.IP 1. 3
Collect annotations from disparate annotation files
.IP 2. 3
Remove redundant assemblies, ie, assemblies that are \fIidentical\fP across the various input files.
.IP 3. 3
Determine the strand of the transcript junctions
.IP 4. 3
Ensure uniqueness of the transcript names
.IP 5. 3
Order the transcript by locus
.IP 6. 3
Extract the transcript sequences.
.UNINDENT
.SS Usage
.sp
\fBMikado prepare\fP allows to override some of the parameters present in the configuration file through command line options, eg the input files. Notwithstanding, in the interest of reproducibility we advise to configure everything through the configuration file and supply it to Mikado prepare without further modifications.
.sp
Available parameters:
.INDENT 0.0
.IP \(bu 2
\fIjson\-conf\fP: the most important parameter. This is the configuration file created through Mikado configure\&.
.IP \(bu 2
\fIfasta\fP: reference genome. Required, either through the command line or through the configuration file.
.IP \(bu 2
\fIout\fP: Output GTF file, with the collapsed transcripts.
.IP \(bu 2
\fIout_fasta\fP: Output FASTA file of the collapsed transcripts.
.IP \(bu 2
\fIstart\-method\fP: multiprocessing start method\&.
.IP \(bu 2
\fIverbose\fP, \fIquiet\fP: flags to set the verbosity of Mikado prepare. It is generally not advised to turn the verbose mode on, unless there is a problem to debug, given the verbosity of the output.
.IP \(bu 2
\fIstrand\-specific\fP: If set, all assemblies will be treated as strand\-specific.
.IP \(bu 2
\fIstrand\-specific\-assemblies\fP: comma\-separated list of strand specific assemblies.
.IP \(bu 2
.INDENT 2.0
.TP
.B \fIlist\fP: in alternative to specifying all the information on the command line, it is possible to give to Mikado a \fItab\-separated\fP file with the following contents:
.INDENT 7.0
.IP 1. 3
Location of the file
.IP 2. 3
label for the file
.IP 3. 3
whether that assembly is strand\-specific or not (write True/False)
.IP 4. 3
Optionally, a bonus/malus to be associated to transcripts coming from that assembly.
.UNINDENT
.UNINDENT
.IP \(bu 2
\fIlog\fP: log file. Optional, by default Mikado will print to standard error.
.IP \(bu 2
\fIlenient\fP: flag. If set, transcripts without any canonical splice site will be output as well. By default, they would be discarded.
.IP \(bu 2
\fIsingle\fP: flag that disables multiprocessing. Mostly useful for debug purposes.
.IP \(bu 2
\fIstrip\-cds\fP: some aligners (eg GMAP) will try calculate a CDS on the fly for alignments. Use this flag to discard such CDS sections and retain only the cDNA information.
.IP \(bu 2
\fIminimum_length\fP: minimum length of the transcripts to be kept.
.UNINDENT
.sp
Command line usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado prepare \-\-help
usage: Mikado prepare [\-h] [\-\-fasta FASTA] [\-v | \-q]
                      [\-\-start\-method {fork,spawn,forkserver}]
                      [\-s | \-sa STRAND_SPECIFIC_ASSEMBLIES] [\-\-list LIST]
                      [\-l LOG] [\-\-lenient] [\-m MINIMUM_LENGTH] [\-p PROCS]
                      [\-scds] [\-\-labels LABELS] [\-\-single] [\-od OUTPUT_DIR]
                      [\-o OUT] [\-of OUT_FASTA] [\-\-json\-conf JSON_CONF]
                      [gff [gff ...]]

Mikado prepare analyses an input GTF file and prepares it for the picking
analysis by sorting its transcripts and performing some simple consistency
checks.

positional arguments:
  gff                   Input GFF/GTF file(s).

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-fasta FASTA         Genome FASTA file. Required.
  \-v, \-\-verbose
  \-q, \-\-quiet
  \-\-start\-method {fork,spawn,forkserver}
                        Multiprocessing start method.
  \-s, \-\-strand\-specific
                        Flag. If set, monoexonic transcripts will be left on
                        their strand rather than being moved to the unknown
                        strand.
  \-sa STRAND_SPECIFIC_ASSEMBLIES, \-\-strand\-specific\-assemblies STRAND_SPECIFIC_ASSEMBLIES
                        Comma\-delimited list of strand specific assemblies.
  \-\-list LIST           Tab\-delimited file containing rows with the following
                        format <file> <label> <strandedness>
  \-l LOG, \-\-log LOG     Log file. Optional.
  \-\-lenient             Flag. If set, transcripts with only non\-canonical
                        splices will be output as well.
  \-m MINIMUM_LENGTH, \-\-minimum_length MINIMUM_LENGTH
                        Minimum length for transcripts. Default: 200 bps.
  \-p PROCS, \-\-procs PROCS
                        Number of processors to use (default 1)
  \-scds, \-\-strip_cds    Boolean flag. If set, ignores any CDS/UTR segment.
  \-\-labels LABELS       Labels to attach to the IDs of the transcripts of the
                        input files, separated by comma.
  \-\-single              Disable multi\-threading. Useful for debugging.
  \-od OUTPUT_DIR, \-\-output\-dir OUTPUT_DIR
                        Output directory. Default: current working directory
  \-o OUT, \-\-out OUT     Output file. Default: mikado_prepared.gtf.
  \-of OUT_FASTA, \-\-out_fasta OUT_FASTA
                        Output file. Default: mikado_prepared.fasta.
  \-\-json\-conf JSON_CONF
                        Configuration file.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Collection of transcripts from the annotation files
.sp
Different assemblers will produce data in different formats, typically in GFF or GTF format, and not necessarily in the same order (if any is present). Mikado will serialise the transcripts from these files and port them all into a standard GTF format. Moreover, it will ensure that each transcript ID appears only once across the input files. The optional labels provided for each file will be attached to the transcript names as prefixes, and used as the source field in the output GTF, to ensure the uniqueness of each transcript name.
If two or more transcripts are found to be identical, only one will be retained, chosen at random among all the possibilities.
In addition to this, Mikado prepare will also sort the transcripts by coordinate, irrespective of strand, so that they are suitably displayed for the divide\-et\-impera algorithm of Mikado pick\&.
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
To be considered \fIidentical\fP, two transcripts must match down to the last base pair. A simple match or containment of the intron chain will not suffice. This is because using the cDNA data alone it is difficult to understand whether the longer form(s) is the correct assembly rather than a chimera or a trans\-splice event.
.UNINDENT
.UNINDENT
.SS Check on strand correctness
.sp
During its run, Mikado prepare will also check the correctness of the transcripts. In particular:
.INDENT 0.0
.IP \(bu 2
Unless the assembly is marked as strand\-specific, any monoexonic transcript will have its strand \fIremoved\fP\&.
.IP \(bu 2
If a transcript contains canonical splice junctions on \fBboth\fP strands, it will be completely removed
.IP \(bu 2
If a transcript contains only non\-canonical splice junctions, it will be removed \fIunless\fP the "lenient" option is specified either at the command line or in the configuration file.
.UNINDENT
.sp
The couples of splice acceptors and donors which are considered as canonical can be specified in the configuration file\&. By default, Mikado will consider as canonical both properly canonical splicing event (GT\-AG) as well as the semi\-canonical events (GC\-AG, AT\-AC). Any other couple will be considered as non\-canonical.
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
Mikado will check the strand of each junction inside a transcript \fIindependently\fP\&. Therefore, if a transcript with 9 junctions on the plus strand is found to have a non\-canonical splicing junction \fBwhich happens to be the reverse of a canonical one\fP (eg. CT\-AC), it will deem this junction as misassigned to the wrong strand and flip it to the minus strand. In this example, the transcript will therefore be \fBconsidered as an error\fP as it contains both + and \- junctions, and discarded.
.UNINDENT
.UNINDENT
.SS Output files
.sp
Mikado prepare will produce two files:
.INDENT 0.0
.IP \(bu 2
a \fIsorted\fP GTF file, containing all the transcripts surviving the checks
.IP \(bu 2
a FASTA file of the transcripts, in the proper cDNA orientation.
.UNINDENT
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
contrary to other tools such as eg gffread from Cufflinks [Cufflinks], Mikado prepare will \fBnot\fP try to calculate the loci for the transcripts. This task will be performed later in the pipeline. As such, the GTF file is formally incorrect, as multiple transcripts in the same locus but coming from different assemblies will \fInot\fP have the same gene_id but rather will have kept their original one. Moreover, if two gene_ids were identical but discrete in the input files (ie located on different sections of the genome), this error will not be corrected. If you desire to use this GTF file for any purpose, please use a tool like gffread to calculate the loci appropriately.
.UNINDENT
.UNINDENT
.SS Mikado serialise
.sp
Mikado integrates data from multiple sources to select the best transcripts. During this step, these sources are brought together inside a common database, simplifying the process of retrieving them at runtime. Currently, Mikado integrates three different types of data:
.SS \fI\%BED12\fP files
.sp
During serialisation, Mikado interprets BED12 files as having the relevant information in the \fBthick\-start\fP, \fBthick\-end\fP fields, ie columns 7 and 8. For ORF files, this means that the CDS should start at the 7th column and end at the 8th (stop\-codon exclusive, like in \fI\%TransDecoder\fP) \- or viceversa for ORFs on the negative strand. For junction files, it means that the reliable junction, ie the reliable \fIintron\fP, starts at the thick\-start position and ends at the thick\-end position. This format requirement is the opposite of what happens for example in the junctions produced by \fI\%TopHat\fP, where the BED12 file lists the two \fIexonic\fP fragments, rather than the intron. \fI\%STAR\fP instead provides a tabular non\-standard file indicating the most reliable junctions in the alignment. \fI\%Portcullis\fP provides utilities to convert such files into the format used by Mikado, and to merge together multiple junction files. However, we recommend running Portcullis directly on the alignments, rather than using the junctions indicated by the programs themselves.
.INDENT 0.0
.IP 1. 3
reliable junctions, as detected by \fI\%Portcullis\fP, in \fI\%BED12\fP format (
.IP 2. 3
ORF data, currently identified using \fI\%TransDecoder\fP, but any program capable of generating it in \fI\%BED12\fP format is suitable.
.IP 3. 3
BLASTX [Blastplus] data in XML format
.UNINDENT
.sp
After serialisation in the database, these sources will be available to use for any subsequent Mikado pick run. Having the data present in the database allows to run Mikado with multiple configurations and little overhead in terms of pre\-loading data; this feature is taken directly advtange of in Daijin, where it is possible to run Mikado using multiple modes.
.sp
Mikado serialise can use three different SQL databases as backends \- SQLite, MySQL and PostgreSQL \- thanks to \fI\%SQLAlchemy\fP\&.
This step, together with the creation of the TransDecoder and BLAST data, is the most time consuming of the pipeline. In particular, although Mikado serialise will try to analyse the XML data in a parallelised fashion if so instructed, the insertion of the data in the database will still happen in a single thread and will therefore be of limited speed. If using SQLite as database (the default option), it is possible to decrease the runtime by modifying the "max_objects" parameters, at the cost however of increased RAM usage.
.SS Transdecoder ORFs
.sp
When Mikado analyses ORFs produced by \fI\%TransDecoder\fP or equivalent program, it performs additionally the following checks:
.INDENT 0.0
.IP 1. 3
Check the congruence between the length of the transcript in the BED12 file and that found in the FASTA file
.IP 2. 3
Check that the ORF does not contain internal stop codons
.IP 3. 3
Check that the CDS length is valid, ie a multiple of 3, if the ORF is complete
.IP 4. 3
Optionally, if the ORF is open on the 5\(aq side, Mikado can try to find an internal start codon. See :\fIthis section <max\-regression>\fP for details.
.UNINDENT
.SS Usage
.sp
\fBmikado serialise\fP allows to override some of the parameters present in the configuration file through command line options, eg the input files. Notwithstanding, in the interest of reproducibility we advise to configure everything through the configuration file and supply it to Mikado prepare without further modifications.
.sp
Available parameters:
.INDENT 0.0
.IP \(bu 2
.INDENT 2.0
.TP
.B Parameters related to performance:
.INDENT 7.0
.IP \(bu 2
\fIstart\-method\fP: one of fork, spawn, forkserver. It determines the multiprocessing start method. By default, Mikado will use the default for the system (fork on UNIX, spawn on Windows).
.IP \(bu 2
\fIprocs\fP: Number of processors to use.
.IP \(bu 2
\fIsingle\-thread\fP: flag. If set, Mikado will disable all multithreading.
.IP \(bu 2
\fImax_objects\fP: Maximum number of objects to keep in memory before committing to the database. See this section of the configuration for details.
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B Basic input data and settings:
.INDENT 7.0
.IP \(bu 2
\fIoutput\-dir\fP: directory where the SQLite database and the log will be written to.
.IP \(bu 2
\fItranscripts\fP: these are the input transcripts that are present on the GTF file considered by Mikado. Normally this should be the output of Mikado prepare.
.IP \(bu 2
\fIgenome_fai\fP: FAIDX file of the genome FASTA. If not given, serialise will derive it from the "reference: genome" field of the configuration.
.IP \(bu 2
\fIforce\fP: flag. If set, and the database is already present, it will be truncated rather than updated.
.IP \(bu 2
\fBjson\-conf\fP: this is the configuration file created with Mikado configure\&.
.IP \(bu 2
\fIdb\fP: if the database is specified on the command line, \fBmikado serialise\fP will interpret it as a \fBSQLite\fP database. This will overwrite any setting present in the configuration file.
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B Parameters related to logging:
.INDENT 7.0
.IP \(bu 2
\fIlog\fP: log file. It defaults to \fBserialise.log\fP\&.
.IP \(bu 2
\fIlog_level\fP: verbosity of the logging. Please be advised that excessive verbosity can negatively impact the performance of the program \- the debug mode is extremely verbose.
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B Parameters related to reliable junctions:
.INDENT 7.0
.IP \(bu 2
\fIjunctions\fP: a \fI\%BED12\fP file of reliable junctions. This can be obtained using \fI\%Portcullis\fP\&. Please see the relative \fI\%sidebar\fP\&.
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B Parameters related to the treatment of ORF data:
.INDENT 7.0
.IP \(bu 2
\fIorfs\fP: ORF BED12 files, separated by comma.
.IP \(bu 2
\fImax\-regression\fP: A percentage, expressed as a number between 0 and 1, which indicates how far can Mikado regress along the ORF to find a valid start codon. See the relative section in the configuration for details.
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B Parameters related to BLAST data:
.INDENT 7.0
.IP \(bu 2
\fIblast_targets\fP: BLAST FASTA database.
.IP \(bu 2
\fIdiscard\-definition\fP: Flag. Depending on how the database has been created, sometimes BLAST will substitute the ID of the sequence with "lcl|" ids. Mikado circumvents this by looking for the definition field in the XML file. Using this flag will disable this behaviour and force Mikado to use the ID \- with the potential of having a mismatch between the sequences in the BLAST DB and the sequences in the BLAST files.
.IP \(bu 2
.INDENT 2.0
.TP
.B \fIxml\fP: BLAST files to parse. This can be one of the following:
.INDENT 7.0
.IP \(bu 2
A list of XML BLAST files, optionally compressed with GZip or BZip2, comma separated (suffix .xml)
.IP \(bu 2
A list of ASN BLAST files, optionally compressed with GZip or BZip2, comma separated (suffix .asn)
.IP \(bu 2
A list of folders, comma separated, where it is possible to find files of the former 2 types
.IP \(bu 2
A mixture of the three above types.
.UNINDENT
.UNINDENT
.IP \(bu 2
\fImax\-target\-seqs\fP: maximum number of BLAST targets that can be loaded per sequence, for each BLAST alignment. Please note that if you align against multiple databases, this threshold will be applied once per file.
.UNINDENT
.UNINDENT
.UNINDENT
.sp
\fBHINT:\fP
.INDENT 0.0
.INDENT 3.5
Mikado will parallelise only the reading of multiple XML files. As such, this part of the pipeline is less performing than the other steps.
.UNINDENT
.UNINDENT
.sp
\fBWARNING:\fP
.INDENT 0.0
.INDENT 3.5
It is advised to set this parameter to \fIspawn\fP even on UNIX. See the dedicated sidebar for details\&.
.UNINDENT
.UNINDENT
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado serialise \-\-help
usage: Mikado serialise [\-h] [\-\-start\-method {fork,spawn,forkserver}]
                        [\-\-orfs ORFS] [\-\-transcripts TRANSCRIPTS]
                        [\-mr MAX_REGRESSION]
                        [\-\-max_target_seqs MAX_TARGET_SEQS]
                        [\-\-blast_targets BLAST_TARGETS] [\-\-discard\-definition]
                        [\-\-xml XML] [\-p PROCS] [\-\-single\-thread]
                        [\-\-genome_fai GENOME_FAI] [\-\-junctions JUNCTIONS]
                        [\-mo MAX_OBJECTS] [\-f] \-\-json\-conf JSON_CONF
                        [\-l [LOG]] [\-od OUTPUT_DIR]
                        [\-lv {DEBUG,INFO,WARN,ERROR}]
                        [db]

Mikado serialise creates the database used by the pick program. It handles
Junction and ORF BED12 files as well as BLAST XML results.

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-start\-method {fork,spawn,forkserver}
                        Multiprocessing start method.
  \-od OUTPUT_DIR, \-\-output\-dir OUTPUT_DIR
                        Output directory. Default: current working directory

  \-\-orfs ORFS           ORF BED file(s), separated by commas
  \-\-transcripts TRANSCRIPTS
                        Transcript FASTA file(s) used for ORF calling and
                        BLAST queries, separated by commas. If multiple files
                        are given, they must be in the same order of the ORF
                        files. E.g. valid command lines are:
                        \-\-transcript_fasta all_seqs1.fasta \-\-orfs all_orfs.bed
                        \-\-transcript_fasta seq1.fasta,seq2.fasta \-\-orfs
                        orfs1.bed,orf2.bed \-\-transcript_fasta all_seqs.fasta
                        \-\-orfs orfs1.bed,orf2.bed These are invalid instead: #
                        Inverted order \-\-transcript_fasta
                        seq1.fasta,seq2.fasta \-\-orfs orfs2.bed,orf1.bed #Two
                        transcript files, one ORF file \-\-transcript_fasta
                        seq1.fasta,seq2.fasta \-\-orfs all_orfs.bed
  \-mr MAX_REGRESSION, \-\-max\-regression MAX_REGRESSION
                        "Amount of sequence in the ORF (in %) to backtrack in
                        order to find a valid START codon, if one is absent.
                        Default: None

  \-\-max_target_seqs MAX_TARGET_SEQS
                        Maximum number of target sequences.
  \-\-blast_targets BLAST_TARGETS
                        Target sequences
  \-\-discard\-definition  Flag. If set, the sequences IDs instead of their
                        definition will be used for serialisation.
  \-\-xml XML             XML file(s) to parse. They can be provided in three
                        ways: \- a comma\-separated list \- as a base folder \-
                        using bash\-like name expansion (*,?, etc.). In this
                        case, you have to enclose the filename pattern in
                        double quotes. Multiple folders/file patterns can be
                        given, separated by a comma.
  \-p PROCS, \-\-procs PROCS
                        Number of threads to use for analysing the BLAST
                        files. This number should not be higher than the total
                        number of XML files.
  \-\-single\-thread       Force serialise to run with a single thread,
                        irrespective of other configuration options.

  \-\-genome_fai GENOME_FAI
  \-\-junctions JUNCTIONS

  \-mo MAX_OBJECTS, \-\-max\-objects MAX_OBJECTS
                        Maximum number of objects to cache in memory before
                        committing to the database. Default: 100,000 i.e.
                        approximately 450MB RAM usage for Drosophila.
  \-f, \-\-force           Flag. If set, an existing databse will be deleted
                        (sqlite) or dropped (MySQL/PostGreSQL) before
                        beginning the serialisation.
  \-\-json\-conf JSON_CONF
  \-l [LOG], \-\-log [LOG]
                        Optional log file. Default: stderr
  \-lv {DEBUG,INFO,WARN,ERROR}, \-\-log_level {DEBUG,INFO,WARN,ERROR}
                        Log level. Default: INFO
  db                    Optional output database. Default: derived from
                        json_conf
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Technical details
.sp
The schema of the database is quite simple, as it is composed only of 7 discrete tables in two groups. The first group, \fIchrom\fP and \fIjunctions\fP, serialises the information pertaining to the reliable junctions \- ie information which is not relative to the transcripts but rather to their genomic locations.
The second group serialises the data regarding ORFs and BLAST files. The need of using a database is mainly driven by the latter, as querying a relational database is faster than retrieving the information from the XML files themselves at runtime.
.SS Database schema used by Mikado.
.INDENT 0.0
.INDENT 2.5
[image]
.UNINDENT
.UNINDENT
.SS Mikado pick
.sp
This is the final stage of the pipeline, and the one which actually applies the Mikado algorithm to identify the loci and select the best transcripts.
.SS Usage
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado pick \-\-help
usage: Mikado pick [\-h] [\-\-start\-method {fork,spawn,forkserver}] [\-p PROCS]
                   \-\-json\-conf JSON_CONF [\-i INTRON_RANGE INTRON_RANGE]
                   [\-\-subloci_out SUBLOCI_OUT] [\-\-monoloci_out MONOLOCI_OUT]
                   [\-\-loci_out LOCI_OUT] [\-\-prefix PREFIX] [\-\-no_cds]
                   [\-\-source SOURCE] [\-\-flank FLANK] [\-\-purge] [\-shm]
                   [\-shmdb SHM_DB] [\-\-preload] [\-db SQLITE_DB]
                   [\-od OUTPUT_DIR] [\-\-single] [\-l LOG] [\-v | \-nv]
                   [\-lv {DEBUG,INFO,WARN,ERROR,CRITICAL}]
                   [\-\-mode {nosplit,stringent,lenient,permissive,split}]
                   [gff]

Mikado pick analyses a sorted GTF/GFF files in order to identify its loci and
choose the best transcripts according to user\-specified criteria. It is
dependent on files produced by the "prepare" and "serialise" components.

positional arguments:
  gff

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-start\-method {fork,spawn,forkserver}
                        Multiprocessing start method. (default: None)
  \-p PROCS, \-\-procs PROCS
                        Number of processors to use. Default: look in the
                        configuration file (1 if undefined) (default: None)
  \-\-json\-conf JSON_CONF
                        JSON/YAML configuration file for scoring transcripts.
                        (default: None)
  \-i INTRON_RANGE INTRON_RANGE, \-\-intron\-range INTRON_RANGE INTRON_RANGE
                        Range into which intron lengths should fall, as a
                        couple of integers. Transcripts with intron lengths
                        outside of this range will be penalised. Default: (60,
                        900) (default: None)
  \-\-subloci_out SUBLOCI_OUT
  \-\-monoloci_out MONOLOCI_OUT
  \-\-loci_out LOCI_OUT   This output file is mandatory. If it is not specified
                        in the configuration file, it must be provided here.
                        (default: None)
  \-\-prefix PREFIX       Prefix for the genes. Default: Mikado (default: None)
  \-\-no_cds              Flag. If set, not CDS information will be printed out
                        in the GFF output files. (default: None)
  \-\-source SOURCE       Source field to use for the output files. (default:
                        None)
  \-\-flank FLANK         Flanking distance (in bps) to group non\-overlapping
                        transcripts into a single superlocus. Default:
                        determined by the configuration file. (default: None)
  \-\-purge               Flag. If set, the pipeline will suppress any loci
                        whose transcripts do not pass the requirements set in
                        the JSON file. (default: False)
  \-shm, \-\-shared\-memory
                        Flag. If set, the DB will be copied into memory.
                        (default: False)
  \-shmdb SHM_DB, \-\-shared\-memory\-db SHM_DB
                        Name of the shared memory DB. WARNING: if set, the DB
                        copy will be persistently copied into memory, so that
                        multiple pickers can share. (default: None)
  \-\-preload             Flag. If set, the Mikado DB will be pre\-loaded into
                        memory for faster access. WARNING: this option will
                        increase memory usage and the preloading might be
                        quite slow. (default: False)
  \-db SQLITE_DB, \-\-sqlite\-db SQLITE_DB
                        Location of an SQLite database to overwrite what is
                        specified in the configuration file. (default: None)
  \-od OUTPUT_DIR, \-\-output\-dir OUTPUT_DIR
                        Output directory. Default: current working directory
                        (default: None)
  \-\-single              Flag. If set, Creator will be launched with a single
                        process. Useful for debugging purposes only. (default:
                        False)
  \-\-mode {nosplit,stringent,lenient,permissive,split}
                        Mode in which Mikado will treat transcripts with
                        multiple ORFs. \- nosplit: keep the transcripts whole.
                        \- stringent: split multi\-orf transcripts if two
                        consecutive ORFs have both BLAST hits and none of
                        those hits is against the same target. \- lenient:
                        split multi\-orf transcripts as in stringent, and
                        additionally, also when either of the ORFs lacks a
                        BLAST hit (but not both). \- permissive: like lenient,
                        but also split when both ORFs lack BLAST hits \- split:
                        split multi\-orf transcripts regardless of what BLAST
                        data is available. (default: None)

Log options:
  \-l LOG, \-\-log LOG     File to write the log to. Default: decided by the
                        configuration file. (default: None)
  \-v, \-\-verbose         Flag. If set, the debug mode will be activated.
                        (default: False)
  \-nv, \-\-noverbose      Flag. If set, the log will report only errors and
                        critical events. (default: False)
  \-lv {DEBUG,INFO,WARN,ERROR,CRITICAL}, \-\-log\-level {DEBUG,INFO,WARN,ERROR,CRITICAL}
                        Logging level. Default: retrieved by the configuration
                        file. (default: None)
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
The Mikado pipeline is composed of four different stages, that have to be executed serially:
.INDENT 0.0
.IP 1. 3
configure, for creating the configuration file that will be used throughout the run.
.IP 2. 3
prepare, for collapsing the input assemblies into a single file. After this step, it is possible to perform additional analyses on the data such as TransDecoder (highly recommended), \fI\%Portcullis\fP, or BLAST.
.IP 3. 3
serialise, to gather all external data into a single database.
.IP 4. 3
pick, to perform the actual selection of the best transcripts in each locus.
.UNINDENT
.SH MIKADO UTILITIES
.SS Compare
.SS Overview
.INDENT 0.0
.TP
.B This Mikado utility allows the user to compare the transcripts from any two annotations. Its output allows:
.INDENT 7.0
.IP \(bu 2
To understand which reference transcript each prediction is most similar to
.IP \(bu 2
To understand which prediction transcript best represent each reference model
.IP \(bu 2
To have a summary information about the similarity between the two annotations.
.UNINDENT
.UNINDENT
.sp
Mikado compare has been directly inspired by the popular \fI\%Cuffcompare\fP [Cufflinks] utility and by \fI\%ParsEval\fP [ParsEval]\&. Please note that while superficially similar to Cuffcompare in the style of the output files, Mikado compare is more philosophically similar to ParsEval, as it will not try to aggregate transcripts in loci but will perform a pure comparison between the two annotation files. Both GTF and GFF files are accepted, in any combination.
.SS Usage
.sp
Mikado compare is invoked by specifying the \fIreference\fP annotation and the desired mode of analysis. There are three possible options:
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP 1. 3
In its default mode, compare will ask for a \fIprediction\fP annotation to compare the reference against.
.IP 2. 3
In the \fI"self"\fP mode, compare will do a self\-comparison of the reference against itself, excluding as possible results the matches between a transcript and itself. It can be useful to glean the relationships between transcripts and genes in an annotation.
.IP 3. 3
In the \fI"internal"\fP mode of operations, compare will again perform a self\-comparison, focussed on multi\-isoform genes. For those, compare will perform and report all possible comparisons. It is useful to understand the relationships between the transcripts in a single locus.
.UNINDENT
.UNINDENT
.UNINDENT
.sp
Mikado stores the information of the reference in a specialised index, with a ".midx" suffix, which will be created by the program upon its first execution with a new reference. If the index file is already present, Mikado will try to use it rather than read again the annotation.
.SS Command line
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado compare \-\-help
usage: Mikado compare [\-h] \-r REFERENCE
                      (\-p PREDICTION | \-\-self | \-\-internal | \-\-index)
                      [\-\-distance DISTANCE] [\-pc] [\-o OUT] [\-\-lenient] [\-eu]
                      [\-n] [\-l LOG] [\-v]

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-distance DISTANCE   Maximum distance for a transcript to be considered a
                        polymerase run\-on. Default: 2000
  \-pc, \-\-protein\-coding
                        Flag. If set, only transcripts with a CDS (both in
                        reference and prediction) will be considered.
  \-o OUT, \-\-out OUT     Prefix for the output files. Default: mikado_compare
  \-\-lenient             If set, exonic statistics will be calculated leniently
                        in the TMAP as well \- ie they will consider an exon as
                        match even if only the internal junction has been
                        recovered.
  \-eu, \-\-exclude\-utr    Flag. If set, reference and prediction transcripts
                        will be stripped of their UTRs (if they are coding).
  \-n, \-\-no\-index, \-\-no\-save\-index
                        Unless this flag is set, compare will save an index of
                        the reference to quicken multiple calls.
  \-l LOG, \-\-log LOG
  \-v, \-\-verbose

Prediction and annotation files.:
  \-r REFERENCE, \-\-reference REFERENCE
                        Reference annotation file. By default, an index will
                        be crated and saved with the suffix ".midx".
  \-p PREDICTION, \-\-prediction PREDICTION
                        Prediction annotation file.
  \-\-self                Flag. If set, the reference will be compared with
                        itself. Useful for understanding how the reference
                        transcripts interact with each other.
  \-\-internal            Flag. If set, for each gene with more than one
                        transcript isoform each will be compared to the
                        others. Useful for understanding the structural
                        relationships between the transcripts in each gene.
  \-\-index               Flag. If set, compare will stop after having generated
                        the GFF index for the reference.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Output files
.sp
Mikado compare produces two tabular files, \fI\%tmap\fP and \fI\%refmap\fP, and one \fI\%statistics\fP file.
.SS TMAP files
.sp
TMAP are tabular files that store the information regarding the best match for each prediction in the reference. The columns are as follows:
.INDENT 0.0
.IP 1. 4
\fBref_id\fP: Transcript ID of the matched reference model(s).
.IP 2. 4
\fBref_gene\fP: Gene ID of the matched reference model(s).
.IP 3. 4
\fBccode\fP: class code of the match. See \fI\%the relevant section on Class codes\fP\&.
.IP 4. 4
\fBtid\fP: Transcript ID of the prediction model.
.IP 5. 4
\fBgid\fP: Gene ID of the prediction model.
.IP 6. 4
\fBtid_num_exons\fP: Number of exons of the prediction model.
.IP 7. 4
\fBref_num_exons\fP: Number of exons of the reference model.
.IP 8. 4
\fBn_prec\fP: Nucleotide precision of the prediction ( TP / (length of the prediction))
.IP 9. 4
\fBn_recall\fP: Nucleotide recall of the reference (TP / (length of the reference))
.IP 10. 4
\fBn_f1\fP: \fI\%F1\fP of recall and precision at the nucleotide level.
.IP 11. 4
\fBj_prec\fP: Splice junction precision of the prediction model ( TP / (number of splice sites in the prediction))
.IP 12. 4
\fBj_recall\fP: Splice junction recall of the reference model ( TP / (number of splice sites in the reference))
.IP 13. 4
\fBj_f1\fP: \fI\%F1\fP of recall and precision at the splice junction level.
.IP 14. 4
\fBe_prec\fP: Exon precision of the prediction model ( TP / (number of exons in the prediction)). \fBNB\fP: this value is calculated "leniently", ie terminal exons count as a match if the \fIinternal\fP border is called correctly and the exon is terminal in both prediction and reference.
.IP 15. 4
\fBe_recall\fP: Exon recall of the reference model ( TP / (number of exons in the reference))
.IP 16. 4
\fBe_f1\fP: \fI\%F1\fP of recall and precision at the exon level.
.IP 17. 4
\fBdistance\fP: Distance of the model from its putative match.
.UNINDENT
.sp
An example of TMAP file is as follows:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
ref_id      ref_gene        ccode   tid     gid     tid_num_exons   ref_num_exons   n_prec  n_recall        n_f1    j_prec  j_recall        j_f1    e_prec  e_recall        e_f1    distance
AT5G66610.1 AT5G66610       =       mikado.Chr5G1.2 mikado.Chr5G1   11      11      97.77   99.16   98.46   100.00  100.00  100.00  81.82   81.82   81.82   0
AT5G66610.1 AT5G66610       j       mikado.Chr5G1.1 mikado.Chr5G1   11      11      92.93   94.74   93.82   95.00   95.00   95.00   81.82   81.82   81.82   0
AT5G66620.1,AT5G66630.1,AT5G66631.1 AT5G66620,AT5G66630,AT5G66631   f,j,J,O st_Stringtie_STAR.21710.6       Stringtie_STAR.21710    22      11,10,1 27.84,34.47,28.63       99.79,99.13,100.00      43.54,51.16,44.52       45.24,42.86,0.00        95.00,100.00,0.00       61.29,60.00,0.00        36.36,36.36,0.00        72.73,80.00,0.00        48.48,50.00,0.00        0
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
You can notice that the third example is particular as the prediction transcript matches not one but multiple reference transcripts. This is a \fI\%fusion\fP event.
.SS RefMap files
.sp
RefMap files are tabular files which store the information regarding the best match for each reference transcript, among all possible prediction models. The columns of the file are as follows:
.INDENT 0.0
.IP 1. 4
\fBref_id\fP: Transcript ID of the reference model.
.IP 2. 4
\fBccode\fP: class code of the match. See \fI\%the relevant section on Class codes\fP\&.
.IP 3. 4
\fBtid\fP: Transcript ID of the prediction model.
.IP 4. 4
\fBgid\fP: Gene ID of the prediction model.
.IP 5. 4
\fBnF1\fP: \fI\%F1\fP of recall and precision at the nucleotide level.
.IP 6. 4
\fBjF1\fP: \fI\%F1\fP of recall and precision at the splice junction level.
.IP 7. 4
\fBeF1\fP: \fI\%F1\fP of recall and precision at the exon level. \fBNB\fP: this value is calculated "leniently", ie terminal exons count as a match if the \fIinternal\fP border is called correctly and the exon is terminal in both prediction and reference.
.IP 8. 4
\fBref_gene\fP: Gene ID of the reference model.
.IP 9. 4
\fBbest_ccode\fP: Best possible class code found for any of the transcripts of the gene.
.IP 10. 4
\fBbest_tid\fP: Transcript ID of the prediction model which fit best one of the transcript models of the reference gene.
.IP 11. 4
\fBbest_gid\fP: Gene ID of the prediction model which fit best one of the transcript models of the reference gene.
.IP 12. 4
\fBbest_nF1\fP: \fI\%F1\fP of recall and precision at the nucleotide level, for the best possible comparison.
.IP 13. 4
\fBbest_jF1\fP: \fI\%F1\fP of recall and precision at the splice junction level, for the best possible comparison.
.IP 14. 4
\fBbest_eF1\fP: \fI\%F1\fP of recall and precision at the exon level, for the best possible comparison.
.UNINDENT
.sp
An example of a RefMap file is as follows:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
ref_id      ccode   tid     gid     nF1     jF1     eF1     ref_gene        best_ccode      best_tid        best_gid        best_nF1        best_jF1        best_eF1
AT5G66610.1 =       mikado.Chr5G1.2 mikado.Chr5G1   98.46   100.0   81.82   AT5G66610       =       mikado.Chr5G1.2 mikado.Chr5G1   98.46   100.0   81.82
AT5G66610.2 J       mikado.Chr5G1.2 mikado.Chr5G1   93.91   94.74   76.19   AT5G66610       =       mikado.Chr5G1.2 mikado.Chr5G1   98.46   100.0   81.82
AT5G66630.1 f,n     tr_c58_g1_i4.mrna1.6    c58_g1_i4.path1.6       66.32   94.74   76.19   AT5G66630       f,n     tr_c58_g1_i4.mrna1.6    c58_g1_i4.path1.6       66.32   94.74   76.19
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
Please note that the third example (AT5G66630.1) has as best possible match a \fI\%fusion\fP event.
.SS Stats files
.sp
These files provide a summary of the comparison between the reference and the annotation. An example is as follows:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
Command line:
/usr/users/ga002/venturil/py351/bin/mikado compare \-r reference.gff3 \-p mikado.loci.gff3 \-o compare \-l compare.log
7 reference RNAs in 5 genes
15 predicted RNAs in  8 genes
\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\- |   Sn |   Pr |   F1 |
                        Base level: 85.74  64.73  73.77
            Exon level (stringent): 63.83  42.86  51.28
              Exon level (lenient): 80.00  52.94  63.72
                      Intron level: 89.47  59.65  71.58
                Intron chain level: 33.33  14.29  20.00
      Transcript level (stringent): 0.00  0.00  0.00
  Transcript level (>=95% base F1): 28.57  13.33  18.18
  Transcript level (>=80% base F1): 42.86  20.00  27.27
         Gene level (100% base F1): 0.00  0.00  0.00
        Gene level (>=95% base F1): 40.00  25.00  30.77
        Gene level (>=80% base F1): 60.00  37.50  46.15

#   Matching: in prediction; matched: in reference.

            Matching intron chains: 2
             Matched intron chains: 2
   Matching monoexonic transcripts: 1
    Matched monoexonic transcripts: 1
        Total matching transcripts: 3
         Total matched transcripts: 3

          Missed exons (stringent): 17/47  (36.17%)
           Novel exons (stringent): 40/70  (57.14%)
            Missed exons (lenient): 9/45  (20.00%)
             Novel exons (lenient): 32/68  (47.06%)
                    Missed introns: 4/38  (10.53%)
                     Novel introns: 23/57  (40.35%)

                Missed transcripts: 0/7  (0.00%)
                 Novel transcripts: 6/15  (40.00%)
                      Missed genes: 0/5  (0.00%)
                       Novel genes: 2/8  (25.00%)
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
The first section of the file describes:
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP 1. 3
Concordance of the two annotations at the base level (recall, precision, and F1)
.IP 2. 3
Concordance of the two annotation at the exonic level (recall, precision, and F1), in two ways:
.INDENT 3.0
.IP \(bu 2
\fI"stringent"\fP: only perfect exonic matches are considered.
.IP \(bu 2
\fI"lenient"\fP: in this mode, terminal exons are counted as a match if the \fBinternal\fP border is matched. See the RGASP paper [RGASP] for details on the rationale.
.UNINDENT
.IP 3. 3
Concordance of the two annotations at the intron level.
.IP 4. 3
Concordance of the two annotations at the intron chain level \- how many intron chains of the reference are found identical in the prediction. Only multiexonic models are considered for this level.
.IP 5. 3
Concordance of the two annotations at the transcript level, in three different modes:
.INDENT 3.0
.IP \(bu 2
\fI"stringent"\fP: in this mode, only perfect matches are considered.
.IP \(bu 2
\fI"95% base F1"\fP: in this mode, we only count instances where the nucleotide F1 is greater than \fI95%\fP and, for multiexonic transcripts, the intron chain is reconstructed perfectly.
.IP \(bu 2
\fI"80% base F1"\fP: in this mode, we only count instances where the nucleotide F1 is greater than \fI80%\fP and, for multiexonic transcripts, the intron chain is reconstructed perfectly.
.UNINDENT
.IP 6. 3
Concordance of the two annotations at the gene level, in three different modes:
.INDENT 3.0
.IP \(bu 2
\fI"stringent"\fP: in this mode, we consider reference genes for which it was possible to find at least one perfect match for one of its transcripts.
.IP \(bu 2
\fI"95% base F1"\fP: in this mode, we only count instances where the nucleotide F1 is greater than \fI95%\fP and, for multiexonic transcripts, the intron chain is reconstructed perfectly.
.IP \(bu 2
\fI"80% base F1"\fP: in this mode, we only count instances where the nucleotide F1 is greater than \fI80%\fP and, for multiexonic transcripts, the intron chain is reconstructed perfectly.
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.sp
In the second section, the file reports how many of the intron chains, monoexonic transcripts and total transcripts in the \fBreference\fP were \fImatched\fP by at least one \fImatching\fP \fBprediction\fP transcript. Finally, in the third section the file reports the number of missed (present in the reference but not in the prediction) or novel (viceversa \- present in the prediction but not in the reference) features.
.sp
\fBNOTE:\fP
.INDENT 0.0
.INDENT 3.5
Please note that a gene might be considered as "found" even if its best match is intronic, on the opposite strand, or not directly overlapping it, or is in the opposite strand (see \fI\%next section\fP, in particular the \fIIntronic\fP, \fIFragment\fP and \fINo overlap\fP categories).
.UNINDENT
.UNINDENT
.SS Class codes
.sp
In addition to recall, precision and F1 values, Mikado assign each comparison between two transcripts a \fIclass code\fP, which summarises the relationship between the two transcripts. The idea is lifted from the popular tool \fI\%Cuffcompare\fP, although Mikado greatly extends the catalogue of possible class codes.
All class codes fall within one of the following categories:
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
\fBMatch\fP: class codes of this type indicate concordance between the two transcript models.
.IP \(bu 2
\fBExtension\fP: class codes of this type indicate that one of the two models extends the intron chain of the other, without internal interruptions. The extension can be from either perspective \- either the prediction extends the reference, or it is instead \fIcontained\fP within the reference (so that switching perspectives, the reference would "extend" the prediction).
.IP \(bu 2
\fBAlternative splicing\fP: the two exon chains overlap but differ in significant ways.
.IP \(bu 2
\fBIntronic\fP: either the prediction is completely contained within the introns of the reference, or viceversa.
.IP \(bu 2
\fBFragment\fP: the prediction is a fragment of the reference, in most cases because they are on opposite strands.
.IP \(bu 2
\fBNo overlap\fP: the prediction and the reference are near but do not directly overlap.
.UNINDENT
.INDENT 0.0
.IP \(bu 2
\fBFusion\fP: this special class code is a qualifier and it never appears on its own. When a transcript is defined as a fusion,  its class code in the \fItmap\fP file will be an "f" followed by the class codes of the individual transcript matches, sperated by comma. So a prediction which matches two reference models, one with a "j" and another with a "o", will have a class code of \fB"f,j,o"\fP\&. In the \fIrefmap\fP file, if the fusion is the best match, the class code will be "f" followed by the class code for the individual reference transcript; e.g., \fB"f,j"\fP
.UNINDENT
.UNINDENT
.UNINDENT
.SS Available class codes
.TS
center;
|l|l|l|l|l|l|l|l|.
_
T{
Class code
T}	T{
Definition
T}	T{
Is the
reference
transcript
multiexonic?
T}	T{
Is the
prediction
transcript
multiexonic?
T}	T{
Nucleotide:
Recall,
Precision,
F1
T}	T{
Junction:
Recall,
Precision,
F1
T}	T{
Reverse
class code
T}	T{
Category
T}
_
T{
\fB=\fP
T}	T{
Complete intron chain match.
T}	T{
True
T}	T{
True
T}	T{
NA
T}	T{
100%, 100%, 100%
T}	T{
\fB=\fP
T}	T{
\fBMatch\fP
T}
_
T{
\fB_\fP
(underscore)
T}	T{
Complete match between two
monoexonic transcripts.
T}	T{
False
T}	T{
False
T}	T{
NA, NA, \fB>=80%\fP
T}	T{
NA
T}	T{
\fB_\fP
T}	T{
\fBMatch\fP
T}
_
T{
\fBm\fP
T}	T{
Generic match between two
monoexonic transcripts.
T}	T{
False
T}	T{
False
T}	T{
NA, NA, \fB< 80%\fP
T}	T{
NA
T}	T{
\fBm\fP
T}	T{
\fBMatch\fP
T}
_
T{
\fBn\fP
T}	T{
Intron chain extension, ie.
both transcripts are
multiexonic and the
prediction has novel
splice sites \fIoutside\fP of
the reference transcript
boundaries.
T}	T{
True
T}	T{
True
T}	T{
\fB100%\fP, < 100%,
< 100%
T}	T{
100%, < 100%,
< 100%
T}	T{
\fBc\fP
T}	T{
\fBExtension\fP
T}
_
T{
\fBJ\fP
T}	T{
Intron chain extension,
both transcripts are
multiexonic and the
prediction has novel
splice sites \fIinside\fP of the
reference transcript
boundaries.
T}	T{
True
T}	T{
True
T}	T{
< 100%, <= 100%,
< 100%
T}	T{
\fB100%\fP, < 100%,
< 100%
T}	T{
\fBC\fP
T}	T{
\fBExtension\fP
T}
_
T{
\fBc\fP
T}	T{
The prediction
is either multiexonic and
with its intron chain
completely contained within
that of the reference, or
monoexonic and contained
within one of the reference
exons.
T}	T{
True
T}	T{
NA
T}	T{
< 100%, \fB100%\fP
NA
T}	T{
< 100%, \fB100%\fP
NA
T}	T{
\fBn\fP
T}	T{
\fBExtension\fP
T}
_
T{
\fBC\fP
T}	T{
The prediction intron chain
is completely contained
within that of the
reference transcript, but
it partially debords either
into its introns or outside
of the reference boundaries.
T}	T{
True
T}	T{
True
T}	T{
<= 100%, < 100%,
< 100%
T}	T{
< 100%, \fB100%\fP,
< 100%
T}	T{
\fBJ\fP or \fBj\fP
T}	T{
\fBExtension\fP
T}
_
T{
\fBj\fP
T}	T{
Alternative splicing event.
T}	T{
True
T}	T{
True
T}	T{
NA
T}	T{
<= 100%, < 100%,
< 100%
T}	T{
\fBj\fP
T}	T{
\fBAlternative
splicing\fP
T}
_
T{
\fBh\fP
T}	T{
Structural match between two
models where no splice site
is conserved but \fBat least\fP
one intron of the reference
and one intron of the
prediction partially overlap.
T}	T{
True
T}	T{
True
T}	T{
> 0%, > 0%, > 0%
T}	T{
0%, 0%, 0%
T}	T{
\fBh\fP
T}	T{
\fBAlternative
splicing\fP
T}
_
T{
\fBo\fP
T}	T{
Generic overlap between two
multiexonic transcripts,
which do not share \fBany\fP
overlap among their introns.
T}	T{
True
T}	T{
True
T}	T{
> 0%, > 0%, > 0%
T}	T{
0%, 0%, 0%
T}	T{
\fBo\fP
T}	T{
\fBAlternative
splicing\fP
T}
_
T{
\fBg\fP
("mo" before
release 1)
T}	T{
The monoexonic prediction
overlaps one or more exons of
the reference transcript; the
borders of the prediction
cannot fall inside the
introns of the reference.
The prediction transcript
can bridge multiple exons
of the reference model.
T}	T{
True
T}	T{
False
T}	T{
> 0%, > 0%,
between 0 and 100%
T}	T{
0%
T}	T{
\fBG\fP
T}	T{
\fBAlternative
splicing\fP
T}
_
T{
\fBG\fP
("O" before
release 1)
T}	T{
Generic match of a
multiexonic prediction
transcript versus a
monoexonic reference.
T}	T{
False
T}	T{
True
T}	T{
> 0%, > 0%, > 0%
T}	T{
0%
T}	T{
\fBg\fP
T}	T{
\fBAlternative
splicing\fP
T}
_
T{
\fBi\fP
T}	T{
Monoexonic prediction
completely contained within
one intron of the reference
transcript.
T}	T{
True
T}	T{
False
T}	T{
0%
T}	T{
0%
T}	T{
\fBri\fP
T}	T{
\fBIntronic\fP
T}
_
T{
\fBI\fP
T}	T{
Prediction completely
contained within the introns
of the reference transcript.
T}	T{
True
T}	T{
True
T}	T{
0%
T}	T{
0%
T}	T{
\fBrI\fP
T}	T{
\fBIntronic\fP
T}
_
T{
\fBrI\fP
T}	T{
Reference completely
contained within the introns
of the prediction transcript.
T}	T{
True
T}	T{
True
T}	T{
0%
T}	T{
0%
T}	T{
\fBI\fP
T}	T{
\fBIntronic\fP
T}
_
T{
\fBri\fP
T}	T{
Reverse intron transcript \-
the monoexonic reference is
completely contained within
one intron of the prediction
transcript.
T}	T{
False
T}	T{
True
T}	T{
0%
T}	T{
0%
T}	T{
\fBi\fP
T}	T{
\fBIntronic\fP
T}
_
T{
\fBf\fP
T}	T{
Fusion \- this special code
is applied when a prediction
intersects more than one
reference transcript. To be
considered for fusions,
candidate references must
\fBeither\fP share at least one
splice junction with the
prediction, \fBor\fP have at
least 10% of its bases
recalled. If two or more
reference transcripts fit
these constraints, then the
prediction model is
classified as a \fBfusion\fP\&.
T}	T{
NA
T}	T{
NA
T}	T{
\fB> 10%\fP, NA, NA
T}	T{
\fB> 0%\fP, NA, NA
T}	T{
NA
T}	T{
\fBFusion\fP
T}
_
T{
\fBe\fP
T}	T{
Single exon transcript
overlapping \fIone\fP reference
exon and at least 10 bps of a
reference intron, indicating
a possible pre\-mRNA fragment.
T}	T{
True
T}	T{
False
T}	T{
> 0%, > 0%,
between 0 and 100%
T}	T{
0%
T}	T{
\fBG\fP
T}	T{
\fBFragment\fP
T}
_
T{
\fBx\fP
T}	T{
Monoexonic match on the
\fIopposite\fP strand.
T}	T{
NA
T}	T{
False
T}	T{
>= 0%
T}	T{
0%
T}	T{
\fBx\fP or \fBX\fP
T}	T{
\fBFragment\fP
T}
_
T{
\fBX\fP
T}	T{
Multiexonic match on the
\fIopposite\fP strand.
T}	T{
NA
T}	T{
True
T}	T{
>= 0%
T}	T{
0%
T}	T{
\fBx\fP or \fBX\fP
T}	T{
\fBFragment\fP
T}
_
T{
\fBp\fP
T}	T{
The prediction is on the same
strand of a neighbouring but
non\-overlapping transcript.
Probable polymerase run\-on.
T}	T{
NA
T}	T{
NA
T}	T{
0%
T}	T{
0%
T}	T{
\fBp\fP
T}	T{
\fBNo overlap\fP
T}
_
T{
\fBP\fP
T}	T{
The prediction is on the
\fIopposite\fP strand of a
neighbouring but
non\-overlapping transcript.
Probable polymerase run\-on.
T}	T{
NA
T}	T{
NA
T}	T{
0%
T}	T{
0%
T}	T{
\fBP\fP
T}	T{
\fBNo overlap\fP
T}
_
T{
\fBu\fP
T}	T{
Unknown \- no suitable model
has been found near enough
the prediction to perform a
comparison.
T}	T{
NA
T}	T{
NA
T}	T{
0%
T}	T{
0%
T}	T{
NA
T}	T{
\fBNo overlap\fP
T}
_
.TE
.SS Technical details
.sp
Mikado compare conceptualizes the reference annotation as a collection of interval trees, one per chromosome or scaffold, where each node corresponds to an array of genes at the location. The gene and transcript objects are stored separately. The location of each transcript model in the prediction is queried against the tree, with a padding (default 2kbps) to allow for neighouring but non\-overlapping genes, and the transcript itself is subsequently compared with each reference transcript contained in the hits. Each comparison will yield precision, recall and F1 values for the nucleotide, splice junction and exonic levels, together with an associated class code. The best match for the prediction is selected for by choosing the comparison yielding the best splice junction F1 and the best nucleotide F1, in this order. If the prediction transcript overlaps two or more genes on the same strand, and for at least two it has one match each with either 10% nucleotide recall or junction recall over 0%, it is deemed as a \fI\%fusion\fP event, and its line in the \fI\%tmap\fP file will report the best match against each of the fused genes, separated by comma.
.sp
Each calculated match against a reference transcript is stored as a potential \fIbest match\fP for the reference transcript. At the end of the run, the hits for each reference transcript will be ordered using the following function:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
@staticmethod
def result_sorter(result):

    """
    Method to sort the results for the refmap. Order:
    \- CCode does not contain "x", "P", "p" (i.e. fragments on opposite strand or
    polymerase run\-on fragments)
    \- Exonic F1 (e_f1)
    \- Junction F1 (j_f1)
    \- "f" in ccode (i.e. transcript is a fusion)
    \- Nucleotide F1 (n_f1)

    :param result: a resultStorer object
    :type result: ResultStorer
    :return: (int, float, float, float)
    """

    bad_ccodes = ["x", "X", "P", "p"]
    bad_ccodes = set(bad_ccodes)

    orderer = (len(set.intersection(bad_ccodes, set(result.ccode))) == 0,
               result.j_f1, result.e_f1,
               result.n_f1,
               "f" in result.ccode)

    return orderer
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
This function is used to select both for the best match \fIfor the transcript\fP, as well as to select among these matches for the best match \fIfor the gene\fP\&.
.sp
The interval tree data structure is created using Cython code originally part of the \fI\%bx\-python\fP, kindly provided by \fI\%Dr. Taylor\fP for modification and inclusion in Mikado. The code has been slightly modified for making it Python3 compliant.
.sp
The comparison code is written in Cython and is crucial during the picking phase of Mikado, not just for the functioning of the comparison utility.
.SS The Daijin pipeline for driving Mikado
.sp
\fI\%snake_badge\fP
.sp
No emperor or empress can lead its nation without a trusty chancellor to help him or her in organising the bureaucracy. Daijin, the Japanese minister, has the same role in Mikado \- it smooths the path to go from a collection of read inputs (both RNA\-Seq or long reads) to a polished transcriptome assembly. The pipeline is based on \fI\%Snakemake\fP [Snake]; while Snakemake can support any scheduling system, our pipeline manager currently supports only three (SLURM, PBS and LSF), plus any DRMAA\-compliant batch submission system. Other schedulers can be added upon request.
.sp
\fBHINT:\fP
.INDENT 0.0
.INDENT 3.5
It is possible to launch the two steps of the pipeline directly with Snakemake, using the snakefiles located in Mikado.daijin: \fBtr.snakefile\fP for the first step, and \fBmikado.snakefile\fP for the second.
.UNINDENT
.UNINDENT
.SS Configure
.sp
This utility creates the configuration file that will drive Daijin, in \fI\%YAML\fP format. The file will need to be edited to
.SS Assemble
.sp
In the first step of the pipeline, Daijin will perform the following operations for each of the read datasets provided:
.INDENT 0.0
.IP 1. 3
Create the necessary indices for each of the aligner programs requested.
.IP 2. 3
Align the read dataset using all the different tools requested, in all the possible combinations of parameters requested.
* For example, it is possible to ask each dataset to be aligned twice with TopHat2 \- once with the "micro\-exon" mode activated, the second time without. Both alignments will be run independently.
* It is possible to specify which datasets are strand\-specific and which are not, and moreover, it is possible to specify the kind of strand\-specificity (fr\-secondstrand, fr\-firststrand).
.IP 3. 3
Call all the reliable junctions across the alignments using \fI\%Portcullis\fP\&.
.IP 4. 3
Create the statistics for the assembly using \fBsamtools stat\fP, and merge them together in a single file.
.IP 5. 3
Assemble each alignment with all the tools requested, in all the parameter combinations desired.
.IP 6. 3
Call the statistics on each assembly using mikado util stats, and merge them together in a single file.
.IP 7. 3
Create the configuration file for Mikado.
.UNINDENT
.sp
So during this first step Daijin will go from raw reads files to multiple assemblies, and configure Mikado for the second step.
.SS Assembly pipeline, as driven by Daijin
.INDENT 0.0
.INDENT 2.5
[image]
Example of a pipeline to assemble a single paired\-end read dataset using three aligners (STAR [STAR], Hisat [Hisat], TopHat2 [TopHat2] ) and two different RNA\-Seq assemblers (StringTie [StringTie], CLASS2 [Class2] ). Reliable junctions from the three alignments are called and merged together using \fI\%Portcullis\fP\&..UNINDENT
.UNINDENT
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ daijin assemble \-\-help
usage: daijin assemble [\-h] [\-c HPC_CONF] [\-\-jobs N] [\-\-cores [N]]
                       [\-\-threads N] [\-\-no_drmaa] [\-\-rerun\-incomplete]
                       [\-\-forcerun TARGET [TARGET ...]] [\-\-detailed\-summary]
                       [\-\-list] [\-\-dag]
                       config

positional arguments:
  config                Configuration file to use for running the transcript
                        assembly pipeline.

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-c HPC_CONF, \-\-hpc_conf HPC_CONF
                        Configuration file that allows the user to override
                        resource requests for each rule when running under a
                        scheduler in a HPC environment.
  \-\-jobs N, \-J N        Maximum number of cluster jobs to execute
                        concurrently.
  \-\-cores [N], \-C [N]   Use at most N cores in parallel (default: 1000).
  \-\-threads N, \-t N     Maximum number of threads per job. Default: None (set
                        in the configuration file)
  \-\-no_drmaa, \-nd       Use this flag if you wish to run without DRMAA, for
                        example, if running on a HPC and DRMAA is not
                        available, or if running locally on your own machine
                        or server.
  \-\-rerun\-incomplete, \-\-ri
                        Re\-run all jobs the output of which is recognized as
                        incomplete.
  \-\-forcerun TARGET [TARGET ...], \-R TARGET [TARGET ...]
                        Force the re\-execution or creation of the given rules
                        or files. Use this option if you changed a rule and
                        want to have all its output in your workflow updated.
  \-\-detailed\-summary, \-D
                        Print detailed summary of all input and output files
  \-\-list, \-l            List resources used in the workflow
  \-\-dag                 Do not execute anything and print the redirected
                        acylic graph of jobs in the dot language.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Mikado
.sp
In this step, the Daijin manager will execute all the steps necessary to perform Mikado on the desired inputs. The manager will execute the following steps:
.INDENT 0.0
.IP 1. 3
Merge all the input assemblies together using Mikado prepare
.IP 2. 3
Execute \fI\%TransDecoder\fP [Trinity] on the transcript sequences, to retrieve their ORFs.
.IP 3. 3
Split the FASTA file in as many chunks as specified during configuration, and analyse them separately
.IP 4. 3
Execute \fI\%BLASTX+\fP [Blastplus] on the splitted FASTAs, creating BLAST XML outputs.
.IP 5. 3
Run Mikado serialise to load the BLAST results, TransDecoder ORFs, and portcullis junctions into a single database.
.IP 6. 3
Run Mikado pick on the data, in the selected modes.
.IP 7. 3
Collate and collapse the statistics for each of the filtered assemblies.
.UNINDENT
.SS Mikado pipeline, as driven by Daijin
.INDENT 0.0
.INDENT 2.5
[image]
Example of a typical Mikado pipeline. In this case the number of chunks for BLAST is limited \- 10 \- but we advise to increase this number for big datasets..UNINDENT
.UNINDENT
.sp
Command line usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ daijin mikado \-\-help
usage: daijin mikado [\-h] [\-c HPC_CONF] [\-\-jobs N] [\-\-cores [N]] [\-\-threads N]
                     [\-\-no_drmaa] [\-\-rerun\-incomplete]
                     [\-\-forcerun TARGET [TARGET ...]] [\-\-detailed\-summary]
                     [\-\-list] [\-\-dag]
                     config

positional arguments:
  config                Configuration file to use for running the Mikado step
                        of the pipeline.

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-c HPC_CONF, \-\-hpc_conf HPC_CONF
                        Configuration file that allows the user to override
                        resource requests for each rule when running under a
                        scheduler in a HPC environment.
  \-\-jobs N, \-J N        Maximum number of cluster jobs to execute
                        concurrently.
  \-\-cores [N], \-C [N]   Use at most N cores in parallel (default: 1000).
  \-\-threads N, \-t N     Maximum number of threads per job. Default: None (set
                        in the configuration file)
  \-\-no_drmaa, \-nd       Use this flag if you wish to run without DRMAA, for
                        example, if running on a HPC and DRMAA is not
                        available, or if running locally on your own machine
                        or server.
  \-\-rerun\-incomplete, \-\-ri
                        Re\-run all jobs the output of which is recognized as
                        incomplete.
  \-\-forcerun TARGET [TARGET ...], \-R TARGET [TARGET ...]
                        Force the re\-execution or creation of the given rules
                        or files. Use this option if you changed a rule and
                        want to have all its output in your workflow updated.
  \-\-detailed\-summary, \-D
                        Print detailed summary of all input and output files
  \-\-list, \-l            List resources used in the workflow
  \-\-dag                 Do not execute anything and print the redirected
                        acylic graph of jobs in the dot language.
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
\fBTIP:\fP
.INDENT 0.0
.INDENT 3.5
If you have already created some assemblies and wish to analyse them with Daijin, it is also possible to configure Mikado externally and use the resulting configuration file to guide Daijin.
.UNINDENT
.UNINDENT
.SS Mikado miscellaneous scripts
.sp
All these utilities can be accessed with the \fBmikado util\fP CLI. They perform relatively minor tasks.
.SS awk_gtf
.sp
This utility is used to retrieve specific regions from a GTF file, without breaking any transcript feature. Any transcript falling even partly within the specified coordinates will be retained in its entirety.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util awk_gtf \-\-help
usage: mikado.py util awk_gtf [\-h] (\-r REGION | \-\-chrom CHROM) [\-as]
                              [\-\-start START] [\-\-end END]
                              gtf [out]


positional arguments:
  gtf
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-r REGION, \-\-region REGION
                        Region defined as a string like <chrom>:<start>..<end>
  \-\-chrom CHROM
  \-as, \-\-assume\-sorted
  \-\-start START
  \-\-end END\(ga\(ga
.ft P
.fi
.UNINDENT
.UNINDENT
.SS convert
.sp
This utility is used to convert between GTF and GFF3 files, with the possibility of giving as output BED12 files as well. It is limited to converting transcript features, and will therefore ignore any other feature present (transposons, loci, etc.). The output of the conversion to GFF3 is completely GFF3 compliant.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util convert \-\-help
usage: mikado.py util convert [\-h] [\-of {bed12,gtf,gff3}] gf [out]

positional arguments:
  gf
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-of {bed12,gtf,gff3}, \-\-out\-format {bed12,gtf,gff3}
.ft P
.fi
.UNINDENT
.UNINDENT
.SS grep
.sp
This utility extracts specific transcripts and genes from an input GTF/GFF3 file. As input, it requires a text file of either the format "<transcript id><tab><gene id>", or simply gene per line (in which case the "\-\-genes" switch has to be invoked). If only some of the transcripts of a gene are included in the text file, the gene feature will be shrunk accordingly. The name is an obvious homage to the invaluable UNIX command that we all love.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util grep \-\-help
usage: mikado.py util grep [\-h] [\-v] [\-\-genes] ids gff [out]

Script to extract specific models from GFF/GTF files.

positional arguments:
  ids         ID file (format: mrna_id, gene_id \- tab separated)
  gff         The GFF file to parse.
  out         Optional output file

optional arguments:
  \-h, \-\-help  show this help message and exit
  \-v          Exclude from the gff all the records in the id file.
  \-\-genes     Flag. If set, the program expects as ids only a list of genes,
              and will exclude/include all the transcripts children of the
              selected genes.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS merge_blast
.sp
This script merges together various XML BLAST+ files into a single entity. It might be of use when the input data has been chunked into different FASTA files for submission to a cluster queue. It is also capable of converting from ASN files and of dealing with GZipped files.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util merge_blast \-\-help
usage: mikado.py util merge_blast [\-h] [\-v] [\-l LOG] [\-\-out [OUT]]
                                  xml [xml ...]

positional arguments:
  xml

optional arguments:
  \-h, \-\-help         show this help message and exit
  \-v, \-\-verbose
  \-l LOG, \-\-log LOG
  \-\-out [OUT]
.ft P
.fi
.UNINDENT
.UNINDENT
.SS metrics
.sp
This command generates the documentation regarding the available transcript metrics. It is generated dynamycally by inspecting the code. The documentation in the introduction is generated using this utility.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util metrics
.ft P
.fi
.UNINDENT
.UNINDENT
.SS stat
.sp
This command generates a statistics file for GFF3/GTF files. The output is a table including Average, Mode, and various quantiles for different features present in a typical GFF file (genes, introns, exons, cDNAs, etc.). The operation can be quite time consuming for large files, in which case it is advisable to ask for multiple processors.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util stats \-\-help
usage: mikado.py util stats [\-h] [\-\-only\-coding] [\-p PROCS] gff [out]

GFF/GTF statistics script. It will compute median/average length of RNAs,
exons, CDS features, etc.

positional arguments:
  gff                   GFF file to parse.
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-only\-coding
  \-p PROCS, \-\-processors PROCS
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
A typical example statistics file can be found \fBhere, for the TAIR10 annotation\fP\&.
.SS trim
.sp
This utility trims down the terminal exons of multiexonic transcripts, until either shrinking them to the desired maximum length or meeting the beginning/end of the CDS. It has been used for generating the "trimmed" annotations for the analysis of the original Mikado paper.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ mikado util trim \-\-help
usage: mikado.py util trim [\-h] [\-ml MAX_LENGTH] [\-\-as\-gtf] ann [out]

positional arguments:
  ann                   Reference GTF/GFF output file.
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-ml MAX_LENGTH, \-\-max_length MAX_LENGTH
                        Maximal length of trimmed terminal exons
  \-\-as\-gtf              Flag. If set, the output will be in GTF rather than
                        GFF3 format.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS Included scripts
.sp
All the following scripts are included in the "util" folder in the source code, and will be included on the PATH after installation. Some of this scripts are used by the Daijin pipeline to produce statistics or perform other intermediate steps.
.SS add_transcript_feature_to_gtf.py
.sp
This script is needed to add a top\-level transcript feature to GTFs that lack it, eg. those produced by CuffMerge [CuffMerge]\&.
.sp
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ add_transcript_feature_to_gtf.py \-\-help
usage: Script to add a transcript feature to e.g. Cufflinks GTFs
       [\-h] gtf [out]

positional arguments:
  gtf         Input GTF
  out         Output file. Default: stdout.

optional arguments:
  \-h, \-\-help  show this help message and exit
.ft P
.fi
.UNINDENT
.UNINDENT
.SS align_collect.py
.sp
This script is used to collect statistics from \fI\%samtools stat\fP\&.
Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ align_collect.py  \-\-help
usage: Script to collect info from multiple samtools stats files
       [\-h] input [input ...]

positional arguments:
  input       The list of samtools stats file to process

optional arguments:
  \-h, \-\-help  show this help message and exit
.ft P
.fi
.UNINDENT
.UNINDENT
.SS asm_collect.py
.sp
This script is used to collect statistics obtained with from the \fI\%mikado util stats\fP utility. Output is printed directly to the screen. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ asm_collect.py \-h
usage: Script to collect info from multiple mikado util stats files
       [\-h] input [input ...]

positional arguments:
  input       The list of mikado util stats file to process

optional arguments:
  \-h, \-\-help  show this help message and exit
.ft P
.fi
.UNINDENT
.UNINDENT
.SS class_run.py
.sp
Python3 wrapper for the CLASS [Class2] assembler. It will perform the necessary operations for the assembler (depth and call of the splicing junctions), and launch the program itself. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ class_run.py \-\-help
usage: Quick utility to rewrite the wrapper for CLASS. [\-h] [\-\-clean]
                                                       [\-\-force]
                                                       [\-c CLASS_OPTIONS]
                                                       [\-p PROCESSORS]
                                                       [\-\-class_help] [\-v]
                                                       [bam] [out]

positional arguments:
  bam                   Input BAM file.
  out                   Optional output file.

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-\-clean               Flag. If set, remove tepmorary files.
  \-\-force               Flag. If set, it forces recalculation of all
                        intermediate files.
  \-c CLASS_OPTIONS, \-\-class_options CLASS_OPTIONS
                        Additional options to be passed to CLASS. Default: no
                        additional options.
  \-p PROCESSORS, \-\-processors PROCESSORS
                        Number of processors to use with class.
  \-\-class_help          If called, the wrapper will ask class to display its
                        help and exit.
  \-v, \-\-verbose
.ft P
.fi
.UNINDENT
.UNINDENT
.SS getFastaFromIds.py
.sp
Script to extract a list of sequences from a FASTA file, using the \fI\%pyfaidx\fP [PyFaidx] module. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ getFastaFromIds.py \-h
usage: getFastaFromIds.py [\-h] [\-v] list fasta [out]

A simple script that retrieves the FASTA sequences from a file given a list of
ids.

positional arguments:
  list           File with the list of the ids to recover, one by line.
                 Alternatively, names separated by commas.
  fasta          FASTA file.
  out            Optional output file.

optional arguments:
  \-h, \-\-help     show this help message and exit
  \-v, \-\-reverse  Retrieve entries which are not in the list, as in grep \-v (a
                 homage).
.ft P
.fi
.UNINDENT
.UNINDENT
.SS grep.py
.sp
A script to extract data from \fIcolumn\fP files, using a list of targets. More efficient than a standard "grep \-f" for this niche case. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ util/grep.py \-h
usage: grep.py [\-h] [\-v] [\-s SEPARATOR] [\-f FIELD] [\-q] ids target [out]

This script is basically an efficient version of the GNU "grep \-f" utility for
table\-like files, and functions with a similar sintax.

positional arguments:
  ids                   The file of patterns to extract
  target                The file to filter
  out                   The output file

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-v, \-\-reverse         Equivalent to the "\-v" grep option
  \-s SEPARATOR, \-\-separator SEPARATOR
                        The field separator. Default: consecutive
                        whitespace(s)
  \-f FIELD, \-\-field FIELD
                        The field to look in the target file.
  \-q, \-\-quiet           No logging.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS remove_from_embl.py
.sp
Quick script to remove sequences from a given organism from SwissProt files, and print them out in FASTA format. Used to produce the BLAST datasets for the Mikado paper. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ remove_from_embl.py \-h
usage: Script to remove sequences specific of a given organism from a SwissProt file.
       [\-h] \-o ORGANISM [\-\-format {fasta}] input [out]

positional arguments:
  input
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-o ORGANISM, \-\-organism ORGANISM
                        Organism to be excluded
  \-\-format {fasta}      Output format. Choices: fasta. Default: fasta.
.ft P
.fi
.UNINDENT
.UNINDENT
.SS split_fasta.py
.sp
This script is used to split a FASTA file in a fixed number of files, with an approximate equal number of sequences in each. If the number of sequences in the input file is lower than the number of requested splits, the script will create the necessary number of empty files. Used in Daijin for preparing the input data for the BLAST analysis. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ split_fasta.py \-\-help
usage: Script to split FASTA sequences in a fixed number of multiple files.
       [\-h] [\-m NUM_FILES] fasta [out]

positional arguments:
  fasta                 Input FASTA file.
  out                   Output prefix. Default: filename+split

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-m NUM_FILES, \-\-num\-files NUM_FILES
                        Number of files to create. Default: 1000
.ft P
.fi
.UNINDENT
.UNINDENT
.SS trim_long_introns.py
.sp
This script parses an annotation file and truncates any transcript which has \fIUTR\fP introns over the provided threshold. In such cases, the UTR section after the long intron is simply removed. Usage:
.INDENT 0.0
.INDENT 3.5
.sp
.nf
.ft C
$ trim_long_introns.py \-\-help
usage: This script truncates transcript with UTR exons separated by long introns.
       [\-h] [\-mi MAX_INTRON] gff [out]

positional arguments:
  gff
  out

optional arguments:
  \-h, \-\-help            show this help message and exit
  \-mi MAX_INTRON, \-\-max\-intron MAX_INTRON
                        Maximum intron length for UTR introns.
.ft P
.fi
.UNINDENT
.UNINDENT
.sp
In addition with the pipeline proper, Mikado includes the following:
#. A dedicated utility, Mikado compare, to assess the similarity between two annotations.
#. A pipeline manager, Daijin, to align and assemble transcripts with multiple methods and subsequently drive Mikado on the assemblies.
#. Assorted utilities, some of them part of the Mikado suite and others provided as accessory scripts, to perform standard operations such as calculating statistics from a GFF file or recover a specific suite of transcripts from an annotation file.
.SH REFERENCES
.IP [Cufflinks] 5
\fBTranscript assembly and quantification by RNA\-Seq reveals unannotated transcripts and isoform switching during cell differentiation\fP Cole Trapnell, Brian Williams, Geo Pertea, Ali Mortazavi, Gordon Kwan, Jeltje van Baren, Steven Salzberg, Barbara Wold, Lior Pachter. \fINature Biotechnology\fP, 2010, doi:10.1038/nbt.1621
.IP [ParsEval] 5
\fBParsEval: parallel comparison and analysis of gene structure annotations\fP Daniel S Standage and Volker P Brendel. \fIBMC Bioinformatics\fP, 2012, doi:10.1186/1471\-2105\-13\-187
.IP [RGASP] 5
\fBAssessment of transcript reconstruction methods for RNA\-seq\fP  Tamara Steijger, Josep F Abril, Pr G Engstrm, Felix Kokocinski, The RGASP Consortium, Tim J Hubbard, Roderic Guig, Jennifer Harrow & Paul Bertone. \fINature Methods\fP, 2013, doi:10.1038/nmeth.2714
.IP [SnowyOwl] 5
\fBSnowyOwl: accurate prediction of fungal genes by using RNA\-Seq and homology information to select among ab initio models\fP Ian Reid, Nicholas OToole, Omar Zabaneh, Reza Nourzadeh, Mahmoud Dahdouli, Mostafa Abdellateef, Paul MK Gordon, Jung Soh, Gregory Butler, Christoph W Sensen and Adrian Tsang. \fIBMC Bioinformatics\fP, 2014, doi:10.1186/1471\-2105\-15\-229
.IP [CuffMerge] 5
\fBIdentification of novel transcripts in annotated genomes using RNA\-Seq\fP Adam Roberts, Harold Pimentel, Cole Trapnell and Lior Pachter. \fIBioinformatics\fP, 2011, doi:10.1093/bioinformatics/btr355
.IP [Class2] 5
\fBCLASS2: accurate and efficient splice variant annotation from RNA\-seq reads\fP Li Song, Sarven Sabunciyan and Liliana Florea. \fIBioinformatics\fP, 2016, doi:10.1093/nar/gkw158
.IP [PyFaidx] 5
\fBEfficient "pythonic" access to FASTA files using pyfaidx\fP Matthew D Shirley, Zhaorong Ma, Brent S Pedersen and Sarah J Wheelan. \fIPeerJ PrePrints\fP 3:e1196, 2015. doi:10.7287/peerj.preprints.970v1
.IP [Snake] 5
\fBSnakemakea scalable bioinformatics workflow engine\fP Johannes Kster and Sven Rahmann1. \fIBioinformatics\fP, 2012, doi:10.1093/bioinformatics/bts480
.IP [Trinity] 5
\fBDe novo transcript sequence reconstruction from RNA\-Seq: reference generation and analysis with Trinity\fP Brian J Haas, et al. \fINature Protocols\fP, 2013. doi:10.1038/nprot.2013.084
.IP [Blastplus] 5
\fBBLAST+: architecture and applications.\fP Camacho C, Coulouris G, Avagyan V, Ma N, Papadopoulos J, Bealer K, Madden TL. \fIBMC Bioinformatics\fP, 2009. doi:10.1186/1471\-2105\-10\-421
.IP [STAR] 5
\fBSTAR: ultrafast universal RNA\-seq aligner\fP Alexander Dobin, Carrie A. Davis1, Felix Schlesinger, Jorg Drenkow, Chris Zaleski, Sonali Jha1, Philippe Batut1, Mark Chaisson and Thomas R. Gingeras. \fIBioinformatics\fP, 2012. doi:10.1093/bioinformatics/bts635
.IP [Hisat] 5
\fBHISAT: a fast spliced aligner with low memory requirements\fP Daehwan Kim, Ben Langmead and Stevan L Salzberg. \fINature Methods\fP, 2015. doi:10.1038/nmeth.3317
.IP [TopHat2] 5
\fBTopHat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions\fP Daehwan Kim, Geo Pertea, Cole Trapnell, Harold Pimentel, Ryan Kelley and Steven L Salzberg. \fIGenome Biology\fP, 2013. doi:10.1186/gb\-2013\-14\-4\-r36
.IP [StringTie] 5
\fBStringTie enables improved reconstruction of a transcriptome from RNA\-seq reads\fP  Mihaela Pertea, Geo M Pertea, Corina M Antonescu, Tsung\-Cheng Chang, Joshua T Mendell       and Steven L Salzberg. \fINature Biotechnology\fP, 2015. doi:10.1038/nbt.3122
.IP [GMAP] 5
\fBGMAP: a genomic mapping and alignment program for mRNA and EST sequences\fP Thomas D. Wu and Colin K. Watanabe. \fIBioinformatics\fP 2005. doi:10.1093/bioinformatics/bti310
.IP [uORFs] 5
\fBuAUG and uORFs in human and rodent 5untranslated mRNAs.\fP Michele Iacono, Flavio Mignone and Graziano Pesole. \fIGene\fP, 2005. doi:10.1016/j.gene.2004.11.041
.IP [PyYaml] 5
\fBPyyaml library\fP K Simonov. \fIhttp://pyyaml.org/\fP, 2006.
.IP [Cython] 5
\fBCython: the best of both worlds.\fP Stefan Behnel, RObert Bradshaw, Craig Citro, Lisandro Dalcin, Dag Sverre Seljebotn and Kurt Smith. \fIAIP \- Computing in science & engineering\fP, 2011. doi:10.1109/MCSE.2010.118
.IP [Numpy] 5
\fBThe NumPy array: A structure for efficient numerical computation.\fP Stefan van der Walt, S. Chris Colbert and Gael Varoquaux. \fIComputing in Science & Engineering\fP, 2011. doi:10.1109/MCSE.2011.37
.IP [Scipy] 5
\fBSciPy: Open Source Scientific Tools for Python.\fP Eric Jones and Travis Oliphant and Pearu Peterson et al. \fIhttp://www.scipy.org/*\fP, 2001.
.IP [NetworkX] 5
\fBExploring network structure, dynamics, and function using NetworkX\fP Aric A. Hagberg, Daniel A. Schult and Pieter J. Swart. \fIProceedings of the 7th Python in Science Conference (SciPy2008)\fP, 2008. doi:
.IP [BioPython] 5
\fBBiopython: freely available Python tools for computational molecular biology and bioinformatics.\fP PA Cock, T Antao, JT Chang, BA Bradman, CJ Cox, A Dalke, I Friedberg, T Hamelryck, F Kauff, B Wilczynski and MJL de Hoon. \fIBioinformatics\fP, 2009. doi:10.1093/bioinformatics/btp163
.IP [SciKit] 5
\fBScikit\-learn: Machine Learning in Python.\fP Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot and douard Duchesnay. \fIThe Journal of Machine Learning Research\fP, 2011. doi:
.IP [DRMAA] 5
\fBDistributed resource management application API Version 2 (DRMAA).\fP P Trger, R Brobst, D Gruber, M Mamonski and D Templeton. \fIOpen Grid Forum\fP, 2012. doi:
.SH LIBRARY DOCUMENTATION
.sp
Mikado is a Python suite whose purpose is to find and resolve genic loci in a
genomic annotation. This is the library it relies onto.
.SS Custom exceptions
.sp
Custom exceptions for Mikado.
.INDENT 0.0
.TP
.B exception Mikado.exceptions.CorruptIndex
Exception to be raised when the index for Mikado compare is corrupt.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.IncorrectStrandError
Exception to be raised when a transcript contains an invalid intron
(e.g. an AG\-GT intron assigned to the minus strand).
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.InvalidAssembly
Exception to be raised when the input for prepare is not properly formatted.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.InvalidCDS
Exception to be raised when a transcript contains an invalid CDS
(e.g. with a UTR in the middle).
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.InvalidJson
Exception to be raised when the JSON/YAML is invalid.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.InvalidLocusError
Exception to be raised when something has made a Locus object invalid.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.InvalidTranscript
Exception to be raised when a transcript contains corrupted data
(e.g. overlapping or missing exons).
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.ModificationError
This exception is raised when something tries to modify a finalized object.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.NoJsonConfigError
Exception to be raised if no/an invalid configuration dictionary has been provided.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.NotInLocusError
Error to be raised when a method tries to add a transcript to a Locus it does not belong to.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.UnrecognizedOperator
Exception to be raised when the configuration file contains an unsupported operator
for a scoring/filtering function.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.UnrecognizedRescaler
Exception to be raised when the configuration file contains an unsupported rescaling
function for a scoring operation.
.UNINDENT
.INDENT 0.0
.TP
.B exception Mikado.exceptions.UnsortedInput
Exception to be raised when the input for pick is not properly sorted.
.UNINDENT
.SS Modules
.SS Submodule: configuration
.sp
This module defines the functions needed to check the sanity of the configuration file,
plus the JSON schemas for the configuration and scoring files.
.SS configuration_blueprint.json
.sp
\fI\%JSON schema\fP of the Mikado configuration\&. File: .. download:: ../Usage_dir/configuration_blueprint.json
.SS configurator.py
.sp
This module defines the functionalities needed to verify the integrity and completeness
of Mikado configuration files. Missing values are replaced with default ones,
while existing values are checked for type and consistency.
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.check_all_requirements(json_conf)
Function to check all the "requirements" sections of the configuration.
.INDENT 7.0
.TP
.B Parameters
\fBjson_conf\fP (\fIdict\fP) \-\- the dictionary to be checked.
.TP
.B Returns
json_conf
.UNINDENT
.sp
:rtype dict
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.check_db(json_conf)
Function to check the validity of the database options.
:param json_conf:
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.check_json(json_conf, simple=False, external_dict=None)
Wrapper for the various checks performed on the configuration file.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- The dicitonary loaded from the configuration file.
.IP \(bu 2
\fBsimple\fP (\fIbool\fP) \-\- boolean flag indicating whether we desire
the simplified version of the configuration, or not.
.IP \(bu 2
\fBexternal_dict\fP (\fI(dict|None)\fP) \-\- optional external dictionary with values to pass to the configuration.
.UNINDENT
.UNINDENT
.sp
:return json_conf
:rtype: dict
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.check_requirements(json_conf, require_schema)
Function to check the "requirements" section of the configuration.
Each filtering function will be checked for:
\- validity of the expression (it can be interpreted by Mikado)
\- validity of the parameter (it is a valid Metric)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- configuration dictionary to check.
.IP \(bu 2
\fBrequire_schema\fP (\fIdict\fP) \-\- the requirements section of the JSON schema.
.UNINDENT
.TP
.B Returns
json_conf
.UNINDENT
.sp
:rtype dict
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.check_scoring(json_conf)
.INDENT 7.0
.TP
.B Parameters
\fBjson_conf\fP (\fIdict\fP) \-\- configuration dictionary to check.
.UNINDENT
.sp
Function to check the "scoring" section of the configuration.
Each scoring function will be checked for:
\- validity of the expression (it can be interpreted by Mikado)
\- validity of the parameter (it is a valid Metric)
.INDENT 7.0
.TP
.B Returns
json_conf
.UNINDENT
.sp
:rtype dict
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.create_validator(simple=False)
Method to create a validator class (see extend_with_default).
The simple keyword (boolean) is used to determine whether to keep
only SimpleComment or full Comments from the schema.
.INDENT 7.0
.UNINDENT
.sp
:return validator
:rtype: jsonschema.Draft4Validator
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.extend_with_default(validator_class, resolver=None, simple=False)
Function to extend the normal validation classes for jsonschema
so that they also set the default values provided inside the schema
itself. Source:
\fI\%https://python\-jsonschema.readthedocs.org/en/latest/faq/?highlight=default\fP
:param validator_class: the validator class to extend (e.g. Draft4Validator)
.INDENT 7.0
.TP
.B Parameters
\fBsimple\fP (\fIbool\fP) \-\- boolean flag. If set to True, only required properties will be extended.
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.configuration.configurator.to_json(string, simple=False)
Function to serialise the JSON for configuration and check its consistency.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBstring\fP (\fI(str | None | dict)\fP) \-\- the configuration file name.
.IP \(bu 2
\fBsimple\fP (\fIbool\fP) \-\- boolean flag indicating whether we desire
the simplified version of the configuration, or not.
.UNINDENT
.UNINDENT
.UNINDENT
.SS daijin_configurator.py
.SS daijin_schema.json
.sp
\fI\%JSON schema\fP of the Daijin configuration. File: .. download:: ../Usage_dir/daijin_schema.json
.SS requirements_blueprint.json
.sp
\fI\%JSON schema\fP of the requirements section of scoring files. File: .. download:: ../Usage_dir/requirements_blueprint.json
.SS scoring_blueprint.json
.sp
\fI\%JSON schema\fP of the scoring proper section of scoring files. File: .. download:: ../Usage_dir/scoring_blueprint.json
.SS Submodule: daijin
.sp
The Daijin module is built to manage multiple alignments and assemblies of
RNA\-Seq data, and subsequently merge them with Mikado.
.SS hpc.yaml
.sp
Example configuration file for scheduler information with DRMAA. File: \fBhpc.yaml\fP
.SS mikado.snakefile
.sp
This file defines the Snakefile [Snake] of the pipeline for the stages regarding Mikado, ie after the assemblies have been performed. File: \fBmikado.snakefile\fP\&.
.SS tr.snakefile
.sp
This file defines the Snakefile [Snake] of the pipeline for the stages read alignment and assembly, and for calling the reliable junctions with Portcullis. File: \fBtr.snakefile\fP\&.
.SS Submodule: loci
.sp
This module defines the objects which rely the information on the transcript
location on the genome. The most basic construct is the transcript, which holds
information about a single RNA molecule.
Transcripts can then be gathered in superloci, subloci, monosubloci or loci;
all of these are defined as implementations of the blueprint "abstractlocus" class.
The creation of the loci is delegated to the "Creator" class.
.SS abstractlocus.py
.sp
Module that defines the blueprint for all loci classes.
.INDENT 0.0
.TP
.B class Mikado.loci.abstractlocus.Abstractlocus(source=\(aq\(aq)
This abstract class defines the basic features of any Locus\-like object.
It also defines methods/properties that are needed throughout the program,
e.g. the Bron\-Kerbosch algorithm for defining cliques, or the find_retained_introns method.
.INDENT 7.0
.TP
.B _cds_introntree
.INDENT 7.0
.TP
.B Return type
intervaltree.IntervalTree
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript, check_in_locus=True)
:param transcript
:type transcript: Mikado.loci_objects.transcript.Transcript
.INDENT 7.0
.TP
.B Parameters
\fBcheck_in_locus\fP \-\- flag to indicate whether the function
.UNINDENT
.sp
should check the transcript before adding it
or instead whether to trust the assignment to be correct
:type check_in_locus: bool
.sp
This method checks that a transcript is contained within the superlocus
(using the "in_superlocus" class method)
and upon a successful check extends the superlocus with the new transcript.
More precisely, it updates the boundaries (start and end) it adds the transcript
to the internal "transcripts" store, and finally it extends
the splices and introns with those found inside the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod choose_best(transcripts: dict) -> str
.INDENT 7.0
.TP
.B Parameters
\fBtranscripts\fP (\fIdict\fP) \-\- the dictionary of transcripts of the instance
.UNINDENT
.sp
Given a transcript dictionary, this function will choose the one with the highest score.
If multiple transcripts have exactly the same score, one will be chosen randomly.
.UNINDENT
.INDENT 7.0
.TP
.B define_graph(objects: dict, inters=None, **kwargs) -> networkx.classes.graph.Graph
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBobjects\fP (\fIdict\fP) \-\- a dictionary of objects to be grouped into a graph
.IP \(bu 2
\fBinters\fP (\fIcallable\fP) \-\- the intersecting function to be used to define the graph
.IP \(bu 2
\fBkwargs\fP (\fIdict\fP) \-\- optional arguments to be passed to the inters function
.UNINDENT
.UNINDENT
.sp
This function will compute the graph which will later be used by find_communities.
The method takes as mandatory inputs the following:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
"objects" a dictionary of objects that form the graph
.IP \(bu 2
"inters" a function/method that determines whether two objects are connected or not.
.UNINDENT
.UNINDENT
.UNINDENT
.sp
It will then return a graph.
The method accepts also kwargs that can be passed to the inters function.
WARNING: the kwargs option is really stupid and does not check
for correctness of the arguments!
.UNINDENT
.INDENT 7.0
.TP
.B static evaluate(param: str, conf: dict) -> bool
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBparam\fP (\fIstr\fP) \-\- string to be checked according to the expression in the configuration
.IP \(bu 2
\fBconf\fP (\fIdict\fP) \-\- a dictionary containing the expressions to evaluate
.UNINDENT
.UNINDENT
.sp
This static method evaluates a single parameter using the requested
operation from the JSON dict file.
.UNINDENT
.INDENT 7.0
.TP
.B find_cliques()
.INDENT 7.0
.TP
.B Parameters
\fBgraph\fP \-\- graph to which it is necessary to call the cliques for.
.UNINDENT
.sp
Wrapper for the BronKerbosch algorithm, which returns the maximal cliques in the graph.
It is the new interface for the BronKerbosch function, which is not called directly
from outside this class any longer.
The "inters" keyword provides the function used to determine
whether two vertices are connected or not in the graph.
.UNINDENT
.INDENT 7.0
.TP
.B find_communities(graph: networkx.classes.graph.Graph) -> list
.INDENT 7.0
.TP
.B Parameters
\fBgraph\fP (\fInetworkx.Graph\fP) \-\- a Graph instance from networkx
.UNINDENT
.sp
This function is a wrapper around the networkX methods to find
cliques and communities inside a graph.
The method takes as input a precomputed graph and returns
two lists:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
cliques
.IP \(bu 2
communities
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B find_retained_introns(transcript)
This method checks the number of exons that are possibly retained
introns for a given transcript.
A retained intron is defined as an exon which:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
spans completely an intron of another model \fIbetween coding exons\fP
.IP \(bu 2
is not completely coding itself
.IP \(bu 2
has \fIpart\fP of the non\-coding section lying inside the intron
.UNINDENT
.UNINDENT
.UNINDENT
.sp
The results are stored inside the transcript instance,
in the "retained_introns" tuple.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fITranscript\fP) \-\- a Transcript instance
.UNINDENT
.sp
:returns : None
:rtype : None
.UNINDENT
.INDENT 7.0
.TP
.B id
This is a generic string generator for all inherited children.
:rtype : str
.UNINDENT
.INDENT 7.0
.TP
.B classmethod in_locus(locus_instance, transcript, flank=0) -> bool
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBlocus_instance\fP \-\- an inheritor of this class
.IP \(bu 2
\fBtranscript\fP \-\- a transcript instance
.IP \(bu 2
\fBflank\fP (\fIint\fP) \-\- an optional extending parameter to check for neighbours
.UNINDENT
.UNINDENT
.sp
Function to determine whether a transcript should be added or not to the locus_instance.
This is a class method, i.e. it can be used also unbound from any
specific instance of the class.
It will be possible therefore to use it to compare any locus_instance to any transcript.
Arguments:
\- a "locus_instance" object
\- a "transcript" object (it must possess the "finalize" method)
\- flank \- optional keyword
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting(*args, **kwargs)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBargs\fP \-\- positional arguments
.IP \(bu 2
\fBkwargs\fP \-\- keyword arguments
.UNINDENT
.UNINDENT
.sp
This class method defines how two transcript objects will be considered as overlapping.
It is used by the BronKerbosch method, and must be implemented
at the class level for each child object.
.UNINDENT
.INDENT 7.0
.TP
.B logger
Logger instance for the class.
:rtype : logging.Logger
.UNINDENT
.INDENT 7.0
.TP
.B name
Alias for id.
:rtype : str
.UNINDENT
.INDENT 7.0
.TP
.B static overlap()
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfirst_interval\fP (\fI(int,int)\fP) \-\- a tuple of integers
.IP \(bu 2
\fBsecond_interval\fP (\fI(int,int | intervaltree.Interval)\fP) \-\- a tuple of integers
.IP \(bu 2
\fBflank\fP (\fIint\fP) \-\- an optional extending parameter to check for neighbours
.UNINDENT
.UNINDENT
.sp
This static method returns the overlap between two intervals.
.sp
Values<=0 indicate no overlap.
.sp
The optional "flank" argument (default 0) allows to expand a locus
upstream and downstream.
As a static method, it can be used also outside of any instance \-
"abstractlocus.overlap()" will function.
Input: two 2\-tuples of integers.
.UNINDENT
.INDENT 7.0
.TP
.B print_metrics()
This method yields dictionary "rows" that will be given to a csv.DictWriter class.
.UNINDENT
.INDENT 7.0
.TP
.B remove_transcript_from_locus(tid: str)
.INDENT 7.0
.TP
.B Parameters
\fBtid\fP \-\- name of the transcript to remove
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B source
Property. Returns the source field.
:rtype : str
.UNINDENT
.INDENT 7.0
.TP
.B stranded
This property determines whether a Monosublocus will consider
the strand for e.g. the in_locus method.
By default, the parameter is set to True (i.e. the loci are strand\-specific).
At the moment, the only class which modifies the parameter is the superlocus class.
.UNINDENT
.UNINDENT
.SS clique_methods.py
.sp
Module that implements the Reid/Daid/Hurley algorithm for community finding.
.INDENT 0.0
.TP
.B Mikado.loci.clique_methods.reid_daid_hurley(graph, k, cliques=None, logger=None)
Implementation of the Reid\-Daid\-Hurley algorithm for clique percolation
published in \fI\%http://arxiv.org/pdf/1205.0038.pdf\fP
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBgraph\fP (\fInetworkx.Graph\fP) \-\- 
.IP \(bu 2
\fBk\fP \-\- 
.IP \(bu 2
\fBcliques\fP \-\- 
.IP \(bu 2
\fBlogger\fP \-\- optional logger for the function
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.SS excluded.py
.sp
This module defines a containers that hold transcripts excluded from further consideration.
It is invoked when all transcripts in a locus have a score of 0 and the "purge"
option has been enabled.
.INDENT 0.0
.TP
.B class Mikado.loci.excluded.Excluded(monosublocus_instance, json_conf=None, logger=None)
This is a container of discarded transcripts. It is used only for completeness purposes \-
i.e. printing out the discarded transcripts to a separate file.
.INDENT 7.0
.TP
.B add_monosublocus(monosublocus_instance)
Wrapper to extract the transcript from the monosubloci and pass it
to the constructor.
:param monosublocus_instance
:type monosublocus_instance: Mikado.loci_objects.monosublocus.Monosublocus
.UNINDENT
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript, **kwargs)
Override of the sublocus method, and reversal to the original
method in the Abstractlocus class.
:param transcript: a transcript to add
:type transcript: Mikado.loci_objects.transcript.Transcript
.INDENT 7.0
.TP
.B Parameters
\fBkwargs\fP \-\- optional arguments are completely ignored by this method.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B calculate_scores()
Suppress the method from the base class
.UNINDENT
.INDENT 7.0
.TP
.B define_monosubloci()
Suppress the method from the base class
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting()
Present to fulfill the contract with Abstractlocus, but
it only raises a NotImplementedError
.UNINDENT
.UNINDENT
.SS locus.py
.sp
This module defines the last object to be created during the picking,
i.e. the locus.
.INDENT 0.0
.TP
.B class Mikado.loci.locus.Locus(transcript: Mikado.loci.transcript.Transcript, logger=None)
Class that defines the final loci.
It is a child of monosublocus, but it also has the possibility of adding
additional transcripts if they are valid splicing isoforms.
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript: Mikado.loci.transcript.Transcript, **kwargs)
Implementation of the add_transcript_to_locus method.
Before a transcript is added, the class checks that it is a valid splicing isoform
and that we have not exceeded already the maximum number of isoforms for the Locus.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fITranscript\fP) \-\- the candidate transcript
.IP \(bu 2
\fBkwargs\fP \-\- optional keyword arguments are ignored.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B calculate_metrics(tid: str)
.INDENT 7.0
.TP
.B Parameters
\fBtid\fP (\fIstr\fP) \-\- the name of the transcript to be analysed
.UNINDENT
.sp
This function will calculate the metrics for a transcript which are relative in nature
i.e. that depend on the other transcripts in the sublocus. Examples include the fraction
of introns or exons in the sublocus, or the number/fraction of retained introns.
.UNINDENT
.INDENT 7.0
.TP
.B calculate_scores()
Function to calculate a score for each transcript, given the metrics derived
with the calculate_metrics method and the scoring scheme provided in the JSON configuration.
If any requirements have been specified, all transcripts which do not pass them
will be assigned a score of 0 and subsequently ignored.
Scores are rounded to the nearest integer.
.UNINDENT
.INDENT 7.0
.TP
.B get_metrics()
Quick wrapper to calculate the metrics for all the transcripts.
.UNINDENT
.INDENT 7.0
.TP
.B id
Override of the abstractlocus method.
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B is_alternative_splicing(other)
This function defines whether another transcript could be a
putative alternative splice variant of the primary Locus
transcript.
To do so, it compares the candidate against all transcripts in the Locus, and calculates
the class code using scales.Assigner.compare.
If all the matches are "n" or "j", the transcript is considered as an AS event.
.INDENT 7.0
.TP
.B Parameters
\fBother\fP (\fITranscript\fP) \-\- another transcript to compare against
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B is_fragment
:rtype : bool
Flag. It returns the value of self.attributes["is_fragment"]
.UNINDENT
.INDENT 7.0
.TP
.B is_intersecting(*args)
Not implemented: this function makes no sense for a single\-transcript container.
:param args: any argument to this nethod will be ignored.
.UNINDENT
.INDENT 7.0
.TP
.B other_is_fragment(other, minimal_cds_length=0, minimal_exons=2)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBother\fP (\fILocus\fP) \-\- another Locus to compare against
.IP \(bu 2
\fBminimal_cds_length\fP \-\- Minimal CDS length to consider
.UNINDENT
.UNINDENT
.sp
a Locus as non\-fragment, no matter the ccode.
:type minimal_cds_length: int
.INDENT 7.0
.TP
.B Parameters
\fBminimal_exons\fP \-\- Maximum number of exons to consider a
.UNINDENT
.sp
a Locus as non\-fragment, no matter the ccode.
:type minimal_cds_length: int
.sp
This function checks whether another \fImonoexonic\fP Locus
\fIon the opposite strand\fP is a fragment,by checking its classification
according to Assigner.compare.
Briefly, a transcript is classified as fragment
if it follows the following criteria:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
it is monoexonic
.IP \(bu 2
it has a combined_cds_length inferior to maximal_cds
.IP \(bu 2
it is classified as x,i,P
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B primary_transcript
This property returns the primary transcript of the Locus
(i.e. the one which has been used for creation and which has the highest score).
:rtype : Transcript
.UNINDENT
.INDENT 7.0
.TP
.B print_scores()
This method yields dictionary rows that are given to a csv.DictWriter class.
.UNINDENT
.INDENT 7.0
.TP
.B set_json_conf(jconf: dict)
Setter for the configuration dictionary.
:param jconf:
:type jconf: dict
.UNINDENT
.UNINDENT
.SS monosublocus.py
.sp
This module defines monosubloci, an intermediate step between the definition of subloci
and the final definition of loci.
A Monosublocus is characterized by its containing one and only one transcript.
.INDENT 0.0
.TP
.B class Mikado.loci.monosublocus.Monosublocus(transcript_instance, logger=None)
Very basic class which holds a single transcript.
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript, check_in_locus=False)
For this basic class, this method raises a NotImplementedError \-
as this container should hold only one transcript.
.sp
:param transcript
:param check_in_locus: flag. Ignored.
:type check_in_locus: bool
.UNINDENT
.INDENT 7.0
.TP
.B id
Override of the Abstractlocus method, to set the name appropriately.
:rtype : str
.UNINDENT
.INDENT 7.0
.TP
.B is_intersecting()
Not implemented: this function makes no sense for a single\-transcript container.
.UNINDENT
.UNINDENT
.SS monosublocusholder.py
.sp
This module defines a holder of Monosublocus instances. It is the last step
before the definition of real loci.
.INDENT 0.0
.TP
.B class Mikado.loci.monosublocusholder.MonosublocusHolder(monosublocus_instance: Mikado.loci.monosublocus.Monosublocus, json_conf=None, logger=None)
This is a container that groups together the transcripts
surviving the selection for the Monosublocus.
The class inherits from both sublocus and Abstractlocus
(the main abstract class) in order to be able to reuse
some of the code present in the former.
Internally, the most important method is define_loci \-
which will select the best transcript(s) and remove all the overlapping ones.
The intersection function for this object is quite laxer than in previous stages,
and so are the requirements for the inclusion.
.INDENT 7.0
.TP
.B add_monosublocus(monosublocus_instance: Mikado.loci.monosublocus.Monosublocus)
Wrapper to extract the transcript from the monosubloci and pass it to the constructor.
.sp
:param monosublocus_instance
:type monosublocus_instance: Monosublocus
.UNINDENT
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript, check_in_locus=True)
Override of the sublocus method, and reversal to the original
method in the Abstractlocus class.
The check_in_locus boolean flag is used to decide
whether to check if the transcript is in the Locus or not.
This should be set to False for the first transcript, and True afterwards.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fITranscript\fP) \-\- a Transcript instance
.IP \(bu 2
\fBcheck_in_locus\fP \-\- optional flag to pass to the basic method.
.UNINDENT
.UNINDENT
.sp
If set to False it disables checks on whether the transcript
is really in the locus
:type check_in_locus: bool
.UNINDENT
.INDENT 7.0
.TP
.B define_loci(purge=False, excluded=None)
This is the main function of the class. It is analogous
to the define_subloci class defined for sublocus objects,
but it returns "Locus" objects (not "Monosublocus").
.sp
Optional parameters:
.INDENT 7.0
.TP
.B Parameters
\fBpurge\fP \-\- flag. If set to True, all loci whose transcripts
.UNINDENT
.sp
have scores of 0 will be thrown out
into an Excluded holder.
:type purge: bool
.sp
:param excluded
:type excluded: Excluded
.UNINDENT
.INDENT 7.0
.TP
.B define_monosubloci(purge=False, excluded=None)
Overriden and set to NotImplemented to avoid cross\-calling it when inappropriate.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBpurge\fP \-\- flag. Ignored.
.IP \(bu 2
\fBexcluded\fP \-\- flag. Ignored.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B id
Wrapper for the id method of abstractlocus. Necessary to redefine the name.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod in_locus(monosublocus: Mikado.loci.abstractlocus.Abstractlocus, transcript: Mikado.loci.transcript.Transcript, flank=0) -> bool
This method checks whether a transcript / monosbulocus
falls inside the Locus coordinates.
.INDENT 7.0
.TP
.B Return type
bool
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBmonosublocus\fP (\fIMonosublocus\fP) \-\- Monosublocus instance
.IP \(bu 2
\fBtranscript\fP (\fITranscript\fP) \-\- the transcript to be compared
.IP \(bu 2
\fBflank\fP (\fIint\fP) \-\- optional flank argument
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting(transcript, other, cds_only=False, logger=None)
Implementation of the is_intersecting method. Now that we are comparing transcripts that
by definition span multiple subloci, we have to be less strict in our definition of what
counts as an intersection.
Criteria:
\- 1 splice site in common (splice, not junction)
\- If one or both of the transcript is monoexonic OR
one or both lack an ORF, check for any exonic overlap
\- Otherwise, check for any CDS overlap.
.INDENT 7.0
.INDENT 3.5
:param transcript
:type transcript; Transcript
.INDENT 0.0
.TP
.B param other
.TP
.B type other
Transcript
.TP
.B param cds_only
boolean flag. If set to True, only
.UNINDENT
.sp
the CDS component of the transcripts will be considered to determine
whether they are intersecting or not.
:type cds_only: bool
.sp
:rtype : bool
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.SS reference_gene.py
.sp
Pretty basic class that defines a reference gene with its transcripts.
Minimal checks.
.INDENT 0.0
.TP
.B class Mikado.loci.reference_gene.Gene
.INDENT 7.0
.TP
.B Parameters
\fBtranscr\fP \-\- a transcript used to initialize the container.
.UNINDENT
.sp
:param gid:Id of the gene.
:param logger: an optional Logger from the logging module.
.INDENT 7.0
.TP
.B add(transcr: Mikado.loci.transcript.Transcript)
This method adds a transcript to the storage.
:param transcr: the transcript to be added.
.UNINDENT
.INDENT 7.0
.TP
.B add_exon(row)
.INDENT 7.0
.TP
.B Parameters
\fBrow\fP (\fI(GtfLine | GffLine)\fP) \-\- 
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B as_dict(remove_attributes=True)
Method to transform the gene object into a JSON\-friendly representation.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B copy()
Method to return a deep copy of the gene.
.UNINDENT
.INDENT 7.0
.TP
.B exons
It returns the set of all exons in the container.
:rtype : set
.UNINDENT
.INDENT 7.0
.TP
.B finalize(exclude_utr=False)
This method will finalize the container by checking the consistency of all the
transcripts and eventually removing incorrect ones.
.INDENT 7.0
.TP
.B Parameters
\fBexclude_utr\fP \-\- boolean flag
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B has_monoexonic
True if any of the transcripts is monoexonic.
:rtype : bool
.UNINDENT
.INDENT 7.0
.TP
.B introns
It returns the set of all introns in the container.
:rtype : set
.UNINDENT
.INDENT 7.0
.TP
.B is_coding
Property. It evaluates to True if at least one transcript is coding, False otherwise.
.UNINDENT
.INDENT 7.0
.TP
.B logger
Logger instance for the class.
:rtype : logging.Logger
.UNINDENT
.INDENT 7.0
.TP
.B monoexonic
Boolean property. False if at least one transcript is multiexonic,
True otherwise.
:return: bool
:rtype: bool
.UNINDENT
.INDENT 7.0
.TP
.B num_coding_transcripts
Number of coding transcripts
:return:
.UNINDENT
.INDENT 7.0
.TP
.B num_transcripts
Number of transcripts.
:rtype : int
.UNINDENT
.INDENT 7.0
.TP
.B remove(tid: str)
.INDENT 7.0
.TP
.B Parameters
\fBtid\fP \-\- name of the transcript to remove.
.UNINDENT
.INDENT 7.0
.TP
.B This method will remove a transcript from the container, and recalculate the
necessary instance attributes.
.UNINDENT
.UNINDENT
.UNINDENT
.SS sublocus.py
.sp
The Sublocus class is the first to be invoked during the Mikado pick analysis.
Each of these containers holds transcripts which either are monoexonic and overlapping,
or multiexonic and with at least one intron in common.
.INDENT 0.0
.TP
.B class Mikado.loci.sublocus.Sublocus(span, json_conf=None, logger=None)
The sublocus class is created either by the superlocus class during
the subloci definition, or directly using a G(T|F)line\-like object.
It is used to define the monosubloci.
.INDENT 7.0
.TP
.B _Sublocus__check_requirements()
This private method will identify and delete all transcripts which do not pass
the minimum muster specified in the configuration.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _calculate_score(param)
Private method that calculates a score for each transcript,
given a target parameter.
:param param:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B add_transcript_to_locus(transcript: Mikado.loci.transcript.Transcript, **kwargs)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fITranscript\fP) \-\- the transcript which might be putatively added to the Locus.
.IP \(bu 2
\fBkwargs\fP \-\- eventual keyword arguments are ignored.
.UNINDENT
.UNINDENT
.sp
This is an override of the original method, as at the sublocus stage
we need to accomplish a couple of things more:
\- check that transcripts added to the sublocus are either all monoexonic or all multiexonic
\- change the id of the transcripts to the new ID
.UNINDENT
.INDENT 7.0
.TP
.B calculate_metrics(tid: str)
.INDENT 7.0
.TP
.B Parameters
\fBtid\fP (\fIstr\fP) \-\- the name of the transcript to be analysed
.UNINDENT
.sp
This function will calculate the metrics for a transcript which are relative in nature
i.e. that depend on the other transcripts in the sublocus. Examples include the fraction
of introns or exons in the sublocus, or the number/fraction of retained introns.
.UNINDENT
.INDENT 7.0
.TP
.B calculate_scores()
Function to calculate a score for each transcript, given the metrics derived
with the calculate_metrics method and the scoring scheme provided in the JSON configuration.
If any requirements have been specified, all transcripts which do not pass them
will be assigned a score of 0 and subsequently ignored.
Scores are rounded to the nearest integer.
.UNINDENT
.INDENT 7.0
.TP
.B define_monosubloci(purge=False, excluded=None)
.INDENT 7.0
.TP
.B Parameters
\fBpurge\fP \-\- a flag which indicates whether loci whose
.UNINDENT
.sp
best transcript has a score of 0 should be excluded (True) or retained (False)
:type purge: bool
.INDENT 7.0
.TP
.B Parameters
\fBexcluded\fP (\fIMikado.loci_objects.excluded.Excluded\fP) \-\- the excluded Locus to which transcripts from purged loci will be added to
.UNINDENT
.sp
This function retrieves the best non\-overlapping transcripts inside
the sublocus, according to the score calculated by
calculate_scores (explicitly called inside the method).
The "excluded" keyword must contain either None or
a MonosublocusHolder object. It is used to contain
transcripts that must be excluded from the Locus due to unmet requirements.
.UNINDENT
.INDENT 7.0
.TP
.B get_metrics()
Quick wrapper to calculate the metrics for all the transcripts.
.UNINDENT
.INDENT 7.0
.TP
.B id
.INDENT 7.0
.TP
.B Returns
The name of the Locus.
.UNINDENT
.sp
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting(transcript, other, logger=None)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fITranscript\fP) \-\- the first transcript to check
.IP \(bu 2
\fBother\fP (\fITranscript\fP) \-\- the second transcript to check
.IP \(bu 2
\fBlogger\fP (\fI(None | logging.Logger)\fP) \-\- the logger to be used.
.UNINDENT
.UNINDENT
.sp
Implementation of the is_intersecting method. Here at the level of the sublocus,
the intersection is seen as overlap between exons.
.UNINDENT
.INDENT 7.0
.TP
.B load_scores(scores)
.INDENT 7.0
.TP
.B Parameters
\fBscores\fP (\fIdict\fP) \-\- an external dictionary with scores
.UNINDENT
.sp
Simple mock function to load scores for the transcripts from an external dictionary.
.UNINDENT
.INDENT 7.0
.TP
.B prepare_metrics()
This method prepares the dictionary "rows"
that will be given to a csv.DictWriter class.
.UNINDENT
.INDENT 7.0
.TP
.B print_metrics()
THis method yields the dictionary "rows" that will be given to a csv.DictWriter class.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B print_scores()
This method yields dictionary rows that are given to a csv.DictWriter class.
.UNINDENT
.INDENT 7.0
.TP
.B splitted
The splitted flag indicates whether a sublocus
has already been processed to produce the necessary monosubloci.
It must be set as a boolean flag (hence why it is coded as a property)
.sp
:rtype bool
.UNINDENT
.UNINDENT
.SS superlocus.py
.sp
Superlocus module. The class here defined is the uppermost container for transcripts
and is used to define all the possible children (subloci, monoloci, loci, etc.)
.INDENT 0.0
.TP
.B class Mikado.loci.superlocus.Superlocus(transcript_instance, stranded=True, json_conf=None, source=\(aq\(aq, logger=None)
The superlocus class is used to define overlapping regions
on the genome, and it receives as input transcript class instances.
.INDENT 7.0
.TP
.B _Superlocus__create_locus_lines(superlocus_line, new_id, print_cds=True)
Private method to prepare the lines for printing out loci
into GFF/GTF files.
.UNINDENT
.INDENT 7.0
.TP
.B _Superlocus__create_monolocus_lines(superlocus_line, new_id, print_cds=True)
Private method to prepare the lines for printing out monosubloci
into GFF/GTF files.
.UNINDENT
.INDENT 7.0
.TP
.B _Superlocus__create_sublocus_lines(superlocus_line, new_id, print_cds=True)
Private method to prepare the lines for printing out subloci
into GFF/GTF files.
.UNINDENT
.INDENT 7.0
.TP
.B _Superlocus__prefilter_transcripts()
Private method that will check whether there are any transcripts
not meeting the minimum requirements specified in the configuration.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Superlocus__reduce_complex_loci(transcript_graph)
Method which checks whether a locus has too many transcripts and tries to reduce them.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript_graph\fP \-\- the transcript graph to analyse for redundancies
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _load_introns(data_dict)
Private method to load the intron data into the locus.
:param data_dict: Dictionary containing the preloaded data, if available.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B calculate_mono_metrics()
Wrapper to calculate the metrics for the monosubloci.
.UNINDENT
.INDENT 7.0
.TP
.B compile_requirements()
Quick function to evaluate the filtering expression, if it is present.
.UNINDENT
.INDENT 7.0
.TP
.B connect_to_db(engine)
.INDENT 7.0
.TP
.B Parameters
\fBengine\fP (\fIEngine\fP) \-\- the connection pool
.UNINDENT
.sp
This method will connect to the database using the information
contained in the JSON configuration.
.UNINDENT
.INDENT 7.0
.TP
.B define_alternative_splicing()
This method will consider all possible candidates for alternative splicing
for each of the final loci, after excluding transcripts which potentially map
to more than one Locus (in order to remove chimeras).
It will then call the add_transcript_to_locus method to try to add
the transcript to the relevant Locus container.
.UNINDENT
.INDENT 7.0
.TP
.B define_loci()
This is the final method in the pipeline. It creates a container
for all the monosubloci (an instance of the class MonosublocusHolder)
and retrieves the loci it calculates internally.
.UNINDENT
.INDENT 7.0
.TP
.B define_monosubloci()
This is a wrapper method that defines the monosubloci for each sublocus.
.UNINDENT
.INDENT 7.0
.TP
.B define_subloci()
This method will define all subloci inside the superlocus.
Steps:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
Call the BronKerbosch algorithm to define cliques
.IP \(bu 2
Call the "merge_cliques" algorithm the merge the cliques.
.IP \(bu 2
Create "sublocus" objects from the merged cliques
.UNINDENT
.sp
and store them inside the instance store "subloci"
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B format(print_cds=True, level=None)
Alias for __str__.
:param print_cds: Boolean. It indicates whether to print the CDS features or not.
:param level: level which we wish to print for. Can be "loci", "subloci", "monosubloci"
:return: formatted GFF strings
.UNINDENT
.INDENT 7.0
.TP
.B get_sublocus_metrics()
Wrapper function to calculate the metrics inside each sublocus.
.UNINDENT
.INDENT 7.0
.TP
.B id
This is a generic string generator for all inherited children.
:rtype : str
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting(transcript, other, cds_only=False)
:rtype : bool
:param transcript: a transcript for which we wish to verify
whether it is intersecting with another transcript or not.
:type transcript: Mikado.loci_objects.transcript.Transcript
:param other: the transcript which will be used for the comparison.
:type other: Mikado.loci_objects.transcript.Transcript
.INDENT 7.0
.TP
.B Parameters
\fBcds_only\fP \-\- boolean flag. If enabled, only CDS exons/intron
.UNINDENT
.sp
will be considered when deciding whether two transcripts are part
of the same Locus or not.
:type cds_only: bool
.sp
When comparing two transcripts, for the definition of subloci inside
superloci we follow these rules:
.sp
If both are multiexonic, the function verifies whether there is at
least one intron in common.
If both are monoexonic, the function verifies whether there is some overlap between them.
If one is monoexonic and the other is not, the function will return False by definition.
.UNINDENT
.INDENT 7.0
.TP
.B load_all_transcript_data(engine=None, data_dict=None)
This method will load data into the transcripts instances,
and perform the split_by_cds if required
by the configuration.
Asyncio coroutines are used to decrease runtime.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBengine\fP (\fIEngine\fP) \-\- a connection engine
.IP \(bu 2
\fBdata_dict\fP \-\- the dictionary to use for data retrieval, if specified.
.UNINDENT
.UNINDENT
.sp
If None, a DB connection will be established to retrieve the necessary data.
:type data_dict: (None | dict)
.UNINDENT
.INDENT 7.0
.TP
.B load_transcript_data(tid, data_dict)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtid\fP (\fIstr\fP) \-\- the name of the transcript to retrieve data for.
.IP \(bu 2
\fBdata_dict\fP \-\- the dictionary to use for data retrieval, if specified.
.UNINDENT
.UNINDENT
.sp
If None, a DB connection will be established to retrieve the necessary data.
:type data_dict: (None | dict)
.sp
This routine is used to load data for a single transcript.
.UNINDENT
.INDENT 7.0
.TP
.B print_loci_scores()
Wrapper method to create a csv.DictWriter instance and call
the Locus.print_scores method on it.
.UNINDENT
.INDENT 7.0
.TP
.B print_monoholder_metrics()
Wrapper method to create a csv.DictWriter instance and call the
MonosublocusHolder.print_metrics method
on it.
.UNINDENT
.INDENT 7.0
.TP
.B print_monoholder_scores()
Wrapper method to create a csv.DictWriter instance and call
the MonosublocusHolder.print_scores method on it.
.UNINDENT
.INDENT 7.0
.TP
.B print_subloci_metrics()
Wrapper method to create a csv.DictWriter instance and call
the sublocus.print_metrics method
on it for each sublocus.
.UNINDENT
.INDENT 7.0
.TP
.B print_subloci_scores()
Wrapper method to create a csv.DictWriter instance and call the
sublocus.print_metrics method
on it for each sublocus.
.UNINDENT
.INDENT 7.0
.TP
.B split_strands()
This method will divide the superlocus on the basis of the strand.
The rationale is to parse a GFF file without regard for the
strand, in order to find all intersecting loci;
and subsequently break the superlocus into the different components.
Notice that each strand might generate more than one superlocus,
if genes on a different strand link what are
two different superloci.
.UNINDENT
.UNINDENT
.SS transcript.py
.sp
This module defines the RNA objects. It also defines Metric, a property alias.
.INDENT 0.0
.TP
.B class Mikado.loci.transcript.Metric
Simple aliasing of property. All transcript metrics
should use this alias, not "property", as a decorator.
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.loci.transcript.Transcript(*args, *, source=None, logger=None, intron_range=(0, 9223372036854775807), trust_orf=False)
This class defines a transcript, down to its exon/CDS/UTR components.
It is instantiated by a transcript GTF/GFF3 line.
Key attributes:
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBchrom\fP (\fIstr\fP) \-\- The chromosome of the transcript
.IP \(bu 2
\fBfeature\fP \-\- mRNA if at least one CDS is defined, else use the one
.UNINDENT
.UNINDENT
.sp
derived from input; default is "transcript"
:type feature: str
:param start: Start of the transcript. Checked against the exons.
:type start: int
:param end: End of the transcript. Checked against the exons.
:type end: int
:param score: The score assigned to the transcript. Modified inside Mikado.
:type score: float
:param strand: one of +,\-,None
:type strand: str
:param id            the ID of the transcripts (or tid)
:type id: str
:param parent: The parent leaves of the transcript
:type parent: list
:param attributes: a dictionary with additional informations from the GFFline
:type attributes: dict
.sp
After all exons have been loaded into the instance (see "addExon"),
the class must be finalized with the appropriate method.
CDS locations can be uploaded from the external, using a dictionary of indexed BED12 entries.
The database queries are baked at the \fIclass\fP level in order to minimize overhead.
.INDENT 7.0
.TP
.B _Transcript__initialize_with_line(transcript_row)
Private method to copy the necessary attributes from
an external GTF/GFF3 row.
:param transcript_row:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B static _Transcript__wrong_combined_entry(to_test)
Private method to test the correctness of entries for "combined"
data
:param to_test:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B add_derived_child(name)
Method to add a derived child (eg TAIR protein) to a transcript
.UNINDENT
.INDENT 7.0
.TP
.B add_exon(gffline, feature=None)
This function will append an exon/CDS feature to the object.
:param gffline: an annotation line
:type gffline: (Mikado.parsers.GFF.GffLine | Mikado.parsers.GTF.GtfLine | tuple | list)
:type feature: flag to indicate what kind of feature we are adding
.UNINDENT
.INDENT 7.0
.TP
.B add_exons(exons, features=None)
Wrapper of the add_exon method for multiple lines.
:param exons: An iterable of G(tf|ff)lines to iterate, or of tuples of values.
:param features: Optional array with the feature types
:return:
.UNINDENT
.INDENT 7.0
.TP
.B as_bed12()
Method to return a BED12 representation of the transcript object.
.INDENT 7.0
.TP
.B Returns
bed12 representation of the instance
:rtype: Mikado.parsers.bed12.BED12
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B as_dict(remove_attributes=True)
Method to transform the transcript object into a JSON\-friendly representation.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B available_metrics
Return the list of available metrics, using the "get_metrics" function.
.UNINDENT
.INDENT 7.0
.TP
.B best_bits
Metric that returns the best BitS associated with the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B blast_score
Interchangeable alias for testing different blast\-related scores.
Current: best bit score.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B canonical_intron_proportion
.INDENT 7.0
.TP
.B This metric returns the proportion of canonical introns
of the transcript on its total number of introns.
.UNINDENT
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B cdna_length
This property returns the length of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B cds_not_maximal
This property returns the length of the CDS excluded from the selected ORF.
.UNINDENT
.INDENT 7.0
.TP
.B cds_not_maximal_fraction
This property returns the fraction of bases not in the selected ORF compared to
the total number of CDS bases in the cDNA.
.UNINDENT
.INDENT 7.0
.TP
.B cds_tree
This property returns an interval tree of the CDS segments.
Used to calculate the non\-coding parts of the CDS.
:rtype: intervaltree.Intervaltree
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds
This is a list which contains all the non\-overlapping CDS
segments inside the cDNA. The list comprises the segments
as duples (start,end).
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_end
This property returns the location of the end of the combined CDS
for the transcript. If no CDS is defined, it defaults
to the transcript end.
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_fraction
This property return the percentage of the CDS part of the transcript
vs. the cDNA length
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_intron_fraction
This property returns the fraction of CDS introns of the transcript
vs. the total number of CDS introns in the Locus.
If the transcript is by itself, it returns 1.
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_introns
This property returns the introns which are located between CDS
segments in the combined CDS.
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_length
This property return the length of the CDS part of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_num
This property returns the number of non\-overlapping CDS segments
in the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_num_fraction
This property returns the fraction of non\-overlapping CDS segments
in the transcript
vs. the total number of exons
.UNINDENT
.INDENT 7.0
.TP
.B combined_cds_start
This property returns the location of the start of the combined
CDS for the transcript. If no CDS is defined, it defaults
to the transcript start.
.UNINDENT
.INDENT 7.0
.TP
.B combined_utr
This is a list which contains all the non\-overlapping UTR
segments inside the cDNA.
The list comprises the segments as duples (start,end).
.UNINDENT
.INDENT 7.0
.TP
.B combined_utr_fraction
This property returns the fraction of the cDNA which is not coding according
to any ORF. Complement of combined_cds_fraction
.UNINDENT
.INDENT 7.0
.TP
.B combined_utr_length
This property return the length of the UTR part of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B copy()
Method to return a shallow copy of the current instance.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B deepcopy()
Method to return a deep copy of the current instance.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B derived_children
This property stores the names of children features (eg TAIR proteins)
that this transcript gives origin to.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B end_distance_from_junction
This metric returns the cDNA distance between the stop codon and
the last junction in the transcript.
In many eukaryotes, this distance cannot exceed 50\-55 bps
otherwise the transcript becomes a target of NMD.
If the transcript is not coding or there is no junction downstream
of the stop codon, the metric returns 0.
This metric considers the combined CDS end.
.UNINDENT
.INDENT 7.0
.TP
.B end_distance_from_tes
This property returns the distance of the end of the combined CDS
from the transcript end site.
If no CDS is defined, it defaults to 0.
.UNINDENT
.INDENT 7.0
.TP
.B exon_fraction
This property returns the fraction of exons of the transcript
which are contained in the sublocus.
If the transcript is by itself, it returns 1. Set from outside.
.UNINDENT
.INDENT 7.0
.TP
.B exon_num
This property returns the number of exons of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B exons
This property stores the exons of the transcript as (start,end) tuples.
.sp
:rtype : list
.UNINDENT
.INDENT 7.0
.TP
.B finalize()
Function to calculate the internal introns from the exons.
In the first step, it will sort the exons by their internal coordinates.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod find_communities(objects: list) -> list
.INDENT 7.0
.TP
.B Parameters
\fBobjects\fP (\fIlist,set\fP) \-\- a list of objects to analyse
.UNINDENT
.sp
Wrapper for the clique_methods functions.
As we are interested only in the communities, not the cliques,
this wrapper discards the cliques
(first element of the Abstractlocus.find_communities results)
.UNINDENT
.INDENT 7.0
.TP
.B find_overlapping_cds(candidate_orfs)
Thin wrapper for the homonym function in retrieval
:param candidate_orfs: List of candidate ORFs
:return:
.UNINDENT
.INDENT 7.0
.TP
.B five_utr
Returns the exons in the 5\(aq UTR of the selected ORF.
If the start codon is absent, no UTR is given.
.UNINDENT
.INDENT 7.0
.TP
.B five_utr_length
Returns the length of the 5\(aq UTR of the selected ORF.
.UNINDENT
.INDENT 7.0
.TP
.B five_utr_num
This property returns the number of 5\(aq UTR segments for the selected ORF.
.UNINDENT
.INDENT 7.0
.TP
.B five_utr_num_complete
This property returns the number of 5\(aq UTR segments for the selected ORF,
considering only those which are complete exons.
.UNINDENT
.INDENT 7.0
.TP
.B format(format_name, with_introns=False, with_cds=True, all_orfs=False)
Method to format the string representation of the object. Available formats:
\- GFF3 ("gff3", "gff")
\- GTF ("gtf")
\- BED12 ("bed", "bed12")
:param format_name: the name of the format to use
:param with_introns: if True, introns will be printed as well.
:type with_introns: bool
:param with_cds: if set to False, CDS lines will be omitted from the output
:type with_cds: bool
:param all_orfs: boolean flags that indicates whether all ORFs of a transcript
should be printed, or only the primary one (default).
:type: all_orfs: bool
:return: the formatted string
:rtype: str
.UNINDENT
.INDENT 7.0
.TP
.B classmethod get_available_metrics() -> list
This function retrieves all metrics available for the class.
.UNINDENT
.INDENT 7.0
.TP
.B has_start_codon
Boolean. True if the selected ORF has a start codon.
:rtype: bool
.UNINDENT
.INDENT 7.0
.TP
.B has_stop_codon
Boolean. True if the selected ORF has a stop codon.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B highest_cds_exon_number
This property returns the maximum number of CDS segments
among the ORFs; this number can refer to an ORF \fIDIFFERENT\fP
from the maximal ORF.
.UNINDENT
.INDENT 7.0
.TP
.B highest_cds_exons_num
Returns the number of CDS segments in the selected ORF
(irrespective of the number of exons involved)
.UNINDENT
.INDENT 7.0
.TP
.B id
ID of the transcript \- cannot be an undefined value.
.UNINDENT
.INDENT 7.0
.TP
.B internal_orf_lengths
This property returns a list of the lengths of the internal ORFs.
:rtype : list[int]
.UNINDENT
.INDENT 7.0
.TP
.B intron_fraction
This property returns the fraction of introns of the transcript
vs. the total number of introns in the Locus.
If the transcript is by itself, it returns 1. Set from outside.
.UNINDENT
.INDENT 7.0
.TP
.B is_coding
Simple property to investigate whether a transcript is coding or not
:return: boolean value
:rtype: bool
.UNINDENT
.INDENT 7.0
.TP
.B is_complete
Boolean. True if the selected ORF has both start and end.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_intersecting(first, second)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfirst\fP (\fItuple([int, int])\fP) \-\- first exon to check
.IP \(bu 2
\fBsecond\fP (\fItuple([int, int])\fP) \-\- second exon to check
.UNINDENT
.UNINDENT
.sp
:rtype bool
.sp
Implementation of the is_intersecting method.
It checks overlaps between exons.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod is_overlapping_cds(first, second)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfirst\fP \-\- first ORF to check for overlap
.IP \(bu 2
\fBsecond\fP \-\- second ORF to check for overlap
.UNINDENT
.UNINDENT
.sp
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B json_conf
Configuration dictionary. It can be None.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B load_information_from_db(json_conf, introns=None, session=None, data_dict=None)
This method will invoke the check for:
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- Necessary configuration file
.IP \(bu 2
\fBintrons\fP (\fINone,set\fP) \-\- the verified introns in the Locus
.IP \(bu 2
\fBsession\fP (\fIsqlalchemy.orm.session\fP) \-\- an SQLAlchemy session
.IP \(bu 2
\fBdata_dict\fP (\fIdict\fP) \-\- a dictionary containing the information directly
.UNINDENT
.UNINDENT
.sp
Verified introns can be provided from outside using the keyword.
Otherwise, they will be extracted from the database directly.
.UNINDENT
.INDENT 7.0
.TP
.B load_orfs(candidate_orfs)
Thin layer over the load_orfs method from the retrieval module.
:param candidate_orfs: list of candidate ORFs in BED12 format.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B logger
Property. It returns the logger instance attached to the class.
:rtype : logging.Logger | None
.UNINDENT
.INDENT 7.0
.TP
.B max_intron_length
This property returns the greatest intron length for the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B monoexonic
Property. True if the transcript has only one exon, False otherwise.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B non_overlapping_cds
This property returns a set containing the set union of all CDS segments
inside the internal CDSs. In the case of a transcript with no CDS, this is empty.
In the case where there is only one CDS, this returns the combined_cds holder.
In the case instead where there are multiple CDSs, the property will calculate
the set union of all CDS segments.
.UNINDENT
.INDENT 7.0
.TP
.B non_verified_introns_num
This metric returns the number of introns of the transcript which are not validated
by external data.
:rtype : int
.UNINDENT
.INDENT 7.0
.TP
.B num_introns_greater_than_max
This metric returns the number of introns greater
than the maximum acceptable intron size
indicated in the constructor.
:rtype : int
.UNINDENT
.INDENT 7.0
.TP
.B num_introns_smaller_than_min
This metric returns the number of introns smaller
than the mininum acceptable intron size
indicated in the constructor.
:rtype : int
.UNINDENT
.INDENT 7.0
.TP
.B number_internal_orfs
This property returns the number of ORFs inside a transcript.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod overlap(first, second)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBfirst\fP (\fItuple([int, int])\fP) \-\- first exon to check
.IP \(bu 2
\fBsecond\fP (\fItuple([int, int])\fP) \-\- second exon to check
.UNINDENT
.TP
.B Return type
int
.UNINDENT
.sp
This method checks the overlap between two int duplexes.
.UNINDENT
.INDENT 7.0
.TP
.B parent
Name of the parent feature of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B phases
.INDENT 7.0
.TP
.B This property contains the first phase gleaned for each internal ORF from the
GFF. Structure:
.sp
dict[(start,end)] = phase
.UNINDENT
.sp
where (start, end) are the coordinates of the coding segment
.INDENT 7.0
.TP
.B Returns
__phases, a list
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B proportion_verified_introns
This metric returns, as a fraction, how many of the transcript introns
are validated by external data.
.UNINDENT
.INDENT 7.0
.TP
.B proportion_verified_introns_inlocus
This metric returns, as a fraction, how many of the
verified introns inside the Locus
are contained inside the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B remove_exon(exon)
Function to remove an exon properly from a Transcript instance.
:param exon: remove an exon from a Transcript.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B remove_exons(exons)
Wrapper to automate the removal of exons.
:param exons:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B remove_utrs()
Method to strip a transcript from its UTRs.
It will not execute anything if the transcript lacks a CDS or
it has more than one ORF defined.
.UNINDENT
.INDENT 7.0
.TP
.B retained_fraction
This property returns the fraction of the cDNA which
is contained in retained introns.
.UNINDENT
.INDENT 7.0
.TP
.B retained_intron_num
This property records the number of introns in the transcripts
which are marked as being retained.
See the corresponding method in the sublocus class.
.UNINDENT
.INDENT 7.0
.TP
.B reverse_strand()
Method to reverse the strand
.UNINDENT
.INDENT 7.0
.TP
.B score
Numerical value which summarizes the reliability of the transcript.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds
This property return the CDS exons of the ORF selected as best
inside the cDNA, in the form of duplices (start, end)
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_end
This property returns the location of the end
of the best CDS for the transcript.
If no CDS is defined, it defaults to the transcript start.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_exons_fraction
Returns the fraction of CDS segments in the selected ORF
(irrespective of the number of exons involved)
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_fraction
This property calculates the fraction of the selected CDS vs. the cDNA length.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_intron_fraction
This property returns the fraction of CDS introns of
the selected ORF of the transcript vs. the total number
of CDS introns in the Locus (considering only the selected ORF).
If the transcript is by itself, it should return 1.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_introns
This property returns the introns which are located between
CDS segments in the selected ORF.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_length
This property calculates the length of the CDS selected as best inside
the cDNA.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_num
This property calculates the number of CDS exons for the selected ORF
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_number_fraction
This property returns the proportion of best possible CDS segments
vs. the number of exons. See selected_cds_number.
.UNINDENT
.INDENT 7.0
.TP
.B selected_cds_start
This property returns the location of the start
of the best CDS for the transcript.
If no CDS is defined, it defaults to the transcript start.
.UNINDENT
.INDENT 7.0
.TP
.B selected_end_distance_from_junction
This metric returns the distance between the stop codon and the
last junction of the transcript. In many eukaryotes, this distance
cannot exceed 50\-55 bps, otherwise the transcript becomes a target of NMD.
If the transcript is not coding or there is no junction downstream of
the stop codon, the metric returns 0.
.UNINDENT
.INDENT 7.0
.TP
.B selected_end_distance_from_tes
This property returns the distance of the end of the best CDS
from the transcript end site.
If no CDS is defined, it defaults to 0.
.UNINDENT
.INDENT 7.0
.TP
.B selected_internal_orf
This property will return the tuple of tuples of the ORF selected as "best".
To avoid memory wasting, the tuple is accessed in real\-time using
a token (__max_internal_orf_index) which holds the position in the
__internal_cds list of the longest CDS.
.UNINDENT
.INDENT 7.0
.TP
.B selected_internal_orf_cds
This property will return the tuple of tuples of the CDS segments of
the selected ORF inside the transcript. To avoid memory wasting,
the tuple is accessed in real\-time using a token
(__max_internal_orf_index) which holds the position
in the __internal_cds list of the longest CDS.
.UNINDENT
.INDENT 7.0
.TP
.B selected_internal_orf_index
Token which memorizes the position in the ORF list of the selected ORF.
:rtype : None | int
.UNINDENT
.INDENT 7.0
.TP
.B selected_start_distance_from_tss
This property returns the distance of the start of the best CDS
from the transcript start site.
If no CDS is defined, it defaults to 0.
.UNINDENT
.INDENT 7.0
.TP
.B snowy_blast_score
Metric that indicates how good a hit is compared to the competition, in terms of BLAST
similarities.
As in SnowyOwl, the score for each hit is calculated by taking the percentage of positive
matches and dividing it by (2 * len(self.blast_hits)).
IMPORTANT: when splitting transcripts by ORF, a blast hit is added to the new transcript
only if it is contained within the new transcript.
This WILL screw up a bit the homology score.
:return
.UNINDENT
.INDENT 7.0
.TP
.B source_score
This metric returns a score that is assigned to the transcript
in virtue of its origin.
.UNINDENT
.INDENT 7.0
.TP
.B split_by_cds()
This method is used for transcripts that have multiple ORFs.
It will split them according to the CDS information into multiple transcripts.
UTR information will be retained only if no ORF is down/upstream.
.UNINDENT
.INDENT 7.0
.TP
.B start_distance_from_tss
This property returns the distance of the start of the combined CDS
from the transcript start site.
If no CDS is defined, it defaults to 0.
.UNINDENT
.INDENT 7.0
.TP
.B strand
Strand of the transcript. One of None, "\-", "+"
.sp
:rtype str | None
.UNINDENT
.INDENT 7.0
.TP
.B strip_cds(strand_specific=True)
Method to completely remove CDS information from a transcript.
Necessary for those cases where the input is malformed.
.INDENT 7.0
.TP
.B Parameters
\fBstrand_specific\fP \-\- boolean flag. If set to False and the transcript is monoexonic,
.UNINDENT
.sp
the strand will be removed from it.
.UNINDENT
.INDENT 7.0
.TP
.B three_utr
Returns the exons in the 3\(aq UTR of the selected ORF.
If the end codon is absent, no UTR is given.
.UNINDENT
.INDENT 7.0
.TP
.B three_utr_length
Returns the length of the 5\(aq UTR of the selected ORF.
.UNINDENT
.INDENT 7.0
.TP
.B three_utr_num
This property returns the number of 3\(aq UTR segments
(referred to the selected ORF).
.UNINDENT
.INDENT 7.0
.TP
.B three_utr_num_complete
This property returns the number of 3\(aq UTR segments for the selected ORF,
considering only those which are complete exons.
.UNINDENT
.INDENT 7.0
.TP
.B tid
ID of the transcript \- cannot be an undefined value. Alias of id.
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B utr_fraction
This property calculates the length of the UTR
of the selected ORF vs. the cDNA length.
.UNINDENT
.INDENT 7.0
.TP
.B utr_length
Returns the sum of the 5\(aq+3\(aq UTR lengths
.UNINDENT
.INDENT 7.0
.TP
.B utr_num
Returns the number of UTR segments (referred to the selected ORF).
.UNINDENT
.INDENT 7.0
.TP
.B utr_num_complete
Returns the number of UTR segments which are
complete exons (referred to the selected ORF).
.UNINDENT
.INDENT 7.0
.TP
.B verified_introns_num
This metric returns the number of introns of the transcript which are validated
by external data.
:rtype : int
.UNINDENT
.UNINDENT
.SS Transcript methods
.sp
This package contains the modules with the private methods employed by the Transcript class.
.SS Finalizing.py
.sp
This module provides the functions needed to check a transcript for consinstency,
e.g. reliability of the CDS/UTR, sanity of borders, etc.
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__basic_final_checks(transcript)
Function that verifies minimal criteria of a transcript before finalising.
:type transcript: Mikado.loci_objects.transcript.Transcript
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__calculate_introns(transcript)
Private method to create the stores of intron
and splice sites positions.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__calculate_phases(coding, previous)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBcoding\fP \-\- 
.IP \(bu 2
\fBprevious\fP \-\- 
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__check_completeness(transcript)
Private method that checks whether a transcript is complete
or not based solely on the presence of CDS/UTR information.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__check_internal_orf(transcript, index)
Method that verifies that an internal ORF does not have any internal gap.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci.Transcript\fP) \-\- the transcript to analyse
.IP \(bu 2
\fBindex\fP (\fIint\fP) \-\- index of the internal orf to check
.UNINDENT
.TP
.B Returns
the updated transcript
.TP
.B Return type
Mikado.loci.Transcript
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__check_phase_correctness(transcript)
This method verifies that the phases are assigned correctly in the case of a coding transcript.
:param transcript: the input transcript.
:type transcript: Mikado.loci.transcript.Transcript
:return: Mikado.loci.transcript.Transcript
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.__verify_boundaries(transcript)
Method to verify that the start/end of the transcripts are exactly where they should.
Called from finalise.
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing._check_cdna_vs_utr(transcript)
Verify that cDNA + UTR in the transcript add up.
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.finalizing.finalize(transcript)
Function to calculate the internal introns from the exons.
In the first step, it will sort the exons by their internal coordinates.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fIMikado.loci.transcript.Transcript\fP) \-\- the Transcript instance to finalize.
.UNINDENT
.UNINDENT
.SS Retrieval.py
.sp
This module contains the methods used by the Transcript class to retrieve information
from the database/dictionary provided during the pick operation.
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.__create_internal_orf(transcript, orf)
Private method that calculates the assignment of the exons given the
coordinates of the transcriptomic ORF.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBorf\fP (\fIMikado.serializers.orf.Orf\fP) \-\- candidate ORF to transform into an internal ORF
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.__load_blast(transcript)
This method looks into the DB for hits corresponding to the desired requirements.
Hits will be loaded into the "blast_hits" list;
we will not store the SQLAlchemy query object,
but rather its representation as a dictionary
(using the Hit.as_dict() method).
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.__load_verified_introns(transcript, data_dict=None, introns=None)
This method will load verified junctions from the external
(usually the superlocus class).
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBdata_dict\fP (\fI(dict | None)\fP) \-\- the dictionary with data to load
.IP \(bu 2
\fBintrons\fP (\fI(set | None)\fP) \-\- verified introns
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval._connect_to_db(transcript)
This method will connect to the database using the information
contained in the JSON configuration.
:param transcript: the Transcript instance
:type transcript: Mikado.loci_objects.transcript.Transcript
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.check_loaded_orfs(transcript)
This function verifies the ORF status after
loading from an external data structure/database.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the transcript instance
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.find_candidate_orfs(transcript, graph, orf_dictionary) -> list
Function that returns the best non\-overlapping ORFs
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBgraph\fP (\fInetworkx.Graph\fP) \-\- The NetworkX graph to be analysed
.IP \(bu 2
\fBorf_dictionary\fP (\fIdict\fP) \-\- a dictionary which contains the orf indexed by name
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.find_overlapping_cds(transcript, candidates: list) -> list
Wrapper for the Abstractlocus method, used for finding overlapping ORFs.
It will pass to the function the class\(aqs "is_overlapping_cds" method
(which would be otherwise be inaccessible from the Abstractlocus class method).
As we are interested only in the communities, not the cliques,
this wrapper discards the cliques
(first element of the Abstractlocus.find_communities results)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBcandidates\fP (\fIlist[Mikado.serializers.orf.Orf]\fP) \-\- candidate ORFs to analyse
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.load_information_from_db(transcript, json_conf, introns=None, session=None, data_dict=None)
This method will invoke the check for:
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- Necessary configuration file
.IP \(bu 2
\fBintrons\fP (\fINone,set\fP) \-\- the verified introns in the Locus
.IP \(bu 2
\fBsession\fP (\fIsqlalchemy.orm.session\fP) \-\- an SQLAlchemy session
.IP \(bu 2
\fBdata_dict\fP (\fIdict\fP) \-\- a dictionary containing the information directly
.UNINDENT
.UNINDENT
.sp
Verified introns can be provided from outside using the keyword.
Otherwise, they will be extracted from the database directly.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.load_orfs(transcript, candidate_orfs)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBcandidate_orfs\fP (\fIlist[Mikado.serializers.orf.Orf|Mikado.parsers.bed12.BED12]\fP) \-\- The ORFs to be inspected for loading.
.UNINDENT
.UNINDENT
.sp
This method replicates what is done internally by the
"cdna_alignment_orf_to_genome_orf.pl"
utility in the TransDecoder suite. It takes as argument "candidate_orfs"
i.e. a list of BED12 serialised objects.
The method expects as argument a dictionary containing BED entries,
and indexed by the transcript name. The indexed name \fImust\fP equal the
"id" property, otherwise the method returns immediately.
If no entry is found for the transcript, the method exits immediately.
Otherwise, any CDS information present in the original GFF/GTF
file is completely overwritten.
Briefly, it follows this logic:
\- Finalise the transcript
\- Retrieve from the dictionary (input) the CDS object
\- Sort in decreasing order the CDSs on the basis of:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
Presence of start/stop codon
.IP \(bu 2
CDS length (useful for monoexonic transcripts where we might want to set the strand)
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.IP \(bu 2
.INDENT 2.0
.TP
.B For each CDS:
.INDENT 7.0
.IP \(bu 2
.INDENT 2.0
.TP
.B If the ORF is on the + strand:
.INDENT 7.0
.IP \(bu 2
all good
.UNINDENT
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B If the ORF is on the \- strand:
.INDENT 7.0
.IP \(bu 2
if the transcript is monoexonic: invert its genomic strand
.IP \(bu 2
if the transcript is multiexonic: skip
.UNINDENT
.UNINDENT
.IP \(bu 2
Start looking at the exons
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.orf_sorter(orf)
Sorting function for the ORFs."
.INDENT 7.0
.TP
.B Parameters
\fBorf\fP (\fIMikado.serializers.orf.Orf\fP) \-\- an ORF to sort
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.retrieve_from_dict(transcript, data_dict)
Method to retrieve transcript data directly from a dictionary.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.IP \(bu 2
\fBdata_dict\fP (\fI(None | dict)\fP) \-\- the dictionary with loaded data from DB
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.retrieval.retrieve_orfs(transcript)
This method will look up the ORFs loaded inside the database.
During the selection, the function will also remove overlapping ORFs.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the Transcript instance
.UNINDENT
.UNINDENT
.SS Splitting.py
.sp
This module contains the methods used by the Transcript class to split an instance into
multiple transcripts, if the conditions are met (multiple ORFs present and BLAST not
supporting them being part of the same transcript).
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__check_collisions(transcript, nspan, spans)
This method checks whether a new transcript collides with a previously
defined transcript.
:param nspan:
:param spans:
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__create_splitted_exons(transcript, boundary, left, right, orf_strand)
Given a boundary in transcriptomic coordinates, this method will extract the
exons retained in the splitted part of the model.
.INDENT 7.0
.TP
.B Parameters
\fBboundary\fP \-\- the \fItranscriptomic\fP coordinates of start/end of the ORF(s)
.UNINDENT
.sp
to be included in the new transcript
:type boundary: (int,int)
.INDENT 7.0
.TP
.B Parameters
\fBleft\fP \-\- boolean flag indicating whether there is another sub\-transcript
.UNINDENT
.sp
to the left of the one we mean to create, irrespective of \fIgenomic\fP strand
:type left: bool
.INDENT 7.0
.TP
.B Parameters
\fBleft\fP \-\- boolean flag indicating whether there is another sub\-transcript
.UNINDENT
.sp
to the right of the one we mean to create, irrespective of \fIgenomic\fP strand
:type right: bool
.INDENT 7.0
.TP
.B Returns
my_exons (final exons), discarded_exons (eventual discarded exons),
.UNINDENT
.sp
tstart (new transcript start), tend (new transcript end)
:rtype: (list(int,int),list(int,int),int,int)
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__create_splitted_transcripts(transcript, cds_boundaries)
Private method called by split_by_cds to create the various (N>1) transcripts
that are its output.
:param cds_boundaries: a list of int tuples, containing the boundaries
.INDENT 7.0
.INDENT 3.5
of the new transcripts.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__get_boundaries_from_blast(transcript, cds_boundaries, cds_hit_dict)
Private method that calculates the CDS boundaries to keep
given the blast hits. Called by check_split_by_blast
:param cds_boundaries:
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__load_blast_hits(new_transcript, boundary, transcript)
Function to load the BLAST hits into the new splitted transcript.
:param new_transcript: the splitted transcript
:type new_transcript: Mikado.loci_objects.Transcript
:param boundary: tuple(start, end) of the boundary of the new transcript
:type boundary: tuple(int, int)
:param transcript:  the original transcript
:type transcript: Mikado.loci_objects.Transcript
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__recalculate_hit(hit, boundary, minimal_overlap)
Static method to recalculate coverage/identity for new hits.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__relocate_orfs(transcript, bed12_objects, tstart, tend)
Function to recalculate the coordinates of BED12 objects based on
the new transcriptomic start/end
:param bed12_objects: list of the BED12 ORFs to relocate
:param tstart: New transcriptomic start
:param tend: New transcriptomic end
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.__split_complex_exon(transcript, exon, texon, sentinel, boundary, invert=False)
Private method used to split an exon when it is only partially coding,
:param exon: Exon to be analysed
:param texon: Transcriptomic coordinates of the exon
:param sentinel: tuple of boolean flags, it indicates whether there are transcripts on the left
(first member) and/or on the right (second member) of the current instance.
.INDENT 7.0
.TP
.B Parameters
\fBboundary\fP \-\- Transcriptomic coordinates of the ORF boundary.
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.check_common_hits(transcript, cds_hits, old_hits)
This private method verifies whether we have to split a transcript
if there are hits for both ORFs and some of them refer to the same target.
To do so, we check whether the two CDS runs actually share at least one HSPs
(in which case we do NOT want to split); if not, we verify whether the HSPs
cover a large fraction of the target length. If this is the case, we decide to
break down the transcript because we are probably in the presence of a tandem
duplication.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the transcript instance to analyse
.IP \(bu 2
\fBcds_hits\fP \-\- 
.IP \(bu 2
\fBold_hits\fP \-\- 
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.check_split_by_blast(transcript, cds_boundaries)
This method verifies if a transcript with multiple ORFs has support by BLAST to
NOT split it into its different components.
.INDENT 7.0
.TP
.B The minimal overlap between ORF and HSP is defined inside the JSON at the key
["chimera_split"]["blast_params"]["minimal_hsp_overlap"]
.UNINDENT
.sp
basically, we consider a HSP a hit only if the overlap is over a certain threshold
and the HSP evalue under a certain threshold.
.sp
The split by CDS can be executed in three different ways \- PERMISSIVE, LENIENT, STRINGENT:
.INDENT 7.0
.IP \(bu 2
PERMISSIVE: split if two CDSs do not have hits in common,
.UNINDENT
.sp
even when one or both do not have a hit at all.
\- STRINGENT: split only if two CDSs have hits and none
of those is in common between them.
\- LENIENT: split if \fIboth\fP lack hits, OR \fIboth\fP have hits and none
of those is in common.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the transcript instance
.IP \(bu 2
\fBcds_boundaries\fP \-\- 
.UNINDENT
.TP
.B Returns
cds_boundaries
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.loci.transcript_methods.splitting.split_by_cds(transcript)
This method is used for transcripts that have multiple ORFs.
It will split them according to the CDS information into multiple transcripts.
UTR information will be retained only if no ORF is down/upstream.
.INDENT 7.0
.TP
.B Parameters
\fBtranscript\fP (\fIMikado.loci_objects.transcript.Transcript\fP) \-\- the transcript instance
.UNINDENT
.UNINDENT
.SS transcriptchecker.py
.sp
This module defines a child of the Transcript class, which is used
to verify that e.g. the assigned strand is correct.
.INDENT 0.0
.TP
.B class Mikado.loci.transcriptchecker.TranscriptChecker(gffline, seq, strand_specific=False, lenient=False, canonical_splices=((\(aqGT\(aq, \(aqAG\(aq), (\(aqGC\(aq, \(aqAG\(aq), (\(aqAT\(aq, \(aqAC\(aq)), logger=None)
This is a subclass of the generic transcript class. Its purpose is to compare
the information of the transcript instance with the information contained in a
genomic FASTA file, to verify some of the information.
At the moment, the class implements only a check on the strandedness made by extracting
the FASTA sequence of the splice sites and verifying that they are concordant
with the annotated strand.
Keyword arguments:
.INDENT 7.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
strand_specific: if set, monoexonic transcripts are not set to "unknown" strand.
.IP \(bu 2
lenient: boolean. If set to True, a transcript with mixed splices will
.UNINDENT
.sp
not throw an exception but rather will just report the number
of splices supporting each strand.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _check_intron(intron)
Private method that checks whether an intron has canonical splice sites
or not.
:param intron: the intron tuple (int,int) in 1\-base offset
[("AG","GT")]
:return: strand of the intron (None | "+" | "\-")
.UNINDENT
.INDENT 7.0
.TP
.B check_strand()
This method will check that the transcript instance has all the splice sites
on one strand,or at most with non\-canonical (therefore unknowable) splice junctions.
If the transcript is monoexonic and strand_specific is set to False,
the strand of the transcript will be set to None.
.sp
The finalize method is called preliminarly before any operation.
.UNINDENT
.INDENT 7.0
.TP
.B fasta
This property calculates and returns the FASTA sequence associated with
the transcript instance.
The FASTA sequence itself will be formatted to be in lines with 60 characters
(the standard).
:return:
.UNINDENT
.INDENT 7.0
.TP
.B classmethod get_translation_table()
Class method to access the translation table.
.UNINDENT
.INDENT 7.0
.TP
.B static grouper(iterable, num, fillvalue=\(aq\(aq)
Collect data into fixed\-length chunks or blocks. From core documentation.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBiterable\fP \-\- the iterable to be considered for grouping.
.IP \(bu 2
\fBnum\fP (\fIint\fP) \-\- length of the chunks.
.IP \(bu 2
\fBfillvalue\fP (\fIstr\fP) \-\- the default filler for missing positions while grouping.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B classmethod rev_complement(string)
Quick method to perform the reverse complement of a given string,
using the class translation table.
.INDENT 7.0
.TP
.B Parameters
\fBstring\fP (\fIstr\fP) \-\- the sequence to be rev\-complented
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B strand_specific
Flag, set from the constructor. If True, transcript will not have their strand changed.
:rtype: bool
.UNINDENT
.INDENT 7.0
.TP
.B translation_table
Returns the table used to reverse complement FASTA strings.
.UNINDENT
.UNINDENT
.SS Submodule: parsers
.sp
This module defines the iterators that will parse BED12, GTF, GFF files.
.SS bed12.py
.sp
Module to parse BED12 objects. Much more basic than what PyBedtools could offer,
but at the same time more pythonic.
.INDENT 0.0
.TP
.B class Mikado.parsers.bed12.BED12(*args: str, *, fasta_index=None, transcriptomic=False, max_regression=0)
BED12 parsing class.
.INDENT 7.0
.TP
.B _BED12__check_validity(transcriptomic, fasta_index)
Private method that checks that the BED12 object has been instantiated correctly.
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _BED12__set_values_from_fields()
Private method that sets the correct values from the fields derived from the input line.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _max_regression
.INDENT 7.0
.TP
.B This property is used to indicate how far downstream we should go in the
FASTA sequence to find a valid start codon, in terms of percentage
of the the cDNA sequence. So eg in a 300 nt cDNA a max_regression value
of 0.3 would instruct the class to look only for the first 90 bps for
a Met.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B cds_len
Return the length of the internal feature i.e. the CDS:
thickEnd\-thickStart+1
.sp
:rtype int
.UNINDENT
.INDENT 7.0
.TP
.B full_orf
Property. True if the BED12 is transcriptomic and has
both start and stop codon, False otherwise.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B has_start_codon
Property. True if the interval contains a start codon.
:rtype bool
:rtype None
.UNINDENT
.INDENT 7.0
.TP
.B has_stop_codon
Property. True if the interval contains a termination codon.
:rtype bool
:rtype None
.UNINDENT
.INDENT 7.0
.TP
.B id
Property. It returns the name of the feature.
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B invalid
Property. It performs basic checks on the BED line to verify its integrity.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B phase
This property is used for transcriptomic BED objects
and indicates what the phase of the transcript is.
So a BED object with an open 5\(aqORF whose first codon
starts at the 1st base would have frame 1, at the second
frame 2. In all other cases, the frame has to be 0.
If the BED object is not transcriptomic, its frame is null
(None).
.UNINDENT
.INDENT 7.0
.TP
.B strand
Strand of the feature. It must be one of None,+,\-
:rtype None | str
.UNINDENT
.INDENT 7.0
.TP
.B transcriptomic
Flag. If set to True, it indicates the BED contains
transcriptomic rather than genomic coordinates.
:rtype bool
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.bed12.Bed12Parser(handle, fasta_index=None, transcriptomic=False, max_regression=0)
Parser class for a Bed12Parser file.
It accepts optionally a fasta index which is used to
determine whether an ORF has start/stop codons.
.INDENT 7.0
.TP
.B _max_regression
.INDENT 7.0
.TP
.B This property is used to indicate how far downstream we should go in the
FASTA sequence to find a valid start codon, in terms of percentage
of the the cDNA sequence. So eg in a 300 nt cDNA a max_regression value
of 0.3 would instruct the class to look only for the first 90 bps for
a Met.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B bed_next()
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B gff_next()
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.UNINDENT
.SS blast_utils.py
.sp
This module contains generic\-purpose utilities to deal with BLAST XML files.
.INDENT 0.0
.TP
.B class Mikado.parsers.blast_utils.XMLMerger(filenames, log_level=30, log=None)
This class has the purpose of merging on the fly multiple BLAST alignment
files, be they in XML, XML.gz, or ASN.gz format. It uses the _Merger
private class as a background process which bothers itself with the real
work, while this class provides a file\-like interface for external
applications such Bio.Blast.NCBIXML.parse.
.INDENT 7.0
.TP
.B read(size=None)
This method allows the XMLMerger class to act, for all purposes,
like a file\-like interface. The bytes are read from the queue,
delivered by the background _Merger instance.
:param size: optional parameter to indicate how much we want to read
from the file\-like interface.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B run()
Method to start the process. Override of the original Thread method.
:return:
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.blast_utils._Merger(filenames, header, other_queue, logger=None)
This private class acts as a background process behind the XMLMerger class.
This allows the XMLMerger class to appear like a normal read\-only
file\-like objects, allowing compatibility with parsers such as
e.g. Bio.Blast.NCBIXML.parse
.INDENT 7.0
.TP
.B run()
Implementation of the "run" method of the Process mother class.
During the running, _Merger will perform the following:
.INDENT 7.0
.IP \(bu 2
check that the XML header is compatible
.IP \(bu 2
check that the file ends correctly
.IP \(bu 2
append the new lines to the stream
.UNINDENT
.sp
WARNING: as it is impossible to look for the end of a
gzipped file or of a stream, we have to keep all lines in memory
to ascertain that the file we are trying to merge is not corrupt.
This makes unfeasible to use the current implementation for
merging large XML files.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.parsers.blast_utils.check_beginning(handle, filename, previous_header)
Static method to check that the beginning of the XML file is actually correct.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBhandle\fP \-\- handle to the file to check.
.IP \(bu 2
\fBfilename\fP (\fIstr\fP) \-\- name of the file associated with the handle.
.IP \(bu 2
\fBprevious_header\fP \-\- header found in previous file(s).
.UNINDENT
.UNINDENT
.sp
It is used the parameter used for the consinstency check.
:type previous_header: (None | list)
.sp
:return
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.parsers.blast_utils.merge()
This function is used to merge together intervals, which have to be supplied as a list
of duplexes \- (start,stop). The function will then merge together overlapping tuples and
return a list of non\-overlapping tuples.
If the list is composed by only one element, the function returns immediately.
:param intervals: a list of integer duplexes
:type intervals: list
.UNINDENT
.SS blast_xml.py
.sp
Bio.SearchIO parser for BLAST+ XML output formats.
.INDENT 0.0
.TP
.B class Mikado.parsers.blast_xml.BlastXmlParser(handle)
Parser for the BLAST XML format
.INDENT 7.0
.TP
.B _parse_hit(root_hit_elem, query_id)
Generator that transforms Iteration_hits XML elements into Hit objects.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBroot_hit_elem\fP (\fIXML element tag\fP) \-\- root element of the Iteration_hits tag.
.IP \(bu 2
\fBquery_id\fP (\fIstring\fP) \-\- QueryResult ID of this Hit
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _parse_hsp(root_hsp_frag_elem, query_id, hit_id)
Iterator that transforms Hit_hsps XML elements into HSP objects.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBroot_hsp_frag_elem\fP (\fIXML element tag\fP) \-\- the \fBHit_hsps\fP tag
.IP \(bu 2
\fBquery_id\fP (\fIstring\fP) \-\- query ID
.IP \(bu 2
\fBhit_id\fP (\fIstring\fP) \-\- hit ID
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _parse_preamble()
Parses all tag data prior to the first query result.
.UNINDENT
.INDENT 7.0
.TP
.B _parse_qresult()
Parses query results.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.blast_xml.BlastXmlIndexer(filename)
Indexer class for BLAST XML output.
.INDENT 7.0
.TP
.B _parser
alias of \fI\%BlastXmlParser\fP
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.blast_xml.BlastXmlWriter(handle)
Stream\-based BLAST+ XML Writer.
.INDENT 7.0
.TP
.B _adjust_output(hsp, elem, attr)
Adjusts output to mimic native BLAST+ XML as much as possible.
.UNINDENT
.INDENT 7.0
.TP
.B _write_elem_block(block_name, map_name, obj, opt_dict={})
Writes sibling XML elements.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBblock_name\fP (\fIstring\fP) \-\- common element name prefix
.IP \(bu 2
\fBmap_name\fP (\fIstring\fP) \-\- name of mapping between element and attribute names
.IP \(bu 2
\fBobj\fP (\fIobject\fP) \-\- object whose attribute value will be used
.IP \(bu 2
\fBopt_dict\fP (\fIdictionary {string: string}\fP) \-\- custom element\-attribute mapping
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _write_hits(hits)
Writes Hit objects.
.UNINDENT
.INDENT 7.0
.TP
.B _write_hsps(hsps)
Writes HSP objects.
.UNINDENT
.INDENT 7.0
.TP
.B _write_param(qresult)
Writes the parameter block of the preamble.
.UNINDENT
.INDENT 7.0
.TP
.B _write_preamble(qresult)
Writes the XML file preamble.
.UNINDENT
.INDENT 7.0
.TP
.B _write_qresults(qresults)
Writes QueryResult objects into iteration elements.
.UNINDENT
.INDENT 7.0
.TP
.B write_file(qresults)
Writes the XML contents to the output handle.
.UNINDENT
.UNINDENT
.SS gfannotation.py
.sp
This module describes an abstract class which underlies the parsing of
GTF/GFF files.
.INDENT 0.0
.TP
.B class Mikado.parsers.gfannotation.GFAnnotation(line, my_line=\(aq\(aq, header=False)
This abstract class describes a generic GTF/GFF annotation line.
The parsers for those two type of files inherit from this abstract class,
which defines common methods and properties.
.INDENT 7.0
.TP
.B _GFAnnotation__format_middle()
Private method to format the middle fields (score, strand, phase)
for printing.
:return: score, strand, phase
:rtype: str, str, str
.UNINDENT
.INDENT 7.0
.TP
.B _format_attributes()
Abstract method. Each children class should implement its own version,
which allow to prepare the ninth field for printing.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _parse_attributes()
.INDENT 7.0
.TP
.B Abstract method. It is used by the children class to serialise the data
inside the ninth field, which is one of the biggest differences between
GFFs and GTFs.
.UNINDENT
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _sort_feature(feature)
Private method that sorts features according to the normal order in a GF file.
:param feature:
:return: numeric sort index
.UNINDENT
.INDENT 7.0
.TP
.B copy()
Wrapper around the copy.copy function.
.UNINDENT
.INDENT 7.0
.TP
.B is_cds
This property evaluates to True if the row describes a CDS/UTR segment,
False otherwise.
.UNINDENT
.INDENT 7.0
.TP
.B is_exon
Property. True if the feature is CDS/exon/UTR/start or stop codon.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B is_gene
Property. True if the feature ends with "gene" and has no parents.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B phase
Property. Stores the phase of the feature.
Valid values: None, 0, 1 ,2
:return:
.UNINDENT
.INDENT 7.0
.TP
.B score
Score value. Either None or float.
:rtype float | None
.UNINDENT
.INDENT 7.0
.TP
.B strand
Strand attribute. One of None, +, \-
:rtype str | None
.UNINDENT
.UNINDENT
.SS GFF.py
.sp
Module to serialize GFF files.
.INDENT 0.0
.TP
.B class Mikado.parsers.GFF.GFF3(handle)
Class that is used to parse a GFF file.
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.GFF.GffLine(line, my_line=\(aq\(aq, header=False)
Object which serializes a GFF line.
.INDENT 7.0
.TP
.B _format_attributes()
Implementation of the abstract method for formatting the
ninth field of a GFF.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _parse_attributes()
Private method that parses the last field of the GFF line.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B derived_from
Property, Set to True if the key "Derives_from" is present among the
instance attributes.
.UNINDENT
.INDENT 7.0
.TP
.B gene
Property. If the feature is a transcript,
returns the parent; else, it returns None
(as only transcript lines have the gene among the attributes)
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B id
Returns the ID of the feature.
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B is_derived
Property. It checks whether there is a "Derives_from" attribute among the line attributes.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B is_parent
Property. True if the feature has no parent defined.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B is_transcript
Property. True if the feature is an RNA, false otherwise.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B name
Returns the name of the feature. It defaults to the ID if missing.
.sp
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B parent
This property looks up the "Parent" field in the "attributes" dictionary.
Contrary to other attributes, this property returns a \fIlist\fP, not a string.
This is due to the fact that GFF files support
multiple inheritance by separating the parent entries with a comma.
.sp
:rtype list
.UNINDENT
.INDENT 7.0
.TP
.B transcript
Property. If the feature is a transcript, it returns the id;
if it is an exon, it returns the parent; else, it returns None
.sp
:rtype str
:rtype list
:rtype None
.UNINDENT
.UNINDENT
.SS GTF.py
.sp
Generic parser for GTF files.
.INDENT 0.0
.TP
.B class Mikado.parsers.GTF.GTF(handle)
The parsing class.
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.parsers.GTF.GtfLine(line, my_line=\(aq\(aq, header=False)
This class defines a typical GTF line, with some added functionality
to make it useful in e.g. parsing cufflinks GTF files or
creating GTF lines from scratch.
Fields:
\- chrom
\- source
\- feature
\- start,end
\- score
\- phase
\- strand
\- info (a dictionary containing all the annotations contained in the last field)
.INDENT 7.0
.IP \(bu 2
gene: the gene_id
.IP \(bu 2
transcript: the transcript_id
.UNINDENT
.sp
For cufflinks files, also:
\- nearest_ref
\- tss_id
\- ccode
.INDENT 7.0
.TP
.B _format_attributes()
Private method to format the last field of the GTF line
prior to printing.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _parse_attributes()
Method to retrieve the attributes from the last field
of the GTF line.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B derived_from
Boolean property. True if the GTF line has a "derives_from" tag,
False otherwise.
.UNINDENT
.INDENT 7.0
.TP
.B frame
Frame of the GTF record line. It can be one of None, 0, 1, 2.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B gene
Return the "gene_id" field.
:rtype : str | None
.UNINDENT
.INDENT 7.0
.TP
.B id
ID of the line. "transcript_id" for transcript features, None in all other cases.
:rtype : str | None
.UNINDENT
.INDENT 7.0
.TP
.B is_derived
Property. It checks whether there is a "Derives_from" attribute among the line attributes.
:rtype bool
.UNINDENT
.INDENT 7.0
.TP
.B is_gene
In a GTF this should always evaluate to False
.UNINDENT
.INDENT 7.0
.TP
.B is_parent
True if we are looking at a transcript, False otherwise.
:rtype : bool
.UNINDENT
.INDENT 7.0
.TP
.B is_transcript
Flag. True if feature is "transcript" or contains "RNA", False in all other cases.
:rtype : bool
.UNINDENT
.INDENT 7.0
.TP
.B name
Returns the name of the feature. It defaults to the ID if missing.
:rtype str
.UNINDENT
.INDENT 7.0
.TP
.B parent
This property looks up the "Parent" field in the "attributes" dictionary.
If the line is a transcript line, it returns the gene field.
Otherwise, it returns the transcript field.
In order to maintain interface consistency with
the GFF objects and contrary to other attributes,
this property returns a \fIlist\fP, not a string. This is due
to the fact that GFF files support
multiple inheritance by separating the parent entries with a comma.
.sp
:rtype : list
.UNINDENT
.INDENT 7.0
.TP
.B transcript
This property returns the "transcript_id" field of the GTF line.
:rtype : str
.UNINDENT
.UNINDENT
.SS Submodule: picking
.SS loci_process.py
.INDENT 0.0
.TP
.B class Mikado.picking.loci_processer.LociProcesser(json_conf, data_dict, output_files, locus_queue, logging_queue, identifier, tempdir=\(aqmikado_pick_tmp\(aq)
This process class takes care of getting from the queue the loci,
analyse them, and print them to the output files.
.INDENT 7.0
.TP
.B _print_locus(stranded_locus, counter)
Private method that handles a single superlocus for printing.
It also detects and flags/discard fragmentary loci.
:param stranded_locus: the stranded locus to analyse
:return:
.UNINDENT
.INDENT 7.0
.TP
.B run()
Start polling the queue, analyse the loci, and send them to the printer process.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.picking.loci_processer.analyse_locus()
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBslocus\fP (\fIMikado.loci_objects.superlocus.Superlocus\fP) \-\- a superlocus instance
.IP \(bu 2
\fBcounter\fP (\fIint\fP) \-\- an integer which is used to create the proper name for the locus.
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- the configuration dictionary
.IP \(bu 2
\fBlogging_queue\fP (\fImultiprocessing.managers.AutoProxy\fP) \-\- the logging queue
.IP \(bu 2
\fBprinter_queue\fP (\fImultiprocessing.managers.AutoProxy\fP) \-\- the printing queue
.IP \(bu 2
\fBengine\fP \-\- an optional engine to connect to the database.
.IP \(bu 2
\fBdata_dict\fP (\fI(None|dict)\fP) \-\- a dictionary of preloaded data
.UNINDENT
.UNINDENT
.sp
This function takes as input a "superlocus" instance and the pipeline configuration.
It also accepts as optional keywords a dictionary with the CDS information
(derived from a Bed12Parser) and a "lock" used for avoiding writing collisions
during multithreading.
The function splits the superlocus into its strand components and calls the relevant methods
to define the loci.
When it is finished, it transmits the superloci to the printer function.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.picking.loci_processer.merge_loci(num_temp, out_handles, prefix=\(aq\(aq, tempdir=\(aqmikado_pick_tmp\(aq)
.INDENT 7.0
.TP
.B Function to merge the temporary loci files into single output files,
renaming the genes according to the preferred style.
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBnum_temp\fP \-\- number of temporary files.
.IP \(bu 2
\fBout_handles\fP \-\- The names of the output loci files.
.IP \(bu 2
\fBprefix\fP \-\- Prefix to use for the gene names.
.IP \(bu 2
\fBtempdir\fP \-\- Temporary directory where the temporary files are located.
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.picking.loci_processer.merge_loci_gff(gff_filenames, gff_handle, prefix=\(aq\(aq)
This function will merge different partial GFF files into a single loci file,
while changing the names to reflect the ordering.
:param gff_filenames:
:param gff_handle:
:param prefix:
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.picking.loci_processer.print_gene(current_gene, gene_counter, handle, prefix)
This function takes a gene and reformats it using the new derived name.
:param current_gene: a dictionary with the data for the current gene.
:type current_gene: dict
:param gene_counter: A counter to be used inside the genes
:type gene_counter: int
:param handle: The handle to the file to print to
:type handle: io.TextIOWrapper
:param prefix: the prefix to add to the name of the genes
:type prefix: str
:return: a dictionary with the correspondeces for the transcripts
:rtype: dict
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.picking.loci_processer.remove_fragments(stranded_loci, json_conf, logger)
This method checks which loci are possible fragments, according to the
parameters provided in the configuration file, and tags/remove them according
to the configuration specification.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBstranded_loci\fP (\fIlist[Superlocus]\fP) \-\- a list of the loci to consider for fragment removal
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- the configuration dictionary
.IP \(bu 2
\fBlogger\fP (\fIlogging.Logger\fP) \-\- the logger
.UNINDENT
.UNINDENT
.UNINDENT
.SS picker.py
.sp
This module defines the Picker class, which is the main workhorse for Mikado pick.
.INDENT 0.0
.TP
.B class Mikado.picking.picker.Picker(json_conf, commandline=\(aq\(aq)
This class is used to launch the main Mikado pipeline. Its purpose is to parse
an input sorted annotation file, locate the loci, and perform the selection analysis
using the parameters provided in the input configuration file.
.INDENT 7.0
.TP
.B _Picker__get_output_files()
Private method used by printer to prepare all the output files.
:return: ((locus_metrics, locus_scores, locus_out),
.INDENT 7.0
.INDENT 3.5
(sub_metrics, sub_scores, sub_out),
mono_out)
all of these are file handles
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__preload_blast(engine, queries)
Private method to load all the blast information
into a specific dictionary.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBengine\fP \-\- the connection engine from the preloading thread
.IP \(bu 2
\fBqueries\fP \-\- a dictionary containing the name=>ID relationship
for queries
.UNINDENT
.TP
.B Returns hits_dict
a dictionary with the loaded BLAST data
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__print_gff_headers(locus_out, score_keys)
Private method to print the GFF headers of the output files.
Moreover, it will determine whether to start output files for
subloci and/or monoloci.
Returns: [subloci_metrics_handle, subloci_scores_handle, subloci_handle],
.INDENT 7.0
.INDENT 3.5
monosubloci_outfile
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__submit_multi_threading(data_dict)
Method to execute Mikado pick in multi threaded mode.
.INDENT 7.0
.TP
.B Parameters
\fBdata_dict\fP \-\- The data dictionary
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__submit_single_threaded(data_dict)
Method to execute Mikado pick in single threaded mode.
:param data_dict:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__test_sortedness(row, current_transcript)
Private method to test whether a row and the current transcript are actually in the expected
sorted order.
:param row:
:param current_transcript:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Picker__unsorted_interrupt(row, current_transcript)
.INDENT 7.0
.TP
.B Private method that brings the program to a screeching halt
if the GTF/GFF is not properly sorted.
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBrow\fP \-\- 
.IP \(bu 2
\fBcurrent_transcript\fP \-\- 
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _parse_and_submit_input(data_dict)
This method does the parsing of the input and submission of the loci to the
_submit_locus method.
:param data_dict: The cached data from the database
:return: jobs (the list of all jobs already submitted)
.UNINDENT
.INDENT 7.0
.TP
.B _print_locus(stranded_locus, gene_counter, logger=None, handles=())
Private method that handles a single superlocus for printing.
It also detects and flags/discard fragmentary loci.
:param stranded_locus: the stranded locus to analyse
:param gene_counter: A counter used to rename the genes/transcripts progressively
:param logger: logger instance
:param handles: the handles to print to
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _submit_locus(slocus, counter, data_dict=None, engine=None)
Private method to submit / start the analysis of a superlocus in input.
:param slocus: the locus to analyse.
:param data_dict: the preloaded data in memory
:param engine: connection engine
:return: job object / None
.UNINDENT
.INDENT 7.0
.TP
.B define_input()
Function to check that the input file exists and is valid. It returns the parser.
.UNINDENT
.INDENT 7.0
.TP
.B preload()
This method preloads the data from the DB into a dictionary ("data_dict").
The information on what to extract and how to connect to the
DB is retrieved from the json_conf dictionary.
:return: data_dict
:rtype: dict
.UNINDENT
.INDENT 7.0
.TP
.B setup_logger()
This function sets up the logger for the class.
It creates the instance attribute "log_writer", which is itself a
logging.handlers.QueueListener instance listening on the logging_queue
instance attribute (which is a normal mp.Manager.Queue instance).
.UNINDENT
.INDENT 7.0
.TP
.B setup_shm_db()
This method will copy the SQLite input DB into memory.
.UNINDENT
.UNINDENT
.SS Submodule: preparation
.SS annotation_parser.py
.INDENT 0.0
.TP
.B Mikado.preparation.annotation_parser.load_from_gff(exon_lines, gff_handle, label, found_ids, logger, strip_cds=False, strand_specific=False)
Method to load the exon lines from GFF3 files.
:param exon_lines: the defaultdict which stores the exon lines.
:param gff_handle: The handle for the GTF to be parsed.
:param label: label to be attached to all transcripts.
:type label: str
:param found_ids: set of IDs already found in other files.
:type found_ids: set
:param logger: a logger to be used to pass messages
:type logger: logging.Logger
:param strip_cds: boolean flag. If true, all CDS lines will be ignored.
:type strip_cds: bool
:param strand_specific: whether the assembly is strand\-specific or not.
:type strand_specific: bool
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.preparation.annotation_parser.load_from_gtf(exon_lines, gff_handle, label, found_ids, logger, strip_cds=False, strand_specific=False)
Method to load the exon lines from GTF files.
:param exon_lines: the defaultdict which stores the exon lines.
:type exon_lines: (collections.defaultdict|None)
:param gff_handle: The handle for the GTF to be parsed.
:param label: label to be attached to all transcripts.
:type label: str
:param found_ids: set of IDs already found in other files.
:type found_ids: set
:param logger: a logger to be used to pass messages
:type logger: logging.Logger
:param strip_cds: boolean flag. If true, all CDS lines will be ignored.
:type strip_cds: bool
:param strand_specific: whether the assembly is strand\-specific or not.
:type strand_specific: bool
:return:
.UNINDENT
.SS checking.py
.INDENT 0.0
.TP
.B Mikado.preparation.checking.create_transcript(lines, fasta_seq, start, end, lenient=False, strand_specific=False, canonical_splices=((\(aqGT\(aq, \(aqAG\(aq), (\(aqGC\(aq, \(aqAG\(aq), (\(aqAT\(aq, \(aqAC\(aq)), logger=None)
Function to create the checker.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBlines\fP (\fIdict\fP) \-\- all the exon lines for an object
.IP \(bu 2
\fBfasta_seq\fP \-\- genomic sequence of the transcript
.IP \(bu 2
\fBstart\fP (\fIint\fP) \-\- start position for the transcript
.IP \(bu 2
\fBend\fP (\fIint\fP) \-\- end position for the transcript
.IP \(bu 2
\fBcanonical_splices\fP (\fIlist[tuple]\fP) \-\- the splices considered as canonical for the species.
.IP \(bu 2
\fBlogger\fP \-\- optional logger to use during processing.
.UNINDENT
.TP
.B Return type
(None|TranscriptChecker)
.UNINDENT
.UNINDENT
.SS prepare.py
.INDENT 0.0
.TP
.B Mikado.preparation.prepare.load_exon_lines(args, logger)
.INDENT 7.0
.TP
.B This function loads all exon lines from the GFF inputs into a
defaultdict instance.
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBargs\fP \-\- the Namespace from the command line.
.IP \(bu 2
\fBlogger\fP (\fIlogging.Logger\fP) \-\- the logger instance.
.UNINDENT
.TP
.B Returns
exon_lines
.TP
.B Return type
collections.defaultdict[list]
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.preparation.prepare.perform_check(keys, exon_lines, args, logger)
This is the most important method. After preparing the data structure,
this function creates the real transcript instances and checks that
they are correct when looking at the underlying genome sequence.
This is also the point at which we start using multithreading, if
so requested.
:param keys: sorted list of [tid, sequence]
:param exon_lines: dictionary hosting the exon lines, indexed by TID
:param args: the namespace
:param logger: logger
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.preparation.prepare.prepare(args, logger)
Main script function.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBargs\fP \-\- the ArgumentParser\-derived namespace.
.IP \(bu 2
\fBlogger\fP (\fIlogging.Logger\fP) \-\- a logging instance
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.preparation.prepare.store_transcripts(exon_lines, logger, min_length=0)
Function that analyses the exon lines from the original file
and organises the data into a proper dictionary.
:param exon_lines: dictionary of exon lines, ordered by TID
:type exon_lines: dict
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBlogger\fP (\fIlogging.Logger\fP) \-\- logger instance.
.IP \(bu 2
\fBmin_length\fP \-\- minimal length of the transcript.
.UNINDENT
.UNINDENT
.sp
If it is not met, the transcript will be discarded.
:type min_length: int
.INDENT 7.0
.TP
.B Returns
transcripts: dictionary which will be the final output
.TP
.B Return type
transcripts
.UNINDENT
.UNINDENT
.SS Submodule: scales
.sp
This module defines the classes needed for the "compare" script, namely:
.INDENT 0.0
.IP \(bu 2
.INDENT 2.0
.TP
.B result_storer:    a glorified struct to
hold the comparison results of a prediction vs. the reference
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B reference_gene:   data structure which holds the transcripts of a gene.
No check is performed \- transcripts are grouped according
to their parent information.
.UNINDENT
.IP \(bu 2
.INDENT 2.0
.TP
.B assigner:         Main workhorse of the sublibrary. This class
assigns each transcript to its best match(es) in the reference annotation.
.UNINDENT
.IP \(bu 2
accountant:       This class calculates the final summary statistics for the comparison.
.UNINDENT
.SS Accountant.py
.sp
This class is used to store all the data calculated by the Assigner class, in order to produce
the RefMap/Stats files.
.INDENT 0.0
.TP
.B class Mikado.scales.accountant.Accountant(genes: dict, args: argparse.Namespace)
This class stores the data necessary to calculate the final statistics
\- base and exon Sn/Sp/F1 etc.
.INDENT 7.0
.TP
.B _Accountant__calculate_exon_stats()
This private method calculates the raw numbers regarding base and exon statistics.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__calculate_gene_stats()
Private method that calculates the number of found transcripts
in the reference and prediction sets. Wrapper around a double
call to __retrieve_gene_stats
:return: double the result of __retrieve_gene_stats
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__calculate_intron_stats()
This private method calculates the raw numbers regarding intron and intron chain statistics.
:return: result_dictionary
:rtype: dict
.UNINDENT
.INDENT 7.0
.TP
.B static _Accountant__calculate_statistics(common, pred, ref)
Function to calculate precision, recall and F1 given
the numbers in common, of the prediction, and of the reference
:param common:
:param pred:
:param ref:
:return: precision, recall, f1stat
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__extract_internal_stats(result_dictionary)
Private method that extracts the internal stats from the stored
data and updates the result_dictionary dictionary.
:param result_dictionary: the dictionary that stores the results
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__extract_terminal_stats(result_dictionary)
Private method to
:param result_dictionary: the results dictionary
:type result_dictionary: dict
:return: updated result dictionary
:rtype: dict
.UNINDENT
.INDENT 7.0
.TP
.B classmethod _Accountant__format_comparison_line(name, private, total)
Method to create the string that will be printed out to screen for the stats file.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B classmethod _Accountant__format_comparison_segments(name, private, common)
Method to create the string that will be printed out to screen for the stats file.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B static _Accountant__format_rowname(stru)
Private method to format the name of the rows in the stats table
:param stru:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B static _Accountant__redundant_stats(common_pred, common_ref, pred, ref)
Function to calculate precision, recall and F1 given the numbers of:
\- predictions which are matches
\- reference which are matches
\- total predictions
\- total references
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBcommon_pred\fP \-\- number of predictions which are a match
.IP \(bu 2
\fBcommon_ref\fP \-\- number of references which are a match
.IP \(bu 2
\fBpred\fP \-\- total number of predictions
.IP \(bu 2
\fBref\fP \-\- total number of references
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__retrieve_gene_stats(store_name=\(aqref\(aq)
This private method recovers from the pred/ref store the statistics regarding the
number of genes and transcripts found and missed,
both stringently and leniently.
The keyword store_name, which must evaluate to either
"ref"
or
"pred",
indicates whether we are intersted in prediction of reference data.
:param store_name: str
:return: { "stringent": (transcript_stringent, gene_stringent),
.INDENT 7.0
.INDENT 3.5
"lenient": (transcript_lenient, gene_lenient),
"total": total_transcripts,
"private": (private_transcripts, private_genes)
}
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__setup_logger()
Private method to set up the logger using indications in the
args namespace.
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__setup_reference_data(genes)
Private method that prepares the reference data into the data structure
that will be used to compare each prediction with a reference transcript.
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__store_monoexonic_result(transcr, strand, result: Mikado.scales.resultstorer.ResultStorer, other_exon=None)
Private procedure to store the comparison of a monoexonic
transcript with the reference.
:param transcr: the monoexonic transcript
:param strand: the strand to be used for storing
:param other_exon: the reference exon this transcript is assigned to
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__store_multiexonic_reference(transcr, strand)
Private method to store a multiexonic reference transcript.
:param transcr:
:param strand:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Accountant__store_multiexonic_result(transcr, strand, result)
Private procedure to store the results regarding a multiexonic
transcript compared to the reference.
:param transcr: a transcript instance
:param strand: the strand to be used for storing
:param result: a ResultStorer instance
:return:
.UNINDENT
.INDENT 7.0
.TP
.B print_stats()
This method calculates and prints the final stats file.
It is called when the prediction file
parsing has been terminated correctly.
.UNINDENT
.INDENT 7.0
.TP
.B store(transcr: Mikado.loci.transcript.Transcript, result: Mikado.scales.resultstorer.ResultStorer, other_exon)
Add exons introns intron chains etc. to the storage.
:param transcr: a "Transcript" instance
:param result: Instance of "result_storer"
:param other_exon: either None or an integer duplex
:type other_exon: None | (int,int)
.INDENT 7.0
.TP
.B A transcript is considered a perfect match if it has:
junction_f1==100 and nucleotide_f1==100;
.UNINDENT
.sp
a lenient match if it has junction_f1==100 and nucleotide_f1>95,
i.e. min(nucleotide_precision, nucleotide_recall)>90.4
.UNINDENT
.UNINDENT
.SS Assigner.py
.sp
This class is the main workhorse of the compare.py utility.
.INDENT 0.0
.TP
.B class Mikado.scales.assigner.Assigner(genes: dict, positions: collections.defaultdict, args: argparse.Namespace, stat_calculator: Mikado.scales.accountant.Accountant)
This class has the purpose of assiging each prediction transcript to its best match
among the reference transcripts.
.INDENT 7.0
.TP
.B _Assigner__check_for_fusions(prediction, matches)
This private method checks whether a transcript with
multiple matches at distance 0 is indeed a fusion, or not.
:param prediction:
:param matches:
:type matches: list
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Assigner__prepare_result(prediction, distances)
This private method prepares the matching result for cases where the
minimum distance from a reference gene/transcript is 0.
:param prediction:
:param distances:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _Assigner__prepare_transcript(prediction: Mikado.loci.transcript.Transcript)
Private method that checks that a prediction transcript is OK
before starting to analyse its concordance with the reference.
:param prediction:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B add_to_refmap(result: Mikado.scales.resultstorer.ResultStorer) -> None
.INDENT 7.0
.TP
.B Parameters
\fBresult\fP \-\- the result of the compare function
.UNINDENT
.sp
This method verifies whether the comparison in input is the best available for the
candidate reference gene, and loads it into the refmap dictionary if such is the case.
.UNINDENT
.INDENT 7.0
.TP
.B calc_and_store_compare(prediction: Mikado.loci.transcript.Transcript, reference: Mikado.loci.transcript.Transcript) -> Mikado.scales.resultstorer.ResultStorer
Thin layer around the calc_and_store_compare class method.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBprediction\fP \-\- a Transcript instance.
.IP \(bu 2
\fBreference\fP \-\- a Transcript instance to which the prediction is compared to.
.UNINDENT
.UNINDENT
.sp
:rtype ResultStorer
.UNINDENT
.INDENT 7.0
.TP
.B static compare()
Function to compare two transcripts and determine a ccode. Thin wrapper
around the compare cython code.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBprediction\fP (\fITranscript\fP) \-\- the transcript query
.IP \(bu 2
\fBreference\fP \-\- the reference transcript against which we desire to
.UNINDENT
.UNINDENT
.sp
calculate the ccode and other stats.
:type reference: Transcript
.sp
:rtype (ResultStorer, (int,int)) | (ResultStorer, None)
.sp
Available ccodes (from Cufflinks documentation):
.INDENT 7.0
.IP \(bu 2
=    Complete intron chain match
.IP \(bu 2
c    Contained (perfect junction recall and precision, imperfect recall)
.IP \(bu 2
j    Potentially novel isoform (fragment): at least one splice junction is shared
.UNINDENT
.sp
with a reference transcript
\- e    Single exon transfrag overlapping a reference exon and at least
10 bp of a reference intron, indicating a possible pre\-mRNA fragment.
\- i    A \fImonoexonic\fP transfrag falling entirely within a reference intron
\- o    Generic exonic overlap with a reference transcript
\- p    Possible polymerase run\-on fragment (within 2Kbases of a reference transcript)
\- u    Unknown, intergenic transcript
\- x    Exonic overlap with reference on the opposite strand (class codes e, o, m, c, _)
\- X    Overlap on the opposite strand, with some junctions in common (probably a serious mistake,
.INDENT 7.0
.INDENT 3.5
unless non\-canonical splicing junctions are involved).
.UNINDENT
.UNINDENT
.sp
Please note that the description for i is changed from Cufflinks.
.sp
We also provide the following additional classifications:
.INDENT 7.0
.IP \(bu 2
f    gene fusion \- in this case, this ccode will be followed by the
.UNINDENT
.sp
ccodes of the matches for each gene, separated by comma
\- _    Complete match, for monoexonic transcripts
(nucleotide F1>=80% \- i.e. min(precision,recall)>=66.7%
\- m    Exon overlap between two monoexonic transcripts
\- n    Potential extension of the reference \- we have added new splice junctions
\fIoutside\fP the boundaries of the transcript itself
\- C    Contained transcript with overextensions on either side
(perfect junction recall, imperfect nucleotide specificity)
\- J    Potentially novel isoform, where all the known junctions
have been confirmed and we have added others as well \fIexternally\fP
\- I    \fImultiexonic\fP transcript falling completely inside a known transcript
\- h    AS event in which at least a couple of introns overlaps but without any
.INDENT 7.0
.INDENT 3.5
junction in common.
.UNINDENT
.UNINDENT
.INDENT 7.0
.IP \(bu 2
O    Reverse generic overlap \- the reference is monoexonic while the prediction isn\(aqt
.IP \(bu 2
P    Possible polymerase run\-on fragment
.IP \(bu 2
mo   Monoexonic overlap \- the prediction is monoexonic and the reference is multiexonic
.UNINDENT
.sp
(within 2K bases of a reference transcript), on the opposite strand
.sp
This is a class method, and can therefore be used outside of a class instance.
.UNINDENT
.INDENT 7.0
.TP
.B static dubious_getter(dubious_result)
Function used to perform the sorting of the matches.
:param dubious_result: a result
:type dubious_result: ResultStorer
.UNINDENT
.INDENT 7.0
.TP
.B classmethod find_neighbours(keys, position, distance=2000)
This class method is used to find the possible matches of a given prediction key.
:param keys: the start
:type keys: Mikado.scales.intervaltree.IntervalTree
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBposition\fP (\fI(int, int)\fP) \-\- the position of my prediction in the genome
.IP \(bu 2
\fBdistance\fP \-\- optional maximum distance of a prediction
.UNINDENT
.UNINDENT
.sp
from reference before being called an unknown
:type distance: int
.INDENT 7.0
.TP
.B Returns
a list of distances, with the following format:
(start, end), distance
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B finish()
This function is called upon completion of the input file parsing.
It will print out the reference file assignments into the refmap
file, and the final statistics into the stats file.
.UNINDENT
.INDENT 7.0
.TP
.B get_best(prediction: Mikado.loci.transcript.Transcript)
.INDENT 7.0
.TP
.B Parameters
\fBprediction\fP (\fITranscript\fP) \-\- the candidate transcript to be analysed
.UNINDENT
.sp
This function will get the best possible assignment for each transcript.
Fusion genes are called when the following conditions are verified:
\- the prediction intersects (at least) two transcripts in (at least)
two different loci
\- the suspected fusion transcript lies on the same strand of all
candidate fused genes
\- each candidate transcript has at least one fusion or
10% of its nucleotides covered by the fusion transcript.
The 10% threshold is hard\-coded in the function.
.UNINDENT
.INDENT 7.0
.TP
.B static get_f1(curr_result)
Simple getter for F1 statistics (N_F1 and J_F1)
:param curr_result: a result storer
:type curr_result: ResultStorer
.INDENT 7.0
.TP
.B Returns
(J_F1, N_F1)
.UNINDENT
.sp
:rtype (float, float)
.UNINDENT
.INDENT 7.0
.TP
.B print_refmap() -> None
Function to print out the best match for each gene.
.UNINDENT
.INDENT 7.0
.TP
.B print_tmap(res)
This method will print a ResultStorer instance onto the TMAP file.
:param res: result from compare
:type res: (ResultStorer | None)
.UNINDENT
.INDENT 7.0
.TP
.B static result_sorter(result)
Method to sort the results for the refmap. Order:
\- CCode does not contain "x", "P", "p" (i.e. fragments on opposite strand or
polymerase run\-on fragments)
\- Exonic F1 (e_f1)
\- Junction F1 (j_f1)
\- "f" in ccode (i.e. transcript is a fusion)
\- Nucleotide F1 (n_f1)
.INDENT 7.0
.TP
.B Parameters
\fBresult\fP (\fIResultStorer\fP) \-\- a resultStorer object
.TP
.B Returns
(int, float, float, float)
.UNINDENT
.UNINDENT
.UNINDENT
.SS Compare.py
.sp
Launcher for the Mikado compare utility.
Launcher for the Mikado compare utility.
.INDENT 0.0
.TP
.B Mikado.scales.compare.compare(args)
This function performs the comparison between two different files.
.INDENT 7.0
.TP
.B Parameters
\fBargs\fP \-\- the argparse Namespace
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.finalize_reference()
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBgenes\fP \-\- 
.IP \(bu 2
\fBpositions\fP \-\- 
.IP \(bu 2
\fBqueue_logger\fP \-\- 
.IP \(bu 2
\fBargs\fP \-\- 
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.load_index(args, queue_logger)
Function to load the genes and positions from the indexed GFF.
:param args:
:param queue_logger:
:return: genes, positions
:rtype: ((None|collections.defaultdict),(None|collections.defaultdict))
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.parse_prediction(args, genes, positions, queue_logger)
.INDENT 7.0
.TP
.B This function performs the real comparison between the reference and the prediction.
It needs the following inputs:
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBargs\fP \-\- the Namespace with the necessary parameters
.IP \(bu 2
\fBgenes\fP \-\- Dictionary with the reference genes, of the form
.UNINDENT
.UNINDENT
.sp
dict[chrom][(start,end)] = [gene object]
:param positions: Dictionary with the positions of the reference genes, of the form
dict[chrom][IntervalTree]
:param queue_logger: Logger
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.parse_self(args, genes, queue_logger)
This function is called when we desire to compare a reference against itself.
:param args:
:param genes:
:param queue_logger:
:return:
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.prepare_reference()
Method to prepare the data structures that hold the reference
information for the parsing.
:param args:
:param queue_logger:
:param ref_gff:
:return: genes, positions
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.compare.setup_logger(args, manager)
Function to setup the logger for the compare function.
:param args:
:param manager:
:return:
.UNINDENT
.SS Contrast.pyx
.INDENT 0.0
.TP
.B Mikado.scales.contrast.compare()
Cython function to compare two transcripts and determine a ccode.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBprediction\fP (\fITranscript\fP) \-\- the transcript query
.IP \(bu 2
\fBreference\fP \-\- the reference transcript against which we desire to
.UNINDENT
.UNINDENT
.sp
calculate the ccode and other stats.
:type reference: Transcript
.INDENT 7.0
.TP
.B Parameters
\fBlenient\fP \-\- a boolean flag that indicates whether the exon\-level features should be calculated
.UNINDENT
.sp
leniently or not.
:type lenient: bool
.sp
:rtype (ResultStorer, (int,int)) | (ResultStorer, None)
.sp
Available ccodes (from Cufflinks documentation):
.INDENT 7.0
.IP \(bu 2
=    Complete intron chain match
.IP \(bu 2
c    Contained (perfect junction recall and precision, imperfect recall)
.IP \(bu 2
j    Potentially novel isoform (fragment): at least one splice junction is shared
.UNINDENT
.sp
with a reference transcript
\- e    Single exon transfrag overlapping a reference exon and at least
10 bp of a reference intron, indicating a possible pre\-mRNA fragment.
\- i    A \fImonoexonic\fP transfrag falling entirely within a reference intron
\- o    Generic exonic overlap with a reference transcript
\- p    Possible polymerase run\-on fragment (within 2Kbases of a reference transcript)
\- u    Unknown, intergenic transcript
\- x    Exonic overlap with reference on the opposite strand (class codes e, o, m, c, _)
\- X    Overlap on the opposite strand, with some junctions in common (probably a serious mistake,
.INDENT 7.0
.INDENT 3.5
unless non\-canonical splicing junctions are involved).
.UNINDENT
.UNINDENT
.sp
Please note that the description for i is changed from Cufflinks.
.sp
We also provide the following additional classifications:
.INDENT 7.0
.IP \(bu 2
f    gene fusion \- in this case, this ccode will be followed by the ccodes of the matches for each gene, separated by comma
.IP \(bu 2
_    Complete match, for monoexonic transcripts (nucleotide F1>=80% \- i.e. min(precision,recall)>=66.7%
.IP \(bu 2
m    Exon overlap between two monoexonic transcripts
.IP \(bu 2
n    Potential extension of the reference \- we have added new splice junctions \fIoutside\fP the boundaries of the transcript itself
.IP \(bu 2
C    Contained transcript with overextensions on either side (perfect junction recall, imperfect nucleotide specificity)
.IP \(bu 2
J    Potentially novel isoform, where all the known junctions have been confirmed and we have added others as well \fIexternally\fP
.IP \(bu 2
I    \fImultiexonic\fP transcript falling completely inside a known transcript
.IP \(bu 2
.INDENT 2.0
.TP
.B h    AS event in which at least a couple of introns overlaps but without any
junction in common.
.UNINDENT
.IP \(bu 2
G    Reverse generic overlap \- the reference is monoexonic while the prediction isn\(aqt
.IP \(bu 2
P    Possible polymerase run\-on fragment
.IP \(bu 2
g   Monoexonic overlap \- the prediction is monoexonic and the reference is multiexonic
.UNINDENT
.sp
(within 2K bases of a reference transcript), on the opposite strand
.sp
This is a class method, and can therefore be used outside of a class instance.
.UNINDENT
.SS F1.pyx
.INDENT 0.0
.TP
.B Mikado.scales.f1.calc_f1()
Static method to calculate the F1 statistic given precision
and recall (order is unimportant). Definition:
F1 = (2 * precision * recall) / (precision + recall)
.UNINDENT
.SS Intervaltree.pyx
.sp
Data structure for performing intersect queries on a set of intervals which
preserves all information about the intervals (unlike bitset projection methods).
.INDENT 0.0
.TP
.B Authors
James Taylor (\fI\%james@jamestaylor.org\fP),
Ian Schenk (\fI\%ian.schenck@gmail.com\fP),
Brent Pedersen (\fI\%bpederse@gmail.com\fP)
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.scales.intervaltree.Intersecter
alias of \fI\%IntervalTree\fP
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.scales.intervaltree.Interval
Basic feature, with required integer start and end properties.
Also accepts optional strand as +1 or \-1 (used for up/downstream queries),
a name, and any arbitrary data is sent in on the info keyword argument
.sp
.nf
.ft C
>>> from bx.intervals.intersection import Interval
.ft P
.fi
.sp
.nf
.ft C
>>> f1 = Interval(23, 36)
>>> f2 = Interval(34, 48, value={\(aqchr\(aq:12, \(aqanno\(aq:\(aqtransposon\(aq})
>>> f2
Interval(34, 48, value={\(aqanno\(aq: \(aqtransposon\(aq, \(aqchr\(aq: 12})
.ft P
.fi
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.scales.intervaltree.IntervalNode
A single node of an \fIIntervalTree\fP\&.
.INDENT 7.0
.TP
.B NOTE: Unless you really know what you are doing, you probably should use
\fIIntervalTree\fP rather than using this directly.
.UNINDENT
.INDENT 7.0
.TP
.B find()
given a start and a end, return a list of features
falling within that range
.UNINDENT
.INDENT 7.0
.TP
.B insert()
Insert a new IntervalNode into the tree of which this node is
currently the root. The return value is the new root of the tree (which
may or may not be this node!)
.UNINDENT
.INDENT 7.0
.TP
.B intersect()
given a start and a end, return a list of features
falling within that range
.UNINDENT
.INDENT 7.0
.TP
.B left()
find n features with a start > than \fIposition\fP
f: a Interval object (or anything with an \fIend\fP attribute)
n: the number of features to return
max_dist: the maximum distance to look before giving up.
.UNINDENT
.INDENT 7.0
.TP
.B right()
find n features with a end < than position
f: a Interval object (or anything with a \fIstart\fP attribute)
n: the number of features to return
max_dist: the maximum distance to look before giving up.
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.scales.intervaltree.IntervalTree
Data structure for performing window intersect queries on a set of
of possibly overlapping 1d intervals.
.sp
Create an empty IntervalTree
.sp
.nf
.ft C
>>> from bx.intervals.intersection import Interval, IntervalTree
>>> intersecter = IntervalTree()
.ft P
.fi
.sp
An interval is a start and end position and a value (possibly None).
You can add any object as an interval:
.sp
.nf
.ft C
>>> intersecter.insert( 0, 10, "food" )
>>> intersecter.insert( 3, 7, dict(foo=\(aqbar\(aq) )
.ft P
.fi
.sp
.nf
.ft C
>>> intersecter.find( 2, 5 )
[\(aqfood\(aq, {\(aqfoo\(aq: \(aqbar\(aq}]
.ft P
.fi
.sp
If the object has start and end attributes (like the Interval class) there
is are some shortcuts:
.sp
.nf
.ft C
>>> intersecter = IntervalTree()
>>> intersecter.insert_interval( Interval( 0, 10 ) )
>>> intersecter.insert_interval( Interval( 3, 7 ) )
>>> intersecter.insert_interval( Interval( 3, 40 ) )
>>> intersecter.insert_interval( Interval( 13, 50 ) )
.ft P
.fi
.sp
.nf
.ft C
>>> intersecter.find( 30, 50 )
[Interval(3, 40), Interval(13, 50)]
>>> intersecter.find( 100, 200 )
[]
.ft P
.fi
.sp
Before/after for intervals
.sp
.nf
.ft C
>>> intersecter.before_interval( Interval( 10, 20 ) )
[Interval(3, 7)]
>>> intersecter.before_interval( Interval( 5, 20 ) )
[]
.ft P
.fi
.sp
Upstream/downstream
.sp
.nf
.ft C
>>> intersecter.upstream_of_interval(Interval(11, 12))
[Interval(0, 10)]
>>> intersecter.upstream_of_interval(Interval(11, 12, strand="\-"))
[Interval(13, 50)]
.ft P
.fi
.sp
.nf
.ft C
>>> intersecter.upstream_of_interval(Interval(1, 2, strand="\-"), num_intervals=3)
[Interval(3, 7), Interval(3, 40), Interval(13, 50)]
.ft P
.fi
.INDENT 7.0
.TP
.B add()
Insert the interval [start,end) associated with value \fIvalue\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B add_interval()
Insert an "interval" like object (one with at least start and end
attributes)
.UNINDENT
.INDENT 7.0
.TP
.B after()
Find \fInum_intervals\fP intervals that lie after \fIposition\fP and are no
further than \fImax_dist\fP positions away
.UNINDENT
.INDENT 7.0
.TP
.B after_interval()
Find \fInum_intervals\fP intervals that lie completely after \fIinterval\fP and
are no further than \fImax_dist\fP positions away
.UNINDENT
.INDENT 7.0
.TP
.B before()
Find \fInum_intervals\fP intervals that lie before \fIposition\fP and are no
further than \fImax_dist\fP positions away
.UNINDENT
.INDENT 7.0
.TP
.B before_interval()
Find \fInum_intervals\fP intervals that lie completely before \fIinterval\fP
and are no further than \fImax_dist\fP positions away
.UNINDENT
.INDENT 7.0
.TP
.B downstream_of_interval()
Find \fInum_intervals\fP intervals that lie completely downstream of
\fIinterval\fP and are no further than \fImax_dist\fP positions away
.UNINDENT
.INDENT 7.0
.TP
.B find()
Return a sorted list of all intervals overlapping [start,end).
.UNINDENT
.INDENT 7.0
.TP
.B from_tuples()
.INDENT 7.0
.TP
.B Create a new IntervalTree from an iterable of 2\- or 3\-tuples,
where the tuple lists begin, end, and optionally data.
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B insert()
Insert the interval [start,end) associated with value \fIvalue\fP\&.
.UNINDENT
.INDENT 7.0
.TP
.B insert_interval()
Insert an "interval" like object (one with at least start and end
attributes)
.UNINDENT
.INDENT 7.0
.TP
.B search()
Return a sorted list of all intervals overlapping [start,end).
.UNINDENT
.INDENT 7.0
.TP
.B traverse()
call fn for each element in the tree
.UNINDENT
.INDENT 7.0
.TP
.B upstream_of_interval()
Find \fInum_intervals\fP intervals that lie completely upstream of
\fIinterval\fP and are no further than \fImax_dist\fP positions away
.UNINDENT
.UNINDENT
.SS ResultStorer.py
.sp
This class defines the results of the Assigner.compare method.
.INDENT 0.0
.TP
.B class Mikado.scales.resultstorer.ResultStorer(*args)
This class stores the results in pre\-defined slots, to reduce memory usage.
.INDENT 7.0
.TP
.B _asdict()
.INDENT 7.0
.TP
.B Returns
a dictionary containing the items of the class
.UNINDENT
.sp
:rtype : dict
.UNINDENT
.INDENT 7.0
.TP
.B as_dict()
Wrapper for the protected method _asdict
:return: dictionary
.UNINDENT
.UNINDENT
.SS Submodule: serializers
.sp
This module contains the ORM modules necessary to create the starting DB from the input data.
.SS blast_serializers
.sp
This package contains all the modules necessary for BLAST serialisation and analysis.
.SS hit.py
.sp
This module implements the Hit serialisation class.
.INDENT 0.0
.TP
.B class Mikado.serializers.blast_serializer.hit.Hit(query_id, target_id, alignment, evalue, bits, hit_number=1, query_multiplier=1, target_multiplier=1)
This class is used to serialise and store in a DB a BLAST hit.
Stored attributes:
.INDENT 7.0
.IP \(bu 2
id                Indexing key
.IP \(bu 2
query_id            Foreign ID key for the query table
.IP \(bu 2
target_id            Foreign ID key for the target table
.IP \(bu 2
qt_constrating
.UNINDENT
.INDENT 7.0
.TP
.B as_dict()
Method to return a dict representation of the object.
Necessary for storing.
.INDENT 7.0
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B classmethod as_dict_static(state_obj)
Method to return a dict representation of the object.
Static method to be called from outside the class.
.INDENT 7.0
.TP
.B Parameters
\fBstate_obj\fP \-\- a namedtuple or an instance of this class
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B classmethod as_full_dict_static(hit_tuple, hsp_list, query_tuple, target_tuple)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBhit_tuple\fP (\fIcollections.namedtuple\fP) \-\- Hit namedtuple (from direct query to the DB)
.IP \(bu 2
\fBhsp_list\fP (\fIlist(collections.namedtuple)\fP) \-\- list of hsp dictionaries from Hsp.as_dict_static
.IP \(bu 2
\fBquery_tuple\fP (\fIcollections.namedtuple\fP) \-\- Query namedtuple
.IP \(bu 2
\fBtarget_tuple\fP (\fIcollections.namedtuple\fP) \-\- Target namedtuple
.UNINDENT
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.UNINDENT
.SS hsp.py
.sp
This module implements the HSP serialisation class.
.INDENT 0.0
.TP
.B class Mikado.serializers.blast_serializer.hsp.Hsp(hsp, counter, query_id, target_id)
This class serializes and stores into the DB the various HSPs.
It is directly connected to the Hit table, through the "hit_id"
reference key.
The Hit reference can be accessed through the hit_object attribute;
back\-reference (Hit to Hsps) is given by the "hsps" attribute.
.sp
Keys:
.INDENT 7.0
.TP
.B Return hit_id
Reference key for the Hit table
.TP
.B Rtype hit_id
int
.TP
.B Return counter
It indicates the progressive number of the HSP for the hit
.TP
.B Rtype counter
int
.TP
.B Return query_hsp_start
Start position on the query
.UNINDENT
.sp
:rtype query_hsp_start; int
.INDENT 7.0
.TP
.B Return query_hsp_end
End position on the query
.TP
.B Rtype query_hsp_end
int
.TP
.B Return target_hsp_start
Start position on the target
.TP
.B Rtype target_hsp_start
int
.TP
.B Return target_hsp_end
End position on the target
.TP
.B Rtype target_hsp_end
int
.TP
.B Return hsp_evalue
Evalue of the HSP
.TP
.B Rtype hsp_evalue
float
.TP
.B Return hsp_bits
Bit\-score of the HSP
.TP
.B Rtype hsp_bits
float
.TP
.B Return hsp_identity
Identity (in %) of the alignment
.TP
.B Rtype hsp_identity
float
.TP
.B Return hsp_length
Length of the HSP
.TP
.B Rtype hsp_length
int
.TP
.B Return match
the match line between query and target, with the following specs:
\- If the position is a match/positive, keep the original value
\- If the position is a gap \fIfor the query\fP, insert a \- (dash)
\- If the position is a gap \fIfor the target\fP, insert a _ (underscore)
\- If the position is a gap \fIfor both\fP, insert a (backslash)
.UNINDENT
.sp
An HSP row has the following constraints:
\- Counter,hit_id must be unique (and are primary keys)
\- The combination ("Hit_id","query_hsp_start","query_hsp_end",
"target_hsp_start", "target_hsp_end") must be unique
.sp
Moreover, the following properties are also present:
.INDENT 7.0
.TP
.B Return query_object
The referenced Query
.TP
.B Rtype query_object
Query
.TP
.B Return target_object
The reference Target
.TP
.B Rtype target_object
Target
.UNINDENT
.INDENT 7.0
.TP
.B as_dict()
Method to return a dict representation of the object. Necessary for storing.
This method returns a dictionary \fIwithout any attribute that requires joined data\fP\&.
It is meant to be used only by the method as_dict of the Hit class.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod as_dict_static(state_obj)
Method to return a dict representation of the object. Necessary for storing.
This method returns a dictionary \fIwithout any attribute that requires joined data\fP\&.
As a static method, it is useful to be used outside of the class.
:param state_obj: an instance of the HSP class or a
collections.namedtuple object from a direct query
.sp
:rtype : dict
.UNINDENT
.INDENT 7.0
.TP
.B as_full_dict()
Method to return a dict representation of the object.
This method also checks query name and hit name, so it is slower than as_dict and used
when it is necessary to retrieve data independently from Hit.
.UNINDENT
.UNINDENT
.SS query.py
.sp
Basic module with the Query serialiser.
.INDENT 0.0
.TP
.B class Mikado.serializers.blast_serializer.query.Query(name, length)
Very simple serialization class for Query objects.
.INDENT 7.0
.TP
.B Return id
integer key
.TP
.B Rtype id
int
.TP
.B Return name
name of the queries
.TP
.B Rtype name
str
.TP
.B Return length
length of the queries
.TP
.B Rtype length
int
.UNINDENT
.INDENT 7.0
.TP
.B as_tuple()
Quick function to convert the SQLalchemy object into
a named tuple with the same fields
.UNINDENT
.INDENT 7.0
.TP
.B named_tup
alias of \fI\%Query\fP
.UNINDENT
.UNINDENT
.SS target.py
.sp
This module implements a very simple class for serialising the BLAST targets into
a table containing numeric ID, name and length.
.INDENT 0.0
.TP
.B class Mikado.serializers.blast_serializer.target.Target(target_name, target_length)
Very simple serialization class for Target objects.
.INDENT 7.0
.TP
.B as_tuple()
Quick function to convert the SQLalchemy object
into a named tuple with the same fields
.UNINDENT
.INDENT 7.0
.TP
.B named_tup
alias of \fI\%Target\fP
.UNINDENT
.UNINDENT
.SS utils.py
.sp
Generic utilities used for BLAST serialising into a DB.
.INDENT 0.0
.TP
.B Mikado.serializers.blast_serializer.utils.prepare_hit(hit, query_id, target_id, **kwargs)
Prepare the dictionary for fast loading of Hit and Hsp objects.
global_positives: the similarity rate for the global hit \fIusing the query perspective\fP
global_identity: the identity rate for the global hit \fIusing the query perspective\fP
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBhit\fP (\fIBio.SearchIO._model.hit.Hit\fP) \-\- the hit to parse.
.IP \(bu 2
\fBquery_id\fP (\fIint\fP) \-\- the numeric ID of the query in the database. Necessary for serialisation.
.IP \(bu 2
\fBtarget_id\fP (\fIint\fP) \-\- the numeric ID of the target in the database. Necessary for serialisation.
.IP \(bu 2
\fBkwargs\fP (\fIdict\fP) \-\- additional properties to give to the hit_dict. Retrieved e.g. from descriptions.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.serializers.blast_serializer.utils.prepare_hsp(hsp, counter)
Prepare a HSP for loading into the DB.
The match line will be reworked in the following way:
.INDENT 7.0
.IP \(bu 2
If the position is a match/positive, keep the original value
.IP \(bu 2
If the position is a gap \fIfor the query\fP, insert a \- (dash)
.IP \(bu 2
If the position is a gap \fIfor the target\fP, insert a _ (underscore)
.IP \(bu 2
If the position is a gap \fIfor both\fP, insert a (backslash)
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
\fBhsp\fP \-\- An HSP object from Bio.Blast.NCBIXML
.UNINDENT
.sp
# :type hsp: Bio.Blast.Record.HSP
:type hsp: Bio.SearchIO._model.hsp.HSP
:param counter: a digit that indicates the priority of the HSP in the hit
:return: hsp_dict, identical_positions, positives
:rtype: (dict, set, set)
.UNINDENT
.SS xml_serialiser.py
.sp
XML serialisation class.
.INDENT 0.0
.TP
.B class Mikado.serializers.blast_serializer.xml_serialiser.XmlSerializer(xml_name, logger=None, json_conf=None)
This class has the role of taking in input a blast XML file and (partially)
serialise it into a database. We are using SQLalchemy, so the database type
could be any of SQLite, MySQL, PSQL, etc.
.INDENT 7.0
.TP
.B _XmlSerializer__determine_sequences(query_seqs, target_seqs)
Private method to assign the sequence file variables
if necessary.
:param query_seqs:
:param target_seqs:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B static _XmlSerializer__get_multipliers(record)
Private quick method to determine the multipliers for a BLAST alignment
according to the application present in the record.
:param record:
:return:
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__get_query_for_blast(record, queries)
This private method formats the name of the query
recovered from the BLAST hit, verifies whether it is present or not
in the DB, and moreover whether the data can be updated (e.g.
by adding the query length)
:param record:
:param queries:
:return: current_query (ID in the database), name
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__get_target_for_blast(alignment, targets)
This private method retrieves the correct target_id
key for the target of the BLAST. If the entry is not present
in the database, it will be created on the fly.
The method returns the index of the current target and
and an updated target dictionary.
:param alignment: an alignment child of a BLAST record object
:param targets: dictionary caching the known targets
:return: current_target (ID in the database), targets
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__load_into_db(hits, hsps, force=False)
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBhits\fP \-\- 
.IP \(bu 2
\fBhsps\fP \-\- 
.IP \(bu 2
\fBforce\fP \-\- boolean flag. If set, data will be loaded no matter what.
.UNINDENT
.UNINDENT
.sp
To be used at the end of the serialisation to load the final batch of data.
:type force: bool
.INDENT 7.0
.TP
.B Returns

.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__serialise_record(record, hits, hsps, targets)
Private method to serialise a single record into the DB.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBrecord\fP \-\- The BLAST record to load into the DB.
.IP \(bu 2
\fBhits\fP (\fIlist\fP) \-\- Cache of hits to load into the DB.
.IP \(bu 2
\fBhsps\fP (\fIlist\fP) \-\- Cache of hsps to load into the DB.
.IP \(bu 2
\fBtargets\fP \-\- dictionary which holds the relationship target ID/name.
It can be updated in place if a target has not been serialised already.
.UNINDENT
.TP
.B Returns
hits, hsps, hit_counter, targets
.TP
.B Return type
(list, list, int, dict)
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__serialise_sequences()
Private method called at the beginning of serialize. It is tasked
with loading all necessary FASTA sequences into the DB and precaching the IDs.
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__serialize_queries(queries)
Private method used to serialise the queries.
Additional argument: a set containing all queries already present
in the database.
.UNINDENT
.INDENT 7.0
.TP
.B _XmlSerializer__serialize_targets(targets)
This private method serialises all targets contained inside the target_seqs
file into the database.
:param targets: a cache dictionary which records whether the sequence
.INDENT 7.0
.INDENT 3.5
is already present in the DB or not.
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B load_into_db(objects)
.INDENT 7.0
.TP
.B Parameters
\fBobjects\fP (\fIlist\fP) \-\- Objects to be loaded into the database
.UNINDENT
.sp
Method to perform the bulk loading of objects into the SQL database.
.UNINDENT
.INDENT 7.0
.TP
.B serialize()
Method to serialize the BLAST XML file into a database
provided with the __init__ method
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.serializers.blast_serializer.xml_serialiser._pickle_xml(filename, default_header=\(aq\(aq, maxobjects=inf, logging_queue=None, level=\(aqWARN\(aq)
Private method to load the records from an XML file into a pickled file,
for faster loading.
:param filename:
:param logging_queue: the queue to be used for logging
.INDENT 7.0
.TP
.B Returns
a list of the
.UNINDENT
.UNINDENT
.SS junction.py
.sp
This module is necessary to serialise the junction information
provided in BED12 format by programs such as TopHat or portcullis.
Please convert any other (custom) format into BED12
before loading.
.INDENT 0.0
.TP
.B class Mikado.serializers.junction.Chrom(name, length=None)
Simple serialization class for chromosomes.
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.serializers.junction.Junction(bed12_object, chrom_id)
Class that describes the junction table in the database.
.INDENT 7.0
.TP
.B is_equal(chrom, start, end, strand)
Function to verify whether a set of coordinates is equal to those in the DB.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBchrom\fP (\fIstr\fP) \-\- chromosome
.IP \(bu 2
\fBstart\fP (\fIint\fP) \-\- start position (1\-offset)
.IP \(bu 2
\fBend\fP (\fIint\fP) \-\- end position (1\-offset)
.IP \(bu 2
\fBstrand\fP (\fIstr\fP) \-\- strand of the junction
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.serializers.junction.JunctionSerializer(handle, json_conf=None, logger=None)
This class is used to serialize a junction BED12 file into an SQL database.
.INDENT 7.0
.TP
.B close()
Closing method for with. It will close the handles, if they are defined.
:return:
.UNINDENT
.INDENT 7.0
.TP
.B serialize()
Workhorse of the class. It parses the input file and loads it into the database.
.UNINDENT
.UNINDENT
.SS orf.py
.sp
This module contains the necessary classes for serialising and querying ORF data.
.INDENT 0.0
.TP
.B class Mikado.serializers.orf.Orf(bed12_object, query_id)
Serialization class for ORFs derived from BED12 files.
.INDENT 7.0
.TP
.B as_bed12()
Method to transform the mapper into a BED12 object.
.UNINDENT
.INDENT 7.0
.TP
.B classmethod as_bed12_static(state, query_name)
Class method to transform the mapper into a BED12 object.
Usable from outside the class.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBstate\fP \-\- the original state derived from the mapping.
.IP \(bu 2
\fBquery_name\fP \-\- the name of the query, retrieved from the Query associated object/table.
.UNINDENT
.UNINDENT
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B class Mikado.serializers.orf.OrfSerializer(handle, json_conf=None, logger=None)
This class has the purpose of automating the loading of ORF information into the SQL database.
.INDENT 7.0
.TP
.B load_fasta(cache)
Private method to load data from the FASTA file into the database.
:param cache: a dictionary which memoizes the IDs.
:type cache: dict
.INDENT 7.0
.TP
.B Returns
the updated cache
.TP
.B Return type
dict
.UNINDENT
.UNINDENT
.INDENT 7.0
.TP
.B serialize()
This method performs the parsing of the ORF file and the
loading into the SQL database.
.UNINDENT
.UNINDENT
.SS Submodule: loci
.sp
This module contains basic utilities for the suite, like e.g. database connection
and log creation.
.SS dbutils.py
.sp
This initializer contains the base declaration for all the DB classes of the module.
.INDENT 0.0
.TP
.B Mikado.utilities.dbutils.connect(json_conf, logger=None)
Function to create an engine to connect to a DB with, using the
configuration inside the provided json_conf.
:param json_conf:
:param logger:
:return: sqlalchemy.engine.base.Engine
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.utilities.dbutils.create_connector(json_conf, logger=None)
Creator function for the database connection. It necessitates the following information from
the json_conf dictionary:
.INDENT 7.0
.IP \(bu 2
dbtype (one of sqlite, mysql, postgresql)
.IP \(bu 2
db (name of the database file, for sqlite, otherwise name of the database)
.UNINDENT
.sp
If the database is MySQL/PostGreSQL, the method also requires:
.INDENT 7.0
.IP \(bu 2
dbuser
.IP \(bu 2
dbhost
.IP \(bu 2
dbpasswd
.IP \(bu 2
dbport
.UNINDENT
.sp
These are controlled and added automatically by the json_utils functions.
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBjson_conf\fP (\fIdict\fP) \-\- configuration dictionary
.IP \(bu 2
\fBlogger\fP (\fIlogging.Logger\fP) \-\- a logger instance
.UNINDENT
.UNINDENT
.sp
:rtype : MySQLdb.connect | sqlite3.connect | psycopg2.connect
.UNINDENT
.SS log_utils.py
.sp
Module which contains all functions related to logging.
.INDENT 0.0
.TP
.B Mikado.utilities.log_utils.check_logger(logger)
Quick function to verify that a logger is really a logger,
otherwise it raises a ValueError.
.INDENT 7.0
.TP
.B Parameters
\fBlogger\fP (\fIlogging.Logger\fP) \-\- the logger instance
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.utilities.log_utils.create_default_logger(name, level=\(aqWARN\(aq)
Default logger
:param name: string used to give a name to the logger.
:type name: str
.INDENT 7.0
.TP
.B Parameters
\fBlevel\fP \-\- level of the logger. Default: WARN
.UNINDENT
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.utilities.log_utils.create_null_logger(*args, **kwargs)
Static method to create a default logging instance for the loci.
The default is a null handler (no log)
.INDENT 7.0
.TP
.B Parameters
\fBinstance\fP \-\- the instance used to derive a name for the logger. It must be either a string
.UNINDENT
.sp
or a class instance with a __name__ attribute.
.UNINDENT
.INDENT 0.0
.TP
.B Mikado.utilities.log_utils.create_queue_logger(instance, prefix=\(aq\(aq)
.INDENT 7.0
.TP
.B Create a queue logger for a specific class, which \fImust\fP have
a "logging_queue" property redirecting to a queue\-like object.
If the instance possesses a "log_level" attribute, the log level
will be set to its value; otherwise, the logger will be configured
with a default level of "WARNING".
.UNINDENT
.INDENT 7.0
.TP
.B Parameters
.INDENT 7.0
.IP \(bu 2
\fBinstance\fP \-\- 
.IP \(bu 2
\fBprefix\fP \-\- 
.UNINDENT
.TP
.B Returns

.UNINDENT
.UNINDENT
.SS overlap.pyx
.INDENT 0.0
.TP
.B Mikado.utilities.overlap.overlap()
This function quickly computes the overlap between two
ranges, with an optional flank.
.UNINDENT
.SH CITING
.sp
We are currently working on our paper, and we will be releasing a pre\-print shortly.
In the meantime, if you use Mikado please reference our github page: \fI\%https://github.com/lucventurini/mikado\fP
.SH AVAILABILITY AND LICENSE
.sp
Open source code available on github: \fI\%https://github.com/lucventurini/mikado\fP
.sp
This documentation is hosted publicly on read the docs: \fI\%https://mikado.readthedocs.org/en/latest/\fP
.sp
Mikado is available under \fI\%GNU GLP V3\fP\&.
.SS Credits
.INDENT 0.0
.INDENT 3.5
.INDENT 0.0
.IP \(bu 2
Luca Venturini (The software architect and developer)
.IP \(bu 2
Shabhonam Caim (Primary tester)
.IP \(bu 2
Daniel Mapleson (Developer of PortCullis and of the Daijin pipeline)
.IP \(bu 2
Gemy Kaithakottil (Tester and analytic consultancy)
.IP \(bu 2
David Swarbreck (Annotation guru and ideator of the pipeline)
.UNINDENT
.UNINDENT
.UNINDENT
.SH AUTHOR
Venturini Luca, Caim Shabhonam, Mapleson Daniel, Kaithakottil Gemy George, Swarbreck David
.SH COPYRIGHT
2016, Venturini Luca, Caim Shabhonam, Mapleson Daniel, Kaithakottil Gemy George, Swarbreck David
.\" Generated by docutils manpage writer.
.
